ChatGPT Isn't Finished (Made into a
Software Application Suite);
It's a Simple Textbox Interface to an API

noctivagous.github.io

ChatGPT (GPT4) offers a lot of capabilities but the actual situation
is that it is just a superficial website gateway-- a plain text box-- 
for what OpenAI engineered that is sitting in the computer data centers.   
Originally  OpenAI was just focused on selling access to that through
a very technical API (the API that communicates to the LLM in the data 
centers).  Then it put together this chat-style format on a web page 
as a shallow demonstration of how it is possible to interact with the API.  
The API's responses are stacked up vertically after the user sends out 
text to the API.  On the front end, it's not that sophisticated.

According to official accounts,  ChatGPT is an accidental success; 
OpenAI originally released it as a "research preview". They had no 
intention of marketing it commercially.  But then the public's interest 
in the user-friendly interface to GPT3 exceeded expectations. 
This is according to their own version of events.

The ChatGPT style of web interaction with AI was possible earlier, of course, and 
there were consumers in previous years requesting an opportunity to chat 
for free with an AI bot in this way, because all of the available options 
cost money and might not be very good.  Fortunately, OpenAI provided 
an opportunity for people interested in AI to try out interacting with 
their API for free, without needing to write a program that interacted with 
the GPT3 API.  OpenAI also succeeded with ChatGPT because it provided a high-quality 
LLM, this GPT3.

But what OpenAI may not realize is that, as an organization, it only
has hired personnel to work on one side of the situation, the engineering 
of the AI in the data centers, and they do not have a team intent 
on completing the ChatGPT app into something finished, resembling a 
completed suite of features (like an iLife app, such as GarageBand).  
The natural evolution of ChatGPT would lead to this, for interacting 
with an LLM can go beyond writing text from scratch every time in a 
one-line box, something that gets tiresome after a while (always writing 
from scratch the commands).  This is to say that ChatGPT isn't a suite of tools and 
OpenAI stopped at providing text box that sends API calls, with the web page 
stacking the responses in the appearance of a "chat".

ChatGPT just provides a simple interface to the GPT's raw API that, 
previously, few people except experienced programmers could use.  
The "research preview" transformed the situation by satisfying lay 
demand for free access to AI, but it wasn't built out beyond that, it isn't a 
complete software package with a fully developed app experience, 
with ways to access all of the use cases and scenarios of an LLM. 
Too much is left to the user to figure out.

It's very basic, as it's not even possible to collapse, close, or hide 
any of the chat output from ChatGPT. There are no nodes (patches) 
a person can wire up to control its responses (such as what is found 
in Unreal Engine's Blueprints). Some people in the AI community 
have come up with their own independent apps with this feature for 
interfacing to LLMs, especially for the image generators.
 
Apart from a text box, there is nothing guiding the user for how to 
use ChatGPT, which means that too much of a burden is placed
on the person who arrives at OpenAI's website.  
When we say that ChatGPT needs to be built into an app 
this means that ChatGPT doesn't have any menus, toolbars, panels, 
presets, templates, or generic prompts.  It isn't a finished app 
because it is a blank box with little guidance of how to use it. 
It isn't any kind of lifestyle or productivity app. So, there 
is no way the public can find this tool useful for very long unless 
OpenAI begins to work on it as real software.

At the most basic level, what ChatGPT needs is not just a few specific 
examples to click on such as "Come up with a trip itinerary for me to 
visit____" but instead a set of grouped, generic prompts: "Come up with a ___" or "Make 
an outline for ___".  These would be grouped into categories of 
use as well, such as for daily life, research, quizzing, etc.

An LLM could be discussed as the basis for a different category of app,
such as one that aids the user in reading older or ancient 
texts and is dedicated to this task, generating live 
marginalia or explanations of the text on the page as each page is turned.  
Another app would look different if utilized for cooking because it would have
features tailored for different aspects of that task, such as generating
recipes out of available ingredients, replacing ingredients in provided
recipes with substitutions, etc.  It would also carry conventional app
features, like storing recipes.  An LLM offers the engineered AI resource
for these use cases and many more but it makes more sense to use it
as the backend of a new category of app.  Just by focusing on these two use case, 
and how they are crammed into the tiny text box that is ChatGPT's means 
input, it demonstrates how uncomfortable ChatGPT really is to use for 
a wide variety of tasks.  A bare text box would have to be repurposed
for these two very different needs.

The main problem in the AI community and the tech community sometimes
is the concept that the following is what consumers will really want
for the long term.  The consumer will utter, "I want this complex thing 
that would normally take me a lot of time," and then the AI goes off and 
does it, returns to the person with an impressive result, and everyone 
is very delighted.  This is the parlor trick mentality of technology
that is to be avoided because it doesn't carry long-term value for
people and these products eventually lose users over time.

Finally, typing text is not always the strongest means of controlling 
an LLM at all times, because it depends on the use case.  If it is 
DALL-E, then there should be pre-configured controls (such as the 
node-based programming nodes) with adjustable parameters.



