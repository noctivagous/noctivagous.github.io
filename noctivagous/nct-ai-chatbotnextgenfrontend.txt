Going Beyond The 2022 ChatGPT App Format

INTERACTIVE MODES

Planning the next generation of AI chatbot web app should be a focus of the AI industry.  The archetypal AI chatbot app (found everywhere) should no longer just repurpose the bare scrolling chat and make it the fixed mode for everything. The user is occasionally putting the AI into modes, such as prompting it to give a quiz or teach a subject.  But when the user interface is a scrolling chat, making the AI enter these modes without there being tailored GUIs to accompany them is really just a forced hack.  The AI isn't given the ability to determine the app's GUI according to the usage situations.  Different modes (quiz vs. teaching) will benefit from different app layouts and GUI controls.  In fact, in these chatbot apps the AI cannot even insert form (GUI) controls inside a response today, to collect information. The AI can only collects information in the form of typed or pasted text, from the large text input field. With just a few minor software additions on the part of the AI vendors, the AI could easily produce a form in its response with multiple input controls.  

After the 2022 ChatGPT web chat experiment took off, it wasn't revised or significantly upgraded. It is important to return to traditional software practices for this type of software. If the AI is quizzing the user, it should be able to change the app's entire GUI into a proper interactive quiz format (still keyboard driven) so that the software's presentation matches the usage situation.k   Another mode that would benefit from GUI is step-by-step walkthrough, in which the user has asked to be walked through a task or project.  This also needs its own GUI.  In the walkthrough mode, for each step, the AI gives the user some instructions, waits for a response, and then uses the results to generate the next step (repeating until the user accomplishes the job). When a mode like this is forced inside the same vertical scrolling chat of plain text, this isn't doing the AI model justice.  Much more work has to be done on the front-end software, in other words.

So, for the next generation of AI chatbot app, this AI chat technique ("start quizzing me on..." or "collect information from me about...") should be turned into officially incorporated modes that load their accompanying GUIs and layouts. For a quiz mode, the GUI is set up to show one question at a time. Matching the GUI needs for a quiz, the app is presenting to the user form input controls like multiple choice buttons, sliders, and checkboxes to get an answer.  For the step-by-step walkthrough mode, one slide can be shown at a time, with a text input area.  The walkthrough mode is useful when asking the AI how to troubleshoot a computer problem, for example, or diagnose a car or appliance issue, or carry out some kind of technical task.  The author of this article has made use of AI chatbots in this mode while configuring a Linux system at the command line level, which is can suddenly turn into a convoluted chore that benefits greatly from AI assistance.

As part of a transitional stage, today's chatbot software could equip the AI with form input fields and other GUI controls that it is able to generate inside responses for collection of information.  The interface would still be keyboard-driven, with input in the main text field selecting options on the form controls.  It would allow scenarios where, for example, the AI embeds an interactive map.  Let's say also, in the vertical scrolling chat, it had an exchange with a user with interactive curve editor or an interactive spreadsheet table.  What the user edits would be the controls in the response produced by the AI and the user would press a "Submit" button (or activate it with Alt/Opt+Enter).

---

Traditional Software Menus at The Top

The absence of conventional menus makes feature discovery harder and constrains the user’s ability to engage with the system in predictable, software-like ways.

To do:

1. Modify In Place

- The generated response is always editable by the user in place.  
List items can be added, changed and deleted as can table rows, columns, and cells.
- The user can shape the AI's response into a finished draft or document because
editing tools are provided.  This is better than the user having to always copy
and paste the generated text to a separate text editor.

2. Restoration of Process
Uploading a document or pasting a large amount of text does not just leave it inside the text input area but instead opens it in an overlay panel that organizes the information so that the user can selectively apply AI to its contents and then the output occurs in the chat or the other pane.
- Uploading a document or pasting a large text block doesn’t fill the input box; instead, it opens in an overlay panel that automatically structures the content into sections (headings, paragraphs, tables). The user can then select regions and choose actions like Summarize, Comment, or Extract Data from a contextual toolbar. AI output appears either in the chat or in a linked pane beside the source.
- Select some text and press the "analyze" button from the toolbar of functions (or press Alt+A) and a popover window appears with the AI’s analysis output.
- Any time that text is selected, a toolbar with labeled buttons appears with functions like : Summarize, Explain, Rephrase. 


3. Make The Software Finished
Integrating conventional GUI elements atop conversational engines—persistent menu bars, context grids, or modular “mode” panes—will bridge natural language flexibility with standard user interface predictability.



prompt keywords grid menu: "analyze", "summarize", "grammar check", etc.

Example: 1) Select some text and press the "analyze" button from 
the grid of actions and either a popover appears or a new chat.

Current situation:

User Burden - Users must remember phrasing or prompt formats for each operation instead of choosing from labeled functions.
Mode Ambiguity - When entering specialized tasks (teaching, quizzes, translation), the system lacks persistent visual state indicators or toggles.
Interface Inflexibility - A pure chat stream prevents multimodal interaction—no contextual toolbars, visual previews, or hierarchical options.
Cognitive Load - Without visual affordances, the user must track modes mentally, making complex workflows cumbersome.

The AI chatbot software format found everywhere, because it still follows closely the 2022 prototype (the ChatGPT "Research Preview") didn't take up the task of incorporating normal user interface elements, like menus that allow the user to access features.

----

THE OUTPUT STAGING AREA

The chatbot window split into two regions:

1. the chat area
2. the output staging area.
    - user can manually put data from the chat
    area into the output area or instruct
    the chatbot to do it.
    - output to this area as files, chat snippets.
    - staging area because 
    it allows routing to other places.
    
    
-----

----

EXAMPLE MODES AND THEIR GUIs: 

1. Quiz Mode
GUI: Displays one question at a time with multiple-choice buttons, checkboxes, text inputs, or sliders. Progress bar, score tracker, and "Reveal Answer" button.
Workflow: AI generates questions from a topic; user submits answers; AI provides immediate feedback, explanations, and adapts difficulty.

2. Step-by-Step Walkthrough Mode
GUI: Carousel or slide-based layout showing one step at a time (instruction + expected result). Side panel for user input (e.g., paste terminal output). "Next" button enabled after submission.
Workflow: Step → User reports result → AI interprets/adjusts → Next step. Ideal for troubleshooting (e.g., Linux config, appliance repair).

3. Questionnaire/Information Gathering Mode
GUI: Form-based (single-page for all questions or one-at-a-time). Inputs include text fields, dropdowns, file uploads, date pickers. Progress indicators and validation.
Workflow: AI asks structured questions to collect data (e.g., for project setup); compiles responses; generates output (e.g., code scaffolds, plans).

4. Teaching/Course Instruction Mode
GUI: Lesson dashboard with modules, embedded videos/images, note-taking panel, and interactive exercises. Timeline navigation for revisiting sections.
Workflow: AI delivers content in sequenced lessons; interleaves quizzes, examples, and Q&A; tracks user progress and adapts pacing.

5. Document Study Mode
GUI: Integrated document viewer (PDF/text upload, page-by-page flip). Highlight/select tools for words/paragraphs; pop-up side panel for definitions, translations, or explanations.
Workflow: User uploads/navigates document; selects text; AI provides lookups, summaries, or context; supports foreign languages or arcane terms.

---

To simulate a walkthrough mode for in today's scrolling chatbot GUI, give it the following prompt: "I want to [e.g.: optimize the speed of my Linux system with the terminal].  Let's do this one step at a time and I give you results. A step–result–interpret loop."  This is usually better for the job than the default response and layout of the chatbot, which is a generated list of instructions for the user to follow.  Doing it the default way like that isn't making use of AI's latent interactive capacities.  The AI is useful for this because when working with the command line complexities and unexpected results can arise at each step. Yhe AI can respond according to the user's results.  Matching the app's GUI to a mode like walthrough is important this is better presented different than a vertical scrolling chat.  The chat right now is more about the user making queries.  In the walkthrough mode, each step is one in which the AI either gathers information or gives instructions and then asks for the results.

In a new type of chatbot, it will make a big difference that there are designated modes offered to the user in a formal way, each of which activate a collection of GUI, decision trees, and workflows.  The welcome screen for the chatbot app might provide a menu grid of these modes.  The improvement is that when the user approaches the software, there are entry points provided for how to use it and the burden isn't place on the user for how to make the AI valuable. The AI chatbot will improve if its GUI transforms to match various mode scenarios.   The design of the software will be more than just a plain chat but it can still offer this. 

Another mode gathers information in the form of questionnaires, either all at once on a single form or spread out one question at a time, before taking action, such as to set up a software development project or project where there are placeholders it can generate.  A little more mode dynamic would be a teaching mode for course instruction, and the GUI would change to accommodate that, too.

When studying a book that has arcane vocabulary or is in a foreign language, the reader can activate the corresponding mode in the AI chatbot software, which allows opening up a document viewer inside the app, displaying its contents page by page, and tools will then be provided for looking up definitions and getting more information about a selected word or paragraph.

At the bottom of this document we provide multiple examples of different interactive modes for the AI chatbot software.  An important point is that people who work in different fields can make their own modes or use modes built for them, whether it is in the music industry, screenwriting, etc.  For that to happen, the web app (or desktop app) should have extensibility built in, which in this case would be the ability of users to make custom modes, explained in a section below.  The modes that ship with the app would be made out of the same declarative desriptor file format that users can utilize to make their interactive modes.


EXTENSIBILITY

The extensibility of the chatbot software is a central way that the app can allow the next generation AI chatbot software to adapt to the world instead of vice-versa.  Users may want to make their own functionality and modes for the AI chatbot app.  These modes can be programmed and supplied by users in the form of files that contain a sequence, decision tree, and workflow descriptor (declarative) data format.  It will describe which GUI to use for a specific step of a mode and it allows providing prompt text to go control every aspect of the sequence.  By implementing all of this, the AI chatbot of today, which has remained the same since 2022, can go beyond a one-size-fits-all vertical scrolling GUI and actually accommodate different situations.

If given a set of workflow components and GUI controls, the AI could put together its own GUI forms and sequences for a situation that is a mix of these situation. But a stock set of modes will provide familiar usage of the AI and structure for it.  It is better to guide the AI today than to let it do what it wants.
Extensibility allows the programming community to try out variations on and additions to the current chat.



IMPROVING THE CONVENTIONAL SCROLLING CHAT

App-Integrated Commands

An AI chatbot web app like ChatGPT could be given some commands that work with the actual app, such as, "Take the last response you generated and put it in the scrapbook."  This is part of the issue that the software should be built out more to be like traditional app software.  Interactions with the chatbot should be able to reference aspects of the software itself.


More Natural Conversations

There is also the overlooked matter that the flow of the conversation with the AI in today's chatbot software is narrow and limited and it can never flow like a real chat, either in real life or onlione, where there commonly is an alternation between questions that ask for short answers and long ones.  In actuality, the chat software of today is following a very limiting query-and-response format and is not like chatting.  In real conversations, people ask for clarification when they need more information or something is vague, whereas the chatbot is programmed to just proceed with assumptions that fill in any unknown information.  In real convesations, people make brief suggestions, ask to make sure everything is ok, and there is a back and forth toward a goal.  After an expert or consultant asks for clarification, it gives him information about where to guide the project, what the other person's goals are and what the person needs to know.  So this is a key improvement that should be made in the next generation of AI chatbots so that they are more normal and natural for real life and the intake of information.  

Take the case of a certain feature to implement, which is brief clarifying menus. The user looking to buy a product asks how to get started and the AI responds like a store employee or expert to begin the process.  The flow of the interaction is more natural and will be easier on the user for this situation.  The user can always ask a question.  Notice that the conversation is free of flattery.  It gives the information needed without too much fluff.

USER: I am looking to buy a mini PC.  
AI: What is your budget? Press a key: 1) <$300 2) <$500 3) <$700 4) >$700 
USER: 3  
AI: 1) Linux or 2) Windows? 
USER: 1
AI: There are a lot of configuration and it depends first on whether you want an Intel CPU
or an AMD (Intel-compatible) one.  The AMD chips focus more on multi-threaded processing. Which
do you prefer?  1) Intel 2) AMD.
USER: 2
AI: How much RAM do you need?  If you can afford it, the baseline today is 16GB.

1) 8GB
2) 16GB
3) 32GB
4) 64GB+

USER: 2
AI: Storage next.  I am tracking the cost.

1) 256GB SSD
2) 512GB SSD
3) 1TB SSD
4) 2TB+ SSD

---
USER: I would like to make a tree map application overview application
that sits on the desktop and it updates live and each box contains the application 
icon and windows of the running application. [Ask questions one at at time and 
number the multiple choice answers so I can just enter a number.]

AI: What is the main purpose of the tree map view
1) process monitoring 
2) window management, or 
3) visual analytics?

USER: 3

AI: 2. Window management.  Let's continue
Which operating system(s) should the application support?

1 Windows

2 macOS

3 Linux

4 Multiple platforms (cross-platform support)


-----

Map kit - research things across a map that remains stationary during the chat.



DESKTOP APP

If this AI app is running on the desktop, the capabilities of the app widen. It can be given an AI agent that is allowed to execute apps and open up windows, which would allow it to generate an on-the-fly instructions for a user to use an unfamiliar app.  (In the future, it could be the case that the AI is given a set of complete application kit components and wires up its own apps on the fly.)  Such an app can, on its own, schedule processes for agents to track whatever the person wants to track.  It can monitor the system if it needs to and integrate into the usage of the computer.




SUMMARY OF EXAMPLE MODES: 

Each mode can carry settings or is launched with parameters (e.g. a quiz mode is launched with or without "Reveal Answer" or a document review mode's settings shows and
hides various features).

1. Quiz Mode
Converts conversational questioning into a structured, trackable exercise.
GUI: Displays one question at a time with multiple-choice buttons, checkboxes, text inputs, or sliders. Progress bar, score tracker, and "Reveal Answer" button.
Workflow: AI generates questions from a topic; user submits answers; AI provides immediate feedback, explanations, and adapts difficulty.

2. Step-by-Step Walkthrough Mode
Guides complex, procedural learning (e.g., coding tutorials, design setups).
GUI: Carousel or slide-based layout showing one step at a time (instruction + expected result). Side panel for user input (e.g., paste terminal output). "Next" button enabled after submission.
Workflow: Step → User reports result → AI interprets/adjusts → Next step. Ideal for troubleshooting (e.g., Linux config, appliance repair).

3. Questionnaire/Information Gathering Mode
GUI: Form-based (single-page for all questions or one-at-a-time). Inputs include text fields, dropdowns, file uploads, date pickers. Progress indicators and validation.
Workflow: AI asks structured questions to collect data (e.g., for project setup); compiles responses; generates output (e.g., code scaffolds, plans).

4. Teaching/Course Instruction Mode
GUI: Lesson dashboard with modules, embedded videos/images, note-taking panel, and interactive exercises. Timeline navigation for revisiting sections.
Workflow: AI delivers content in sequenced lessons; interleaves quizzes, examples, and Q&A; tracks user progress and adapts pacing.

5. Document Study Mode
GUI: Integrated document viewer (PDF/text upload, page-by-page flip). Highlight/select tools for words/paragraphs; pop-up side panel for definitions, translations, or explanations.
Workflow: User uploads/navigates document; selects text; AI provides lookups, summaries, or context; supports foreign languages or arcane terms.

6. Goal Tracking/Habit Building Mode
GUI: Dashboard with progress calendars, checklists, streak counters, and reminder notifications. Editable goals with sub-tasks.
Workflow: AI helps set SMART goals via questionnaire; provides daily check-ins; analyzes progress; adjusts plans (combines teaching and walkthrough).

7. Language Learning/Conversation Practice Mode
GUI: Chat with voice input/output, pronunciation feedback, vocabulary flashcards. Immersive scenarios (e.g., virtual cafe dialogue).
Workflow: AI converses in target language; corrects errors in real-time; drills grammar/vocab; tracks fluency progress (blends quiz and teaching).

8. Role-Playing/Simulation Mode
GUI: Character avatars, dialogue bubbles, and scenario timeline. Branching choice buttons for user decisions; environmental descriptions with images.
Workflow: AI sets up scenario (e.g., negotiation, historical event); responds in-character; adapts based on user choices; ends with debrief/analysis.
Data Analysis/Visualization Mode
GUI: Upload zone for datasets; interactive charts/graphs (draggable filters, zoom). Query bar for natural language asks; export buttons.
Workflow: User uploads data; AI suggests visualizations; iterates on queries (e.g., "Show trends in sales"); explains insights step-by-step.

9. General Review Mode
Multi-purpose. Enables direct comparison between source and output, useful for document editing or translation.
Split view: original content on one side, AI’s annotated or summarized outputs on the other.  A stack of user-prompted output from the AI on the review side.
Enables direct comparison between source and output, useful for document editing or translation.


10. Custom Workflow Builder Mode (For Extensibility)
GUI: Drag-and-drop builder for components (e.g., forms, slides, buttons). Preview pane and export/share for mode files.
Workflow: Users/AI define sequences via declarative files (JSON/YAML); describe GUI per step, prompts, and logic; app loads and runs custom modes.

These modes can be mixed (e.g., AI proposes a hybrid of walkthrough + data analysis for a task) or extended via user-uploaded workflow descriptors. A stock set ensures guided, familiar experiences, while allowing AI to assemble novel GUIs from components for unstructured queries.

field-specific modes that professionals (or enthusiasts) in various industries could create, share, or select from a mode marketplace. Each mode dynamically reshapes the GUI, input controls, and AI workflow to match the domain’s tools, terminology, and decision loops. Users upload or download declarative mode files (JSON/YAML) that define steps, prompts, widgets, and validation rules—making the AI a tailored assistant rather than a generic chat.


