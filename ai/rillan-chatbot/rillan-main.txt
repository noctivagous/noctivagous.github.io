
AI Chatbot App : Rillan


Many times, AI chatbots demonstrate some amazing or unexpected approaches,
They might become helpful in pleasantly surprising ways that carry all kinds 
of implications for improving a product or learning about a subject.  
Yet apart from replying to the output, there is no control over this. It 
isn't guided, only responded to.  Put in the Five Elements theory,
it is like Water flowing in any direction that needs Earth to guide it 
and Wood branching out that needs Metal to shape it.

The way that AI chatbots and AI code editors are set up today, they carry out a
large portion of the work without seeking the user's input. Right after the
initial prompt is sent, they venture off on their own and execute. They generate 
large volumes of output and then the user has to inspect and revise what was done. 
Why did it do so much without first presenting some possible paths for what it can do
and what it would like to do, so that the user can direct it somewhat first?  After that, it can
give you plans for what it is about to generate, so that you can avoid undesirable outcomes
and extraneous output. 

Except for the most plain situations, software development is far from an automate-able 
process, because nearly any project carries custom objectives.
At the minimum, the app has to be shaped in terms of details by the 
software developer. These AI code editors aren't set up to recognize this fact, 
that nearly every project has to be tailored along the way, not just at the outset.
Changes are made by software developers in the middle of a project, 
unless it is the most plain kind.  In the current arrangement, the AI models will 
generate lots of unexpected code and insert text without having gathered any additional
information from the user or presented a menu of options. 

It's not the AI models causing this but that there are no intermediate steps or 
preliminary questions programmed into these apps so that they ask the user about what 
path that can be taken before doing anything, certainly before AI's execution happens. 
Doing nothing like this produces an unnecessarily runaway interactive state of AI products.  

When you wrote code in the past without AI, you dealt 
with all of the implications of the program at every step.  But when the AI makes the 
code, you are currently left out of too many details and, while generating more code
than you would write yourself, it decides many implementation details without 
asking you anything.  The software developer has to be able to make decisions again
in the entire process of building the app and never feel like something was taken out
of his hands.  This isn't limited to the AI code editor making code but applies generally 
to how people make use of calls to AI models for interactive applications, mostly
the AI chatbot.

The goal of Rillan is to introduce preliminary and intermediate steps inside the current convention
for engaging with AI, to make an altogether different AI sequence.  One or more questions 
often will be asked by the AI before it gives a response.  In the form of menus, the 
AI offers a decision tree for the user to traverse before it goes about
generating information or executing tasks.  The user can intervene, modify, backtrack,
or move the direction of the AI at any point of a chat sequence so that the AI is
providing guidance while not taking the reins.  

There are questions that come up when intermediate menus are a key part of interacting
with the software.  When should the chatbot asked short questions to get quick answers
and move on quickly? When is the user prompting it in situations where it should 
gather information?  Long questionnaires might be relevant for big projects and the AI
can offer to generate them.  Filling out forms on websites is tedious, so it cannot 
resemble something that produces drag on the user.  The kinds of menus that come up should 
be appropriate to the situation and accepted by the user.  While the AI should provide
menus with paths for a project that are fitting, the user shouldn't be confined to what 
the AI asks in those menus either and then have to start over. A questionnaire can 
have its questions edited, moved, changed, etc. and a menu can be re-generated by
the user to change the direction that the interaction is going before it goes off
track.

In this software, the AI doesn't just go out and do things unexpectedly but instead
lets the user know what it would do or can. Let's say the user can asks the AI for a 
ways to solve to a problem that is located in a certain document. After the AI examines it,
it can provide a menu of options for how to approach that problem, with the user moving 
through the decision tree or shifting it. A menu tree that is traversed doesn't have to 
disappear after an option is selected but can be kept as part of the history of 
that interaction so that the user can go back to it and branch off and select another 
item to see how that path would work.   When the AI has more conventions placed on
top like this, it moves far away from the undeveloped chat of today, where it only responds
to a query by generating a text response or attempts to do a thing.  There is insertion
of preliminary engagement by the AI before it responds.

It's hard to know all of the things that the AI is doing. Sometimes the user
makes a request and doesn't realize that the thing he or she wants to change in
a file of code is there for a reason or moving it will affect other elements 
or affect the overall goals provided. Right now the AI will just comply with
the request rather than warn the user that it is there for a reason.  It doesn't
ever warn the user about anything before proceeding, which is absurd.
Sometimes the the thing that the user wants is there already and the AI should
mention it. The AI should be told not just to follow what is asked but point out 
first what is happening that makes sense (within the user's rules).  
This addition to AI chatbot software will help avert times when the AI makes 
changes only because the user asked, not because it is what is right for the situation.

The use of preliminary questions and intermediate steps has to be inserted carefully into 
the process so as not to become a drag on the user.  We might establish a convention for 
describing how the AI interacts and also how much interaction time is allowed. Once
this convention is established, the AI can use it on its own to determine how to
answer and what kinds of decision trees to produce.

For a tutorial with fixed path but flexibility in steps (e.g. cooking ingredient
substitution):

Making a Vegan Chocolate Cake

Mutability Goal: 0 
The goal is to make a vegan cake.
So in this case, the recipe item is fixed
and the goal is not mutable.

Mutability of Main Steps to Goal: 3.
The AI is given flexibility for the path
towards the final outcome.  If the value is 0
there is an absolute series of steps.
If the value is 10, it doesn't matter how you
get to the goal.  It does matters how 
you make a vegan chocolate cake but there 
are different ways, so we would set a value
at 3.

Mutability of Materials and Methods Info: 3
You can use an oven but there are other ways to
cook it.  There are a few ingredient substitutions
but not much for vegan chocolate cake.  The
user is able to ask the AI for substitutions.

Generation of Main Steps by AI: 10 
0 is the main steps are determined ahead of 
time, provided to the AI and the AI doesn't alter any steps
provided and just assists in answering questions
along the way.  10 is it can generate the whole thing
by itself.

Feature enabled: 
Allows branching off by user to solve problems 
before coming back. 

User branching reporting: logs any branching off by
user to solve problems so that the process can
be updated.





INCORPORATING PROCESS INTO THE USAGE OF AN LLM WITH AN AI CHATBOT

Today the AI does not ask anything or provide any information to the user as an
intermediate step before responding. Steering AI chatbot responses towards
satisfactory outcomes involves having it first ask questions before answering,
allowing it to present a range of options for a task, project, or request. This
approach gives the user an opportunity to revise or refine what the AI offers the
user before it proceeds to generate information, enabling a more effective sequence
of interaction.  The AI can generate more preliminary menus and intermediate
steps to achieve interactions that fit the dynamic of working with a computer
and AI.

If you hire a landscape designer to improve your property, isn't it an act of
speculation that you would get an outcome you are satisfied with just by saying, 
"come take care of my property"?  Professional landscape designers typically start with a
consultation to understand the client’s goals, lifestyle, aesthetic preferences,
and functional needs (e.g., outdoor entertaining, low maintenance, or
sustainability).  This is a useful analogy, with the client being the AI chatbot
user and the landscape designer being the AI.

Sometimes busy professionals (user) will provide minimal input and just let the
designer (AI) do the rest, but without giving the designer any information, you will
get whatever the person (AI) chooses, for aspects large and small, and if making the
project tailored to your interests is something that in any way matters to you, the
results won't be what you want.  This is highly relevant to using today's AI
software, in which the process exists as if you gave the landscape designer
this prompt: ("Carry out a landscape design project on my property and implement
[this and that feature]").  There is more than just doing the thing that is wanted. 
In the case of today's AI chatbots, only after the project was finished were questions 
asked by the designer (AI) and that is point you (user) started giving the 
landscape designer guidance.  This is in the reverse order, as feedback should
take place from the outset.

When you begin a landscape design project and hire someone, there are books and
materials that can guide you and you can point to them during planning.  Yet, after
opening up a book of portfolio properties the person has finished, you will
still need to interact with the designer you hired, walk along the property
together and discuss different aspects of the project, how it fits your
property. There are many factors for any project, including cost. When getting
started with and planning a project, there is actual back and forth.

Let's consider why this is very important for an AI chatbot to have as well. If
you were to run a simulated computing environment and you were working with an
AI landscape architect, you would expect it ask about your specific goals (e.g.,
low-maintenance plants, outdoor seating) or offer a set of design styles (e.g.,
modern, rustic, native), options for you to choose from before proceeding and
it would produce interactive menu paths that you can traverse.  Just by having
the AI offering you a menu of options you are also being informed, as someone 
who isn't experienced in landscape design.  This is the kind of 
interactive sequence and preliminary the AI needs to take for a user of an 
AI chatbot (or other AI generator-based software) to achieve projects.

Landscape design is often an iterative process. Designers present concepts,
sketches, or 3D renderings and refine them based on client feedback.  The AI
chatbots are not equipped with the types of interaction conventions required to
enable genuine iterative feedback, which has to occur at the beginning, not the
end.

To give another example, at the hairstyle salon or barber shop, usually you will find a
book of examples (called a "lookbook") and you can point to one as a guide for
the hair stylist or barber.  Then, after pointing to that you can be more
specific and the barber will ask you questions too. If instead you say, "do
whatever you think looks good," you could get anything if you don't know the
person.  You won't even know how short the hair will be cut.   An AI would
present you with a sequence of menus and as you make choices, the next menu
and its question(s) will relate to the path you are going down, perhaps showing
you a preview.

In Example 1 below, the user asked for something but was especially vague. 
This triggered the preliminary menu (the setting was turned to 'on'). 


EXAMPLE 1:

User: Talk about Classical Chinese dance. 

AI: What aspect of Classical Chinese
dance would you like me to focus on?

[F] Overview – A general introduction to Classical Chinese dance.

[D] History – The origins and historical development.

[S] Techniques – Key movements, styles, and training methods.

[A] Cultural Significance – Its role in Chinese culture and traditions.

[G] Famous Examples – Notable performers, performances, or pieces.

[H] Learning It – How to get started or resources for beginners.

[J] Comparisons – How it differs from other dance forms.

[K] Modern Adaptations – Contemporary versions or influences.

[L] Other – Specify your own topic in the box: [Text Box].

[Enter] My default - Overview – A general introduction to Classical Chinese
dance.

Press F, D, S, A, G, H, J, K, L, ; to select, or ⏎ to skip.


(Note: In terms of specific features for the menu above, selecting an option does not 
make the menu disappear but rather opens a new tab within the pane and you can 
return to this menu pane and open another option into another tab.)



Before taking action on behalf of the user, the AI should be configured to
collect information on key points.  What it collects will vary from in
quantity and level of generality, from broad to specific, depending on
the context in which it is used.  This ensures that the AI operates with a
clearer understanding of the user's goals and constraints.


There are times when the AI should interject to ask for clarification—when it
encounters ambiguity, incomplete input, or identifies a potential issue
during its process. In other instances, the AI may present a menu or set of
options because the user’s original question has implications that were not
anticipated. Through these interactive sequences, users can guide the AI toward
generating more relevant questions and can revise those questions to better
align with the task at hand.



EXAMPLE 2:

User: Build a calculator.

AI: What kind of calculator would you like to build? This will help me provide a
more accurate response.

Programming Language: [Python] (dropdown menu, includes a dozen programming
languages plus "Other" which makes a text box for entering one manually)

[F] Basic arithmetic - A simple calculator for addition, subtraction,
multiplication, and division.

[D] Scientific - Includes advanced functions like trigonometry, logarithms, and
exponents.

[S] Web-based - An interactive calculator that runs in a web browser.

[A] Mobile app - A calculator designed for smartphones, such as for Android or
iOS.

[G] Command-line - A text-based calculator that runs in the terminal.

[H] Library/module - A reusable code component for calculations in other
programs.

[J] GUI desktop app - A graphical interface calculator for Windows, Mac, or
Linux.

[K] Specify details - Provide more information about features, platform, or
programming language.

[L] Other - Something else not listed here. [Text Box]

[Enter] My default: I was going to suggest building a basic command-line
calculator in Python.

Press F, D, S, A, G, H, J, K, L, ; to select, or Enter to skip.



Whether or not a prompt requires extended interaction depends on its purpose.
Introducing such interactive depth marks the beginning of a genuine process in
AI use, in contrast to the current model, where interaction typically consists
of lengthy responses generated from brief queries. Because the AI lacks
sufficient initial information, its responses often rely on numerous
assumptions. As a result, it may proceed too far into a task before the user can
assess whether the response aligns with the original intent. This forces users
to manually correct the AI’s course—sometimes in painstaking detail—largely
because no questions were asked at the outset. If questions are included at all,
they are typically added at the very end of the response.

Ultimately, the AI is only doing what it was designed to do: generate long-form
answers from limited prompts. The first step toward a more effective model is
the development of an AI chatbot application that incorporates a multi-purpose
interactive form file format. This format should be tailored to each use case in
which the AI must collect preliminary information or ask structured questions to
understand the user's needs and objectives before proceeding.



-------

OVERALL PROCESS FOR THE AI CHATBOT

For queries that require short answers: the user presses submit button that
skips step 1 and goes to step 3. For queries that.


1) PRELIMINARY QUESTIONS

The AI chatbot collects information from the user before generating a response,
ranging from a quick four-item menu list to a multi-page interactive form.  This
is the main point where the user is steering the AI, especially if the forms are
in a mode where they have back-and-forth.



2) PLANS NOTIFICATION

The user should be prepared for what is about to happen.  Since there shouldn't be
many surprises or deviations from what the user would prefer, the AI chatbot 
should inform the user about what it is about to generate or what action it should
perform after it has gathered enough information from the user and other sources.  This
is a preview stage, which can give the user expectations about what is going
to happen (e.g. response length, format, structure) as well as  an opportunity to modify 
the AI's plans just before it carries them out.

In a certain category of sequence, this step would be included.  In a different one
it would be optional.  It might be initiated by the user when he wants to check in 
first and ask, "tell me what you plan to do next."

For steps 1) and 2), the user is offered the opportunity to revise the AI's
trajectory before it proceeds but step 1) is generally the macro or large
trajectory.  For step 1), the user can add or change questions
on a form and answer them while for step 2) the user might change some of the
parameters.  Step 2) is a generally reactive point whereas Step 1) is the initial
instructions that start the path of interaction, wherever it ends up.  This is to
say that the AI is set up for the beginning prompt to serve as the initial 
interaction, not the final blueprint.

Parameters for step 1 inform the AI about what it supposed to do overall and on
details.  Parameters for step 2 inform the AI about how to shape its execution
in response to what it said.

This step is where, if an option is checked, the user can choose to receive
samples of different output, whether it is sets of color schemes, translation
paragraphs, and other things.  If the AI is to translate, it shows how it will.
The user will know how the AI will go about its activities.


3) EXECUTION BY AI

The AI displays a checklist and reports what it is doing by checking off the
list.


3a) POST-GENERATION/POST-PRODUCTION OPTIONS AND ACCESSORY ACTIVITIES

The whole of what the AI carried is not always easily reviewed when it is in large
quantities. So, summaries of what it generated or what actions it performed 
can be provided and this is also when documentation, such as for a software project, 
is made and inserted.  The post-generation stage is the step that assists the user in
reviewing what was generated by the AI.  It is also the time when the user can
make changes in the same kind as post-production for a movie where it is about
effects, fixes, etc.

For a software project where lots of code was generated, a diagram file 
(e.g. MermaidJS) can be generated so that the AI user can get an overview first 
instead of having to read each line of code.




-----

SAMPLES FOR STEP 2, PLANS NOTIFICATION ---

sample a: My response will be about [summary]. It will be this long: [slider].

Here are the sections I'm about to generate. [[accordion] (Change, reorder, add,
delete any).]

[Here are the tasks I'm about to carry out. [list view] (Change, reorder, add,
delete any).]


sample b: (user has pressed button for one sentence reply): [My one sentence
response is: [...]]

buttons:[Continue with elaboration]  [OK, That's all.]] ---

sample c: (user has pressed button for one paragraph reply): [ My one paragraph
response is: [...] ] buttons: [Continue with elaboration]  [OK, That's all.]]


-----

RESPONSE paths

Walkthrough

User: Walk me through [example:] concepts of the Java programming Language.

AI Replies with Possible Response Paths: ---> Slideshow. ---> What is your
familiarity level? ---> Detail level? ---> Topics to start (check off one):


SAMPLE


After a response, the AI generates a series of collapsed accordions with titles
and short descriptions.  They are all editable before opening with the "Edit"
button. After opening one of them, the AI starts to generate a response for that
section and fills it in.  This offers the user the option to get responses
formatted as collapsed, empty accordion list items with section headings.  This
way the user can choose which sections to open and when the section is opened
only then does the AI generate the information.


EMPHASIS ON THE QUALITY CONTROL AND EVALUATION PROCEDURES

The AI makes basic mistakes and cannot identify them afterwards. It will try to
write an app or program and never recognize that the GUI, for example, doesn't
work, because it hasn't been hooked up to analyze it.  Although this will be
addressed by having the person interact with menus, it also means there should
be ways for the AI to evaluate what it did.

While an LLM might write a complex app, the end product may not be practical or
user-friendly without human refinement. Their contemplation of usability has to
be hooked into the final results.

------

FOR A SOFTWARE DEVELOPMENT AI AGENT

What do you want made?
	- Your product requirements.
	- What you want it to look like.

How do you want it made?
	- What programming language?
	- What platform?
	- What programming frameworks/libraries?
	- What programming techniques and philosphies?



