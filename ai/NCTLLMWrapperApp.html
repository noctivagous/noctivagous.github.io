<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=xmWzHJTNiUVlXcM2Up20hL6ZyzhbtwSwefhGRLY_DJ0);.lst-kix_43s5gz7t7f5m-5>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-5}.lst-kix_i691tfqtkrqh-5>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-5}.lst-kix_dtsavrrdqo0t-0>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-0}.lst-kix_i691tfqtkrqh-6>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-6}.lst-kix_43s5gz7t7f5m-6>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-6}ol.lst-kix_i691tfqtkrqh-6.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-6 0}.lst-kix_dtsavrrdqo0t-2>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-2,lower-roman) ") "}ul.lst-kix_yii9rdili81k-0{list-style-type:none}.lst-kix_dtsavrrdqo0t-3>li:before{content:"(" counter(lst-ctn-kix_dtsavrrdqo0t-3,decimal) ") "}ul.lst-kix_yii9rdili81k-1{list-style-type:none}ul.lst-kix_yii9rdili81k-2{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-7{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-8{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-3.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-3 0}.lst-kix_dtsavrrdqo0t-1>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-1,lower-latin) ") "}ol.lst-kix_43s5gz7t7f5m-1{list-style-type:none}.lst-kix_dtsavrrdqo0t-0>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-0,decimal) ") "}ol.lst-kix_43s5gz7t7f5m-2{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-0{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-5{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-6{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-3{list-style-type:none}.lst-kix_i691tfqtkrqh-3>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-3}ol.lst-kix_43s5gz7t7f5m-4{list-style-type:none}.lst-kix_i691tfqtkrqh-0>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-0,decimal) ") "}.lst-kix_i691tfqtkrqh-1>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-1,lower-latin) ") "}.lst-kix_dtsavrrdqo0t-1>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-1}ol.lst-kix_43s5gz7t7f5m-0.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-0 0}.lst-kix_i691tfqtkrqh-8>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-8}.lst-kix_i691tfqtkrqh-6>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-6,decimal) ". "}.lst-kix_i691tfqtkrqh-8>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-8,lower-roman) ". "}.lst-kix_i691tfqtkrqh-2>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-2}.lst-kix_i691tfqtkrqh-5>li:before{content:"(" counter(lst-ctn-kix_i691tfqtkrqh-5,lower-roman) ") "}ol.lst-kix_dtsavrrdqo0t-7.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-7 0}.lst-kix_i691tfqtkrqh-3>li:before{content:"(" counter(lst-ctn-kix_i691tfqtkrqh-3,decimal) ") "}.lst-kix_dtsavrrdqo0t-4>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-4}.lst-kix_i691tfqtkrqh-2>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-2,lower-roman) ") "}.lst-kix_i691tfqtkrqh-4>li:before{content:"(" counter(lst-ctn-kix_i691tfqtkrqh-4,lower-latin) ") "}ol.lst-kix_dtsavrrdqo0t-3.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-3 0}ol.lst-kix_i691tfqtkrqh-7.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-7 0}ol.lst-kix_i691tfqtkrqh-1{list-style-type:none}.lst-kix_dtsavrrdqo0t-3>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-3}ol.lst-kix_i691tfqtkrqh-2{list-style-type:none}ol.lst-kix_i691tfqtkrqh-0{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-6.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-6 0}ol.lst-kix_i691tfqtkrqh-5{list-style-type:none}ol.lst-kix_i691tfqtkrqh-6{list-style-type:none}ol.lst-kix_i691tfqtkrqh-3{list-style-type:none}ol.lst-kix_i691tfqtkrqh-4{list-style-type:none}ol.lst-kix_i691tfqtkrqh-1.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-1 0}ol.lst-kix_i691tfqtkrqh-7{list-style-type:none}ol.lst-kix_i691tfqtkrqh-8{list-style-type:none}.lst-kix_i691tfqtkrqh-7>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-7,lower-latin) ". "}.lst-kix_dtsavrrdqo0t-4>li:before{content:"(" counter(lst-ctn-kix_dtsavrrdqo0t-4,lower-latin) ") "}ul.lst-kix_yii9rdili81k-3{list-style-type:none}.lst-kix_yii9rdili81k-6>li:before{content:"\0025cf   "}ul.lst-kix_yii9rdili81k-4{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-0{list-style-type:none}.lst-kix_yii9rdili81k-5>li:before{content:"\0025a0   "}ul.lst-kix_yii9rdili81k-5{list-style-type:none}.lst-kix_yii9rdili81k-7>li:before{content:"\0025cb   "}ul.lst-kix_yii9rdili81k-6{list-style-type:none}.lst-kix_43s5gz7t7f5m-1>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-1}ul.lst-kix_yii9rdili81k-7{list-style-type:none}ul.lst-kix_yii9rdili81k-8{list-style-type:none}.lst-kix_dtsavrrdqo0t-5>li:before{content:"(" counter(lst-ctn-kix_dtsavrrdqo0t-5,lower-roman) ") "}ol.lst-kix_dtsavrrdqo0t-6{list-style-type:none}.lst-kix_dtsavrrdqo0t-8>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-8,lower-roman) ". "}ol.lst-kix_dtsavrrdqo0t-5{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-8{list-style-type:none}.lst-kix_yii9rdili81k-1>li:before{content:"\0025cb   "}ol.lst-kix_dtsavrrdqo0t-7{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-2{list-style-type:none}.lst-kix_dtsavrrdqo0t-6>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-6,decimal) ". "}.lst-kix_yii9rdili81k-0>li:before{content:"\0025cf   "}.lst-kix_yii9rdili81k-8>li:before{content:"\0025a0   "}ol.lst-kix_dtsavrrdqo0t-1{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-4{list-style-type:none}.lst-kix_dtsavrrdqo0t-7>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-7,lower-latin) ". "}ol.lst-kix_dtsavrrdqo0t-3{list-style-type:none}ol.lst-kix_i691tfqtkrqh-0.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-0 0}ol.lst-kix_43s5gz7t7f5m-5.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-5 0}ol.lst-kix_dtsavrrdqo0t-8.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-8 0}ol.lst-kix_dtsavrrdqo0t-2.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-2 0}.lst-kix_yii9rdili81k-2>li:before{content:"\0025a0   "}.lst-kix_yii9rdili81k-3>li:before{content:"\0025cf   "}.lst-kix_43s5gz7t7f5m-7>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-7}.lst-kix_yii9rdili81k-4>li:before{content:"\0025cb   "}.lst-kix_43s5gz7t7f5m-4>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-4}.lst-kix_43s5gz7t7f5m-0>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-0,decimal) ". "}ol.lst-kix_i691tfqtkrqh-2.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-2 0}.lst-kix_43s5gz7t7f5m-1>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-1,lower-latin) ". "}ol.lst-kix_43s5gz7t7f5m-7.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-7 0}.lst-kix_dtsavrrdqo0t-7>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-7}.lst-kix_43s5gz7t7f5m-0>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-0}.lst-kix_43s5gz7t7f5m-6>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-6,decimal) ". "}.lst-kix_43s5gz7t7f5m-5>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-5,lower-roman) ". "}ol.lst-kix_dtsavrrdqo0t-1.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-1 0}ol.lst-kix_43s5gz7t7f5m-4.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-4 0}.lst-kix_43s5gz7t7f5m-2>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-2,lower-roman) ". "}.lst-kix_43s5gz7t7f5m-4>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-4,lower-latin) ". "}.lst-kix_dtsavrrdqo0t-6>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-6}.lst-kix_43s5gz7t7f5m-3>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-3,decimal) ". "}ol.lst-kix_i691tfqtkrqh-8.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-8 0}ol.lst-kix_dtsavrrdqo0t-6.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-6 0}ol.lst-kix_dtsavrrdqo0t-4.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-4 0}.lst-kix_43s5gz7t7f5m-7>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-7,lower-latin) ". "}.lst-kix_i691tfqtkrqh-0>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-0}.lst-kix_43s5gz7t7f5m-8>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-8,lower-roman) ". "}ol.lst-kix_i691tfqtkrqh-5.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-5 0}ol.lst-kix_43s5gz7t7f5m-2.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-2 0}ol.lst-kix_dtsavrrdqo0t-0.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-0 0}.lst-kix_43s5gz7t7f5m-2>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-2}.lst-kix_43s5gz7t7f5m-8>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-8}.lst-kix_43s5gz7t7f5m-3>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-3}ol.lst-kix_i691tfqtkrqh-4.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-4 0}.lst-kix_dtsavrrdqo0t-8>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-8}ol.lst-kix_i691tfqtkrqh-3.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-3 0}.lst-kix_dtsavrrdqo0t-5>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-5}ol.lst-kix_43s5gz7t7f5m-1.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-1 0}ol.lst-kix_43s5gz7t7f5m-8.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-8 0}.lst-kix_i691tfqtkrqh-1>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-1}.lst-kix_dtsavrrdqo0t-2>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-2}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_i691tfqtkrqh-4>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-4}.lst-kix_i691tfqtkrqh-7>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-7}ol.lst-kix_dtsavrrdqo0t-5.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-5 0}ol{margin:0;padding:0}table td,table th{padding:0}.c4{background-color:#ffffff;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Calibri";font-style:normal}.c16{color:#434343;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c19{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c15{color:#000000;font-weight:800;text-decoration:none;vertical-align:baseline;font-size:22pt;font-family:"Lexend";font-style:normal}.c10{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c14{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c20{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c18{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c1{font-weight:400;font-family:"Courier New"}.c13{background-color:#ffffff;font-size:12pt}.c7{padding:0;margin:0}.c5{height:11pt}.c11{margin-left:72pt}.c12{text-indent:36pt}.c9{padding-left:0pt}.c17{margin-left:108pt}.c6{margin-left:36pt}.title{padding-top:20pt;color:#000000;font-weight:800;font-size:20pt;padding-bottom:6pt;font-family:"Lexend";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-weight:700;font-size:26pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c18 doc-content"><p class="c14 title" id="h.emk9phg3spnz"><span class="c15">NCT LLM Wrapper App</span></p><p class="c0 c5"><span class="c4"></span></p><h1 class="c14" id="h.1vnt12m339id"><span>OVERVIEW</span></h1><p class="c0 c5"><span class="c4"></span></p><h2 class="c10" id="h.6g5i43wox9vs"><span class="c8">Beyond The Chatbot Format</span></h2><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c4">This future application is intended to provide a user-friendly and flexible environment for users to interact with LLMs by building out a more complete app experience, expanding the number of available controls and conventions for generating prompts and interacting with chat responses, providing the user a broader set of tools that interface to AI.</span></p><p class="c0 c5"><span class="c4"></span></p><p class="c0"><span class="c13">First, the chat prompt area is not limited to typing out prompts from scratch. &nbsp;To the left is a panel with a list of template commands for prompts that once clicked on will insert them into the chat prompt input box. This gives the user some direction from the outset instead of just an empty text box. &nbsp;Example template commands include the commonly used </span><span class="c1">SUMMARIZE: [TEXT DATA]</span><span>&nbsp; but also </span><span class="c1">SUGGEST ADDITIONS FOR:[TEXT DATA]</span><span>, </span><span class="c1">SUGGEST MODIFICATIONS FOR:[TEXT DATA],</span><span>&nbsp;</span><span class="c1">MAKE OUTLINE OF:[TEXT DATA]</span><span>&nbsp;and </span><span class="c1">COMPARE [TEXT DATA] WITH [TEXT DATA]</span><span>. &nbsp;There are many commands people use with AI chatbots and these can be included in the library. &nbsp;The template command </span><span class="c1">COMPARE [TEXT DATA] WITH [TEXT DATA]</span><span>&nbsp;a</span><span>llows comparing details of two similar products, to give an example.</span></p><p class="c0 c5"><span class="c4"></span></p><p class="c0"><span class="c4">The chat responses are not just static text for the Control+C operation but instead</span></p><ol class="c7 lst-kix_43s5gz7t7f5m-0 start" start="1"><li class="c0 c9 c11 li-bullet-0"><span class="c4">Are editable by the user (where they sit) with an inline text editor activated by the user.</span></li><li class="c0 c11 c9 li-bullet-0"><span class="c4">Can be transformed by AI (where they sit), replaced with another response by the user with a modifying prompt.</span></li></ol><ol class="c7 lst-kix_43s5gz7t7f5m-1 start" start="1"><li class="c0 c9 c17 li-bullet-0"><span class="c4">These modifying prompts can be made with convenience functions.</span></li></ol><ol class="c7 lst-kix_43s5gz7t7f5m-0" start="3"><li class="c0 c11 c9 li-bullet-0"><span class="c4">Can be deleted from the chat sequence.</span></li><li class="c0 c11 c9 li-bullet-0"><span class="c4">Can be moved out of the chat sequence into a different chat sequence or a separate project bin/folder.</span></li></ol><p class="c0 c5"><span class="c4"></span></p><p class="c0 c5"><span class="c4"></span></p><p class="c0 c5"><span class="c4"></span></p><p class="c0"><span class="c4">Instead of just watching every additional response appended to a long, scrollable list of chat responses, the user has other options for working with the AI output and prompts. &nbsp;He can stay with and revise a single AI response, which means there are interface options to edit the text that was generated and change it with AI repeatedly (in any combination). &nbsp;This adds a requirement that there is an undo manager attached to each chat response text area. &nbsp;</span></p><p class="c0 c5"><span class="c4"></span></p><p class="c0"><span class="c4">By providing a collection of revision tools in-line for engaging with an LLM, the user can effectively shape prompts, reshape output, and prepare the results for its eventual destination, which may be a document or project of some sort.</span></p><p class="c0 c5"><span class="c4"></span></p><p class="c0"><span class="c4">At the tail of each chat response is a set of controls for making revisions or relevant follow-up responses, such as &ldquo;REVISE to Include [TEXT] &amp; Exclude [TEXT]&rdquo;. &nbsp;In the context window of the prompt is included an instruction to provide suggested follow-up responses.</span></p><p class="c0 c5"><span class="c4"></span></p><p class="c0"><span class="c4">The general chat settings include omitting any introductions and conclusions. &nbsp;Modes include generating output that does not contain any lists and is only prose. &nbsp;By controlling the output of an LLM and using tools that can make use of it, this very broad technology can be experienced more powerfully than the current, plain interactive chatbot format.</span></p><p class="c0 c5"><span class="c4"></span></p><p class="c0"><span class="c4">To begin with and the first requirement when building this app is that the tokens as they come in are placed inside a multiple column layout (like a newspaper or magazine) so that little or no scrolling is required to read the output. &nbsp;The volume of text output in the response will be controlled with a slider control that ranges from &ldquo;paragraph&rdquo; to &ldquo;multiple pages.&rdquo;</span></p><p class="c0 c5"><span class="c4"></span></p><h2 class="c10" id="h.ny5731r4ujk6"><span>General </span><span class="c8">Goals of the App</span></h2><p class="c0 c5"><span class="c4"></span></p><ul class="c7 lst-kix_yii9rdili81k-0 start"><li class="c0 c9 c6 li-bullet-0"><span class="c4">Provide control over and conveniences for formulating the initial prompt. </span></li><li class="c0 c9 c6 li-bullet-0"><span class="c4">Making it easier and more accessible to make useful prompts with template prompts</span></li><li class="c0 c9 c6 li-bullet-0"><span class="c4">Letting the user control the quantity of text, style of the output and data format coming from the AI</span></li><li class="c0 c6 c9 li-bullet-0"><span class="c4">Placing the AI&rsquo;s API response into a page design layout that demands little scrolling from the user as it fills up. It should also permit an overview presentation of all chat responses and collections of chat responses.</span></li><li class="c0 c9 c6 li-bullet-0"><span class="c4">Conveniences for revision of output.</span></li></ul><p class="c0 c5"><span class="c4"></span></p><p class="c0 c5"><span class="c4"></span></p><h1 class="c14" id="h.20ekzh4yyetp"><span class="c3">MORE SPECIFICATIONS</span></h1><h2 class="c10" id="h.ytdowhia1l0j"><span class="c8">OUTPUT LAYOUT AND CONTROLS</span></h2><p class="c0 c5 c6"><span class="c2"></span></p><ol class="c7 lst-kix_dtsavrrdqo0t-0 start" start="1"><li class="c0 c9 c6 li-bullet-0"><span class="c2">By default, so that all text can be evaluated by the user as it arrives, text received by the LLM is fed into multiple text container columns, magazine/newspaper style, with 3 columns set by default.</span></li><li class="c0 c9 c6 li-bullet-0"><span class="c2">An option is provided to feed generated text into a clipped, portrait (8.5&rdquo; x 11&rdquo; or 1:1.294) text area that has been scaled down to 70%. &nbsp;The text area will have scrollbars appear on overflow.</span></li><li class="c0 c9 c6 li-bullet-0"><span class="c2">Chat responses can be viewed as a set if grid items, each at 50% scale.</span></li><li class="c0 c9 c6 li-bullet-0"><span class="c2">A slider is made prominent for the chat output length, above or to the side of the chat input box, with markings going from &ldquo;paragraph&rdquo; to &ldquo;several pages&rdquo;.</span></li><li class="c0 c9 c6 li-bullet-0"><span class="c2">Chat responses can be collapsed accordion-style inside the chat sequence. They can also be deleted from a chat sequence, to allow clearing out irrelevant chat responses. &nbsp;All chat responses can be edited and reordered.</span></li></ol><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">The chat input box is placed at the top of the window instead of the bottom. &nbsp;It allows insertion of rich text, including tables and coloring of computer code. It can expand to the height of the viewport (the browser/window height).</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5 c6"><span class="c2"></span></p><h2 class="c10" id="h.8sr8hrjbiw7u"><span class="c8">CHAT RESPONSES ARE TREATED AS DYNAMIC UI OBJECTS, EXIST AS NOTEBOOK CLIPPINGS</span></h2><p class="c0 c5 c6"><span class="c2"></span></p><ol class="c7 lst-kix_dtsavrrdqo0t-0" start="6"><li class="c0 c9 c6 li-bullet-0"><span class="c2">Chat responses will not be fixed and immutable like they are today, requiring copy and paste to change or make use of them. &nbsp;Their essential state at the code level is a notebook clipping that can be moved around and edited by the user in the chat window. &nbsp;</span></li></ol><p class="c0 c11"><span class="c2">. </span></p><ol class="c7 lst-kix_dtsavrrdqo0t-1 start" start="1"><li class="c0 c11 c9 li-bullet-0"><span class="c2">Chat responses can be transformed by the user in-line in multiple ways. First,hey can be modified by applying another chat operation to them, with the operations accessed by a menu at the bottom of the chat response. &nbsp;In other words, the LLM&rsquo;s API will operate on the chat response itself it just gave inside its container according to what the user has requested, whether it is a transformation of data state or copy revision. That is, it will transform the data inside the response text control and replace the previous text. &nbsp;</span></li></ol><ol class="c7 lst-kix_dtsavrrdqo0t-2 start" start="1"><li class="c0 c9 c17 li-bullet-0"><span class="c2">In terms of content, the user can instruct any number of changes to be applied by the AI. </span></li><li class="c0 c9 c17 li-bullet-0"><span class="c2">In terms of data format it might be transformed into or from a table, a list, paragraph form.</span></li></ol><p class="c0 c11"><span class="c2">The text area that contains a chat response can be changed back and forth from static text (as it is everywhere today) into a text editing control so that the user can make successive transformations inside the chat response and get the outcome he or she wants. &nbsp;The person may edit the response then apply another AI operation to the text and so on. &nbsp;Accordingly, there is an undo manager attached to each chat response box, a history of changes, so that the user can go back. &nbsp; When the user is finished, the chat response, existing fundamentally as a notebook clipping at all times, can be moved to a bin inside the app, it can be e-mailed, etc. or downloaded in any format for permanent storage. &nbsp;Each chat response notebook clipping has a download control with options for download format so that this does not have to be the same as the contents of the chat clipping itself.</span></p><ol class="c7 lst-kix_dtsavrrdqo0t-1" start="2"><li class="c0 c11 c9 li-bullet-0"><span class="c2">Notebook clippings are not tied to a single chat window but can be moved into bins. &nbsp;A chat session is a list of editable text controls that can be reordered, revised, and copy-edited so that it is exportable to file to serve as the basis of an eventual document for the user.</span></li></ol><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><h2 class="c10" id="h.prblm1q59vsq"><span class="c8">CHAT OUTPUT TAIL MENU: FOLLOW UP COMMANDS</span></h2><p class="c0"><span class="c2">For each response, the AI is asked to make a list (which is placed inside a dropdown menu) at the end of each chat response with five possible follow-up requests, and this allows context-specific operations to occur by the user. &nbsp;In the UI beneath each chat response is a standard set of operations for follow-up requests as well.</span></p><p class="c0"><span class="c2">- A menu appears at the bottom of every chat response</span></p><p class="c0"><span class="c2">allowing the user to modify the original prompt </span></p><p class="c0"><span class="c2">or respond to the chat. &nbsp;This includes the AI-generated modification prompts provided inside the response that are specific to it as well as the standard ones.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><h2 class="c10" id="h.at1wiqwv4eh8"><span class="c8">BUILDING LLM PROMPTS</span></h2><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">-- Rectangular building blocks components replace typewritten</span></p><p class="c0"><span class="c2">prompts. &nbsp;Each component contains GUI controls for its parameters</span></p><p class="c0"><span class="c2">and is around 200 pt x 200 pt. &nbsp;When there is more than one they </span></p><p class="c0"><span class="c2">flow like text. &nbsp;A prompt is made out</span></p><p class="c0"><span class="c2">of one or more of these building blocks.</span></p><p class="c0"><span class="c2">Each building block makes up the prompt, allowing rapid</span></p><p class="c0"><span class="c2">construction of parametric prompts rather than just verbal ones.</span></p><p class="c0"><span class="c2">The container for making a prompt out of these components </span></p><p class="c0"><span class="c2">can be made as large as a page.</span></p><p class="c0"><span class="c2">-- The AI itself can be requested to make relevant prompts</span></p><p class="c0"><span class="c2">and this will be incorporated into the app.</span></p><p class="c0 c5"><span class="c2"></span></p><h2 class="c10" id="h.umikz57lcqwy"><span class="c8">STANDARD APP SOFTWARE FUNCTIONALITY</span></h2><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">- Export contents of selected output control</span></p><p class="c0"><span class="c2">to document, .RTF, .PDF, .TXT, .CSV, .XLSX.</span></p><p class="c0"><span class="c2">- AI-generated tabular data appears as interactive table</span></p><p class="c0"><span class="c2">in the app.</span></p><p class="c0"><span class="c2">- AI-generated map data appears on an interactive map.</span></p><p class="c0"><span class="c2">- Print selected output control.</span></p><p class="c0"><span class="c2">- Functions for reformatting data output are provided.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><h2 class="c10" id="h.40s79vlypt91"><span class="c8">PROMPT KEYWORDS COMBINED WITH PASTE AREAS AND DROPDOWN MENUS</span></h2><p class="c0 c5 c6"><span class="c2"></span></p><p class="c0 c6"><span class="c2">CONTINUE: [PASTE AREA]</span></p><p class="c0 c6"><span class="c2">EXPLAIN: [PASTE AREA]</span></p><p class="c0 c6"><span class="c2">REACT TO: [PASTE AREA]</span></p><p class="c0 c6"><span class="c2">COMPARE: [PASTE AREA 1] &nbsp;TO [PASTE AREA2]</span></p><p class="c0 c6"><span class="c2">COMPARE: [TABLE CONTROL WITH PASTE CAPABILITIES]</span></p><p class="c0 c6"><span class="c2">EXPAND ON CONTENTS OF TEXT:</span></p><p class="c0 c6"><span class="c2">SUMMARIZE:</span></p><p class="c0 c6"><span class="c2">SUGGEST MODIFICATIONS:</span></p><p class="c0 c6"><span class="c2">SUGGEST ADDITIONS:</span></p><p class="c0 c6"><span class="c2">VERIFY FACTUALITY:</span></p><p class="c0 c6"><span class="c2">CHANGE [TONE/VOICE/PERSPECTIVE]:</span></p><p class="c0 c6"><span class="c2">LIST INSTANCES OF [PASTE AREA] FROM:</span></p><p class="c0 c6"><span class="c2">MAKE OUTLINE OF:</span></p><p class="c0 c5 c6"><span class="c2"></span></p><p class="c0 c6"><span class="c2">MAKE SUGGESTIONS FOR HOW TO CARRY OUT:</span></p><p class="c0 c6 c12"><span class="c4">suggest the beginning steps of the first part to carry this out</span></p><p class="c0 c12 c6"><span class="c4">Make up specifics</span></p><p class="c0 c6"><span class="c2">OUTLINE THE STEPS [TO CARRY OUT]...</span></p><p class="c0 c6"><span class="c2">PROVIDE PLANNING [HOW TO CARRY OUT A CHORE OR TASK]:</span></p><p class="c0 c6"><span class="c2">DIAGNOSE PROBLEM:</span></p><p class="c0 c6"><span class="c2">SUGGEST SOLUTIONS FOR PROBLEM:</span></p><p class="c0 c5 c6"><span class="c2"></span></p><p class="c0 c6"><span class="c2">PROMPT REVISION&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FUNCTIONALITY</span></p><p class="c0 c6"><span class="c2">- Qualities: add [more or less] of [quality].</span></p><p class="c0 c5 c6"><span class="c2"></span></p><p class="c0 c6"><span class="c2">MAKE ANALOGY FOR: [PASTE AREA]</span></p><p class="c0 c6"><span class="c2">RELATE [PASTE AREA] TO [PASTE AREA]</span></p><p class="c0 c6"><span class="c2">CONTRAST [PASTE AREA] WITH [PAST AREA]</span></p><p class="c0 c5 c6"><span class="c2"></span></p><p class="c0 c6"><span class="c19">GENERATION</span></p><p class="c0 c6"><span class="c2">Make a template for</span></p><p class="c0 c6"><span class="c2">FILL IN THE FOLLOWING TEMPLATE [PASTE AREA] WITH THIS DATA [PASTE AREA 2]</span></p><p class="c0 c6"><span class="c2">ANALYZE AND APPLY HEADING STYLES TO THE FOLLOWING TEXT [PASTE AREA] &nbsp; [ [X] WITH FONT: [Arial] ]</span></p><p class="c0 c5"><span class="c2"></span></p><h3 class="c20" id="h.jedx2w4xjrxx"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REFINEMENT</span></h3><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OMIT</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INCLUDE</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;EXCLUDE</span></p><h2 class="c10" id="h.yby2j290n6s4"><span class="c8">PROMPT KEYWORD COMMANDS + CONTROLS IN JSON</span></h2><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">// Order of array contents matters for each prompt command because</span></p><p class="c0"><span class="c2">Compare PasteArea1 With PasteArea2 &nbsp;is four separate objects in sequence.</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c0"><span class="c2">promptKeywordCommands = [{</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compare = {[ {&ldquo;CommandText&rdquo; = &ldquo;COMPARE&rdquo;}, {&ldquo;UIControl&rdquo; = &ldquo;TextAreaRichText&rdquo;}, &nbsp;{&ldquo;CommandText&rdquo; = &ldquo;WITH&rdquo;} {&ldquo;UIControl&rdquo; = &ldquo;TextAreaRichText&rdquo; }]},</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">]</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><h2 class="c10" id="h.jhld2bibjp8c"><span class="c8">CONTROLS USED IN THE APP:</span></h2><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">RICH TEXT CONTROL</span></p><p class="c0"><span class="c2">TABLE CONTROL</span></p><p class="c0"><span class="c2">PLAIN TEXT CONTROL</span></p><p class="c0"><span class="c2">CODE EDITOR CONTROL WITH HIGHLIGHTING</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><h2 class="c10" id="h.584jlljjfssv"><span class="c8">FIRST VERSION</span></h2><p class="c0 c5"><span class="c2"></span></p><ol class="c7 lst-kix_i691tfqtkrqh-0 start" start="1"><li class="c0 c9 c6 li-bullet-0"><span class="c2">TEXT BOX AT TOP</span></li><li class="c0 c9 c6 li-bullet-0"><span class="c2">FEED GENERATED AI TEXT INTO THREE COLUMNS.</span></li></ol><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><h2 class="c10" id="h.v76k6n1preie"><span class="c8">BOOLEAN OPTIONS</span></h2><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">[ &nbsp;] RESPONSE IS HTML WITH RELEVANT HYPERLINKS EMBEDDED THROUGHOUT</span></p><p class="c0"><span class="c2">[ &nbsp;] MAKE LIST OF REFERENCES WITH HYPERLINKS AT BOTTOM</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><h2 class="c10" id="h.43tcb7rtlsjv"><span class="c8">AICHATPROMPT:// URL HYPERLINKS IN CHAT RESPONSES</span></h2><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">EMBEDS OF AICHATPROMPT:// HYPERLINKS THROUGHOUT TEXT ALLOW THE USER TO CLICK ON WORDS, PHRASES, AND PARAGRAPHS CHOSEN BY THE AI THAT WILL EXPAND ON THOSE TOPICS IN A SEPARATE RESPONSE.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><h1 class="c14" id="h.p4c59t1oxr6s"><span class="c3">PREVIOUS ARTICLE</span></h1><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">MAKING THE LLM GO MAINSTREAM</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">A Versatile, Fully-Developed, General Use</span></p><p class="c0"><span class="c2">Software Application Suite </span></p><p class="c0"><span class="c2">Acting As An LLM Wrapper Is How</span></p><p class="c0"><span class="c2">Current AI Technology Can Finally </span></p><p class="c0"><span class="c2">Be Adopted By The Public</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">noctivagous.github.io</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">The potential and utility of an LLM is still hidden.</span></p><p class="c0"><span class="c2">A much more developed category of wrapper app for an LLM</span></p><p class="c0"><span class="c2">should be the priority of the AI community, one that goes</span></p><p class="c0"><span class="c2">beyond the basic AI chat format in which the user is</span></p><p class="c0"><span class="c2">given a free-form textbox and responses are stacked vertically. &nbsp;</span></p><p class="c0"><span class="c2">Interacting with the LLM is confined to typing out prompts from scratch</span></p><p class="c0"><span class="c2">each time; there is no developed workflow for modifying</span></p><p class="c0"><span class="c2">prompts, crafting them parametrically, or viewing the </span></p><p class="c0"><span class="c2">output in different views or presentations. &nbsp;There are </span></p><p class="c0"><span class="c2">many uses for an LLM but the user is supposed to reduce </span></p><p class="c0"><span class="c2">them into a text box. Whatever comes out is supposed to </span></p><p class="c0"><span class="c2">suffice if it is just a stream of text, a chat response.</span></p><p class="c0"><span class="c2">Few genuinely sophisticated features have </span></p><p class="c0"><span class="c2">been provided on the front-end to serve the end user, </span></p><p class="c0"><span class="c2">at least by the major AI vendors.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">The new user is placed in front of the text box and then</span></p><p class="c0"><span class="c2">told, &quot;Now go! Ask for whatever you want!&quot; which sounds great at first, like an opportunity to interact with a genie in a bottle. &nbsp;In reality, instructions for work jobs are more complex</span></p><p class="c0"><span class="c2">than discrete and simple requests made out of sentences. They have</span></p><p class="c0"><span class="c2">parameters, settings, modes that surround the request the person</span></p><p class="c0"><span class="c2">is making. &nbsp;In addition to this, the person should be surrounded</span></p><p class="c0"><span class="c2">by available resources such as the images, documents, and snippets</span></p><p class="c0"><span class="c2">of text he wants to make use of with this machine.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">Current AI technology cannot succeed by way of simplistic chat-formatted responses</span></p><p class="c0"><span class="c2">generated from an LLM. &nbsp;After all, in the workplace a person is provided</span></p><p class="c0"><span class="c2">a complete document of specifications to carry out a job, not just a few sentences. </span></p><p class="c0"><span class="c2">The analogue to this for an LLM would be a set of parametric components, </span></p><p class="c0"><span class="c2">settings, controls, and areas for stored resources that can be included in</span></p><p class="c0"><span class="c2">the queries. &nbsp;The queries themselves need to be made in different ways,</span></p><p class="c0"><span class="c2">whether it is typing them out or wiring them up.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">The &quot;genie in a bottle&quot; format in which the person gets a wish</span></p><p class="c0"><span class="c2">granted with a sentence, its response format in which the person</span></p><p class="c0"><span class="c2">clarifies or corrects the response provided is limited and</span></p><p class="c0"><span class="c2">contrasts with the natural condition of everyday life in which a </span></p><p class="c0"><span class="c2">set of commands comes in structured, in bulk, and may (as in the</span></p><p class="c0"><span class="c2">case of specifications) have charts and other non-verbal descriptions</span></p><p class="c0"><span class="c2">of the demands.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">When you want something complex done do you tell a person who doesn&#39;t know you </span></p><p class="c0"><span class="c2">just one line or a few sentences? &nbsp;Will it all be verbal information?</span></p><p class="c0"><span class="c2">No, you send them a document with detailed specifications and it may have</span></p><p class="c0"><span class="c2">a table included. &nbsp;So the LLM has to be able to receive</span></p><p class="c0"><span class="c2">commands in all kinds of ways and the only way to do that is to provide</span></p><p class="c0"><span class="c2">a complete suite for input settings, input methods and output setting</span></p><p class="c0"><span class="c2">and output methods. &nbsp;What should be part of any query would be</span></p><p class="c0"><span class="c2">a bundle of things and the app makes this possible.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">The small LLM text box amounts to a prototypal, unfinished situation</span></p><p class="c0"><span class="c2">in which the user laboriously starts from scratch each time to compose</span></p><p class="c0"><span class="c2">short prompts, writing instructions out all over again for every minor tweak</span></p><p class="c0"><span class="c2">when something wasn&#39;t quite right, writing paragraphs of prose and </span></p><p class="c0"><span class="c2">complete sentences for every revised interaction. &nbsp;Because the LLM </span></p><p class="c0"><span class="c2">might not provide what was wanted the first time, revisions and tweaks </span></p><p class="c0"><span class="c2">are inevitable for everyone. It&#39;s all too exhausting and incompatible </span></p><p class="c0"><span class="c2">with mainstream adoption of AI.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">To surpass the limitations of the AI chat format,</span></p><p class="c0"><span class="c2">this future app should seek to provide an application suite</span></p><p class="c0"><span class="c2">of prompt-making functionality, crafted by the product makers</span></p><p class="c0"><span class="c2">in accordance with how people generally end up using (or could use)</span></p><p class="c0"><span class="c2">an LLM, divided into modules or categories inside the app. &nbsp;</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">Categories and app sections can include the following.</span></p><p class="c0"><span class="c2">The first is the most freeform. &nbsp;Each category, when activated</span></p><p class="c0"><span class="c2">displays a collection of specialized controls and functionality</span></p><p class="c0"><span class="c2">specific to that category. &nbsp;For dealing with text,</span></p><p class="c0"><span class="c2">common text software tools are built into that mode or section</span></p><p class="c0"><span class="c2">of the app, something of value to many scholars.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">1) (Default Mode) - Continue / Comment On / Make Response to (provided text).</span></p><p class="c0"><span class="c2">2) Inquiry/Explain a Subject - Generate a profile or background on a topic. &nbsp;</span></p><p class="c0"><span class="c2">Provide reading list for subject.</span></p><p class="c0"><span class="c2">3) Manufacture / Generate - literature, poem, essay, possible business names, recipes, etc.</span></p><p class="c0"><span class="c2">4) Programming / Code - &nbsp;Templates, Generate Code, Evaluate Code, Rewrite Code.</span></p><p class="c0"><span class="c2">5) How-to (How to Do a Thing) - &nbsp;Solutions for a Problem. &nbsp;Practical Skills. &nbsp;Everyday </span></p><p class="c0"><span class="c2">Reference. Domestic chores.</span></p><p class="c0"><span class="c2">6) Veracity Check - (find out if something is true generally).</span></p><p class="c0"><span class="c2">7) Work with Texts - &nbsp;Explain provided (especially older) text. &nbsp;Translate. Dictionary word lookup. </span></p><p class="c0"><span class="c2">Text passage origin / its meaning / summary. &nbsp;Extract summary of only</span></p><p class="c0"><span class="c2">certain type of information from the document.</span></p><p class="c0"><span class="c2">8) Data: Generate or Retrieve (e.g. avg. weather for a region). &nbsp;Reformat operations for </span></p><p class="c0"><span class="c2">provided data. Check for a condition inside provided data/text. &nbsp;Analyze.</span></p><p class="c0"><span class="c2">9) Converse or Simulate Interaction: role-playing, simulated interviews,</span></p><p class="c0"><span class="c2">language learning, and other interactive sessions designed to mimic real-life interactions.</span></p><p class="c0"><span class="c2">10) Education/Reading: Provide typical course curriculum for a subject. &nbsp;</span></p><p class="c0"><span class="c2">Provide reading list. Describe prerequisites for taking up a subject.</span></p><p class="c0"><span class="c2">Make quizzes, tests.</span></p><p class="c0"><span class="c2">11) Proofread / Copyedit / Rephrase</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">For any activity that makes use of an LLM there </span></p><p class="c0"><span class="c2">will have to be uses crafted for them. &nbsp;The &quot;Work with Texts&quot; will</span></p><p class="c0"><span class="c2">reflect what people do when they work with texts. &nbsp;This is not</span></p><p class="c0"><span class="c2">an automatic thing.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">----</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">OPERATIONS FOR AN LLM WRAPPER</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">Common operations would be EXTEND, which is to take</span></p><p class="c0"><span class="c2">existing input and go further with it. &nbsp;REVISE.</span></p><p class="c0"><span class="c2">EVALUATE ACCURACY. &nbsp;</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">----------------------------</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">Provide the LLM wrapper a YouTube URL</span></p><p class="c0"><span class="c2">and it will summarize the transcript.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">----------------------------</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">--- SETTINGS IN THE UI ---</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">PARAMETERS, BUTTONS, AND CONTROLS.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">CURRENT OUTPUT MODE: [RTF] (HTML/PDF/TXT)</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">OUTPUT RESULTS OF QUERY: </span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- to a table</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- to a code text box</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- to a web page</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c0"><span class="c2">STYLE THE RESULTS</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- with headings</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- body text font: [Times New Roman] (14pt)</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- heading font: [Arial] (Bold) (18pt)</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">EXPORT RESULTS AS</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- spreadsheet</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- csv</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- html</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- json</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">CONVERT</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- [json] to [xml]</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- [html] to [rtf]</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">------------------------</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">--- BINS, HOLDING AREAS ---</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">--- Separate, stationary holding area for documents to be used in queries</span></p><p class="c0"><span class="c2">--- Separate, stationary holding area for pasted text snippets to be used in queries</span></p><p class="c0"><span class="c2">--- Separate bin for images made part of queries</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">----</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">FETCH AND FORMULATE REPORT OF IMAGES, GALLERIES</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">It might be easy to overlook that at the current stage the</span></p><p class="c0"><span class="c2">LLMs have not been set up to fetch images from the web</span></p><p class="c0"><span class="c2">in response to a query on a certain topic and place them</span></p><p class="c0"><span class="c2">in context of the query. &nbsp;Let&#39;s say that a person wants to </span></p><p class="c0"><span class="c2">research edible mushroom plants. There will be many websites </span></p><p class="c0"><span class="c2">that provide information about them but this will take a lot</span></p><p class="c0"><span class="c2">of time to go through them to get a complete overview, perhaps. &nbsp;</span></p><p class="c0"><span class="c2">There would be value in having the AI compile </span></p><p class="c0"><span class="c2">a report about the topic that is complete with images,</span></p><p class="c0"><span class="c2">captions, and so on, from multiple websites, not for the</span></p><p class="c0"><span class="c2">purpose of re-publication but for providing the user</span></p><p class="c0"><span class="c2">an overview on a less known topic that might be somewhat unpleasant</span></p><p class="c0"><span class="c2">to research on the Internet. &nbsp;&quot;What are all of the different</span></p><p class="c0"><span class="c2">types of edible mushrooms grown for cooking meals?&quot; would</span></p><p class="c0"><span class="c2">return a list of images and captions. &nbsp;Optional would be</span></p><p class="c0"><span class="c2">a summary next to each mushroom type. &nbsp;This is beyond what</span></p><p class="c0"><span class="c2">Google provides at the moment.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">AN IMAGE REMINDING THE USER OF THE VAST AMOUNT OF INFORMATION</span></p><p class="c0"><span class="c2">CONTAINED IN AN LLM AND THE MANY CAPABILITIES.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">One of the issues of leaving interaction with an LLM at</span></p><p class="c0"><span class="c2">a simplistic chat text box is that the user is not in</span></p><p class="c0"><span class="c2">touch with what the LLM provides. &nbsp;Within the AI community</span></p><p class="c0"><span class="c2">there are many criticisms of the LLM but no matter what</span></p><p class="c0"><span class="c2">these could be truly useful bases of knowledge and profound</span></p><p class="c0"><span class="c2">tools if they are provided the right interface and the</span></p><p class="c0"><span class="c2">right indications that they are massive, they are thorough,</span></p><p class="c0"><span class="c2">and they are capable. &nbsp;One does not get this impression</span></p><p class="c0"><span class="c2">when clicking inside the text box and then getting a response.</span></p><p class="c0"><span class="c2">In this way too much is left on the user to figure out.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">&nbsp; </span></p><p class="c0"><span class="c2">&nbsp; </span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">An LLM is so versatile but the barrier to its mainstream</span></p><p class="c0"><span class="c2">adoption is the fatigue produced by typing out prompts each time,</span></p><p class="c0"><span class="c2">the lack of organization, structure and guidance provided by such a simplistic user interface,</span></p><p class="c0"><span class="c2">and the lack of output formatting. So, the AI community should produce common tools </span></p><p class="c0"><span class="c2">that address this, providing a kind of notebook (sections of generic use </span></p><p class="c0"><span class="c2">categories), allowing the user the opportunity to select how it should be </span></p><p class="c0"><span class="c2">used when approaching it.The user approaches the LLM with a text box today </span></p><p class="c0"><span class="c2">but will instead walk up to adeveloped suite of options. The goal </span></p><p class="c0"><span class="c2">should be to allow the user to produce the prompts rapidly by providing him or her</span></p><p class="c0"><span class="c2">with parameter controls. &nbsp;Each category provides its own </span></p><p class="c0"><span class="c2">premade parameters and settings, setting up a kind of mode</span></p><p class="c0"><span class="c2">for interacting with an LLM. &nbsp;Mode #7, text mode supplies software </span></p><p class="c0"><span class="c2">features and workflows will be specific to that category.</span></p><p class="c0"><span class="c2">An application suite is what will allow AI in the form of an LLM to </span></p><p class="c0"><span class="c2">be of value.Put differently, we who use them are just those who are </span></p><p class="c0"><span class="c2">willing to put up with such a basic situation because we are accustomed </span></p><p class="c0"><span class="c2">to rough edges from technical problems.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">The interface for an LLM should be multifaceted, not limited to what the</span></p><p class="c0"><span class="c2">user can come up with inside a text box. A text box is a prompt for the user to</span></p><p class="c0"><span class="c2">come up with something impromptu. But our app is a </span></p><p class="c0"><span class="c2">presentation of pathways for any user who opens it up. &nbsp;</span></p><p class="c0"><span class="c2">Each pathway, each destination has its own utilities built in. &nbsp;</span></p><p class="c0"><span class="c2">For this reason, it is conceivable that a person would spend all</span></p><p class="c0"><span class="c2">day in our app interacting with an LLM.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">When the LLM is made use of for reading old texts, for example, it has traditional</span></p><p class="c0"><span class="c2">software functionality provided for that purpose, for paginating what is pasted, </span></p><p class="c0"><span class="c2">for treating a PDF as a book that has pages that can be flipped or</span></p><p class="c0"><span class="c2">laid out as an imposition (overview) sheet, for highlighting text, etc. This is </span></p><p class="c0"><span class="c2">in contrast to the AI chat that has little recognition when any common, </span></p><p class="c0"><span class="c2">specific usage occurs apart from writing code, which is when it will </span></p><p class="c0"><span class="c2">provide a code box.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">Allowing the output of an LLM to break out of a vertical chat format</span></p><p class="c0"><span class="c2">is important as at times there may be value in generating </span></p><p class="c0"><span class="c2">responses on a grid flowing from left to right, to see iterations. &nbsp;</span></p><p class="c0"><span class="c2">It just has to be emphasized that if an LLM can generate all kinds of</span></p><p class="c0"><span class="c2">data, then the means to present that data and generate it should be varied.</span></p><p class="c0"><span class="c2">If the LLM is used to generate specific kinds of data, the presentation of </span></p><p class="c0"><span class="c2">the generated output should adapt, just like described, </span></p><p class="c0"><span class="c2">so that it isn&#39;t always raw text stacked vertically. If it generates</span></p><p class="c0"><span class="c2">chart data, the data should show up in a chart. If it is a quiz being</span></p><p class="c0"><span class="c2">generated, then ideally an actual set of quiz controls should show up</span></p><p class="c0"><span class="c2">in the response. &nbsp;A recipe should be formatted as a recipe card if possible. &nbsp;</span></p><p class="c0"><span class="c2">Shaping the LLM&#39;s output presentation will make these very expensive</span></p><p class="c0"><span class="c2">AI models valuable. When AI is viewed as a more advanced tool rather than a </span></p><p class="c0"><span class="c2">simplistic genie in a bottle paradigm in which a question is asked an an action follows, </span></p><p class="c0"><span class="c2">these goals will be discussed more often. &nbsp;Tech often gets ahead</span></p><p class="c0"><span class="c2">of itself, wants to be more than it actually is and obsolesce the present</span></p><p class="c0"><span class="c2">to feel like it is moving into the future. &nbsp;But the basics of</span></p><p class="c0"><span class="c2">traditional software remain.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">NOISE IN DATA IS COMPRISED OF...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c0"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c0"><span class="c2">-----</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">1) Continue/Comment On/Make Response to: This would enable users to</span></p><p class="c0"><span class="c2">build upon or have the LLM respond to existing text, whether it&#39;s their own or</span></p><p class="c0"><span class="c2">provided by the LLM. &nbsp;There are &nbsp;dialectical benefits for</span></p><p class="c0"><span class="c2">the user of the LLM in this module. There is the ability to see</span></p><p class="c0"><span class="c2">a broader view of the topic by having the LLM response.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">2) Inquiry/Explain a Subject: Users could utilize the LLM</span></p><p class="c0"><span class="c2">to research and generate informative profiles or backgrounds</span></p><p class="c0"><span class="c2">on a wide range of topics, as well as receive curated reading</span></p><p class="c0"><span class="c2">lists to further explore those subjects.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">3) Manufacture/Generate Text: This would allow users</span></p><p class="c0"><span class="c2">to generate various types of written content,</span></p><p class="c0"><span class="c2">from literature and poetry to business name ideas and essays,</span></p><p class="c0"><span class="c2">based on specified parameters or prompts.</span></p><p class="c0"><span class="c2">The LLM could draw upon its broad knowledge to produce</span></p><p class="c0"><span class="c2">&nbsp;high-quality, original text tailored to the user&#39;s needs.</span></p><p class="c0"><span class="c2">&nbsp;</span></p><p class="c0"><span class="c2">4) Programming Code: This section would enable</span></p><p class="c0"><span class="c2">users to leverage the LLM&#39;s capabilities for</span></p><p class="c0"><span class="c2">software development, including generating code,</span></p><p class="c0"><span class="c2">answering programming-related questions, and</span></p><p class="c0"><span class="c2">even performing various code operations like</span></p><p class="c0"><span class="c2">refactoring, optimization, or debugging.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">5) How-to and Solutions for Problems: This feature would allow users to</span></p><p class="c0"><span class="c2">obtain step-by-step instructions or solutions for a variety of</span></p><p class="c0"><span class="c2">tasks and challenges, drawing on the LLM&#39;s extensive knowledge</span></p><p class="c0"><span class="c2">and problem-solving abilities. &nbsp;Especially relevant to household</span></p><p class="c0"><span class="c2">tasks, home improvement, automotive repair, questions about</span></p><p class="c0"><span class="c2">machines, appliances, etc.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">6) Veracity Check: Users could use this feature to assess the</span></p><p class="c0"><span class="c2">truthfulness or accuracy of claims, information, or statements,</span></p><p class="c0"><span class="c2">leveraging the LLM&#39;s understanding of factual knowledge and its</span></p><p class="c0"><span class="c2">ability to cross-reference sources. &nbsp;Primarily valued for</span></p><p class="c0"><span class="c2">circumstances relating to factuality outside of contemporary</span></p><p class="c0"><span class="c2">controversies.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">7) Explain Provided Text: Users could leverage this feature to gain</span></p><p class="c0"><span class="c2">insights into the origin, meaning, and context of a given text,</span></p><p class="c0"><span class="c2">helping to deepen their understanding. &nbsp;Especially useful for</span></p><p class="c0"><span class="c2">older texts. &nbsp;Translation, summarizing, etc. for provided texts</span></p><p class="c0"><span class="c2">falls under this category.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">8) Data Generation and Analysis: The LLM could be used to generate,</span></p><p class="c0"><span class="c2">format, and analyze various types of data, from weather forecasts</span></p><p class="c0"><span class="c2">to statistical insights, providing users with valuable information</span></p><p class="c0"><span class="c2">and insights from data.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">9) Converse, Simulate Interaction: This section would allow users</span></p><p class="c0"><span class="c2">to engage in more immersive and interactive experiences, such</span></p><p class="c0"><span class="c2">as role-playing, simulated interviews, and language learning</span></p><p class="c0"><span class="c2">exercises, helping to bridge the gap between the LLM and real-world interactions.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">10) Education: The LLM could be utilized to provide information on typical course</span></p><p class="c0"><span class="c2">curricula for different subjects, as well as describe the prerequisites and</span></p><p class="c0"><span class="c2">other relevant details to support educational and learning goals.</span></p><p class="c0"><span class="c2">Test questions and quizzes can be generated in this section.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">11) Proofread / Copy edit / Rephrase For Editing</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">Consider that conventional web search engines are </span></p><p class="c0"><span class="c2">limited in the same way, that often there is an inclination on the part of the</span></p><p class="c0"><span class="c2">user to make web searches carrying more specific conditions </span></p><p class="c0"><span class="c2">but there are no settings on the search page that </span></p><p class="c0"><span class="c2">are provided for this for fear that it would make using </span></p><p class="c0"><span class="c2">the web search engine too technical. &nbsp;But when a web search </span></p><p class="c0"><span class="c2">is made, sometimes there is a desire to </span></p><p class="c0"><span class="c2">limit the results to entities in the physical world, to</span></p><p class="c0"><span class="c2">make sure that results exclude Internet entities.</span></p><p class="c0"><span class="c2">Often there is a desire to limit a list of these results further </span></p><p class="c0"><span class="c2">to a geographic boundary, too. &nbsp;Web search could be said to be in </span></p><p class="c0"><span class="c2">the same state as the LLM chat format, something simplistic. </span></p><p class="c0"><span class="c2">Just like an LLM, there are possible categories of usage that </span></p><p class="c0"><span class="c2">won&#39;t make it difficult for a lay user </span></p><p class="c0"><span class="c2">to use the technology. But because of an online culture </span></p><p class="c0"><span class="c2">that seeks to make everything minimalist, the potential of many</span></p><p class="c0"><span class="c2">technologies is obscured. &nbsp;Minimalist is pursued as an ideal,</span></p><p class="c0"><span class="c2">to the detriment of usability and completion of the software needs.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">Even when you instruct humans you give them long spec sheets </span></p><p class="c0"><span class="c2">and documents with bullet lists. &quot;Genie in a bottle&quot; commands, </span></p><p class="c0"><span class="c2">making consecutive small requests to the AI, isn&#39;t broad enough for</span></p><p class="c0"><span class="c2">the AI to be of value for everyday tasks. &nbsp;The AI tool</span></p><p class="c0"><span class="c2">has to be able to take in a blueprint all at once and</span></p><p class="c0"><span class="c2">the parameters of this have to be easy to change.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">---</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">BUILDING LLM PROMPTS</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">-- Rectangular building blocks components replace typewritten</span></p><p class="c0"><span class="c2">prompts. &nbsp;Each component contains GUI controls for its parameters</span></p><p class="c0"><span class="c2">and is around 200pt x 200pt. &nbsp;When there is more than one they </span></p><p class="c0"><span class="c2">flow like text. &nbsp;A prompt is made out</span></p><p class="c0"><span class="c2">of one or more of these building blocks.</span></p><p class="c0"><span class="c2">Each building block makes up the prompt, allowing rapid</span></p><p class="c0"><span class="c2">construction of parametric prompts rather than just verbal ones.</span></p><p class="c0"><span class="c2">The container for making a prompt out of these components </span></p><p class="c0"><span class="c2">can be made as large as a page.</span></p><p class="c0"><span class="c2">-- The AI itself can be requested to make relevant prompts</span></p><p class="c0"><span class="c2">and this will be incorporated into the app.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">STANDARD APP SOFTWARE FUNCTIONALITY</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">- Export contents of selected output control</span></p><p class="c0"><span class="c2">to document, .RTF, .PDF, .TXT, .CSV, .XLSX.</span></p><p class="c0"><span class="c2">- AI-generated tabular data appears as interactive table</span></p><p class="c0"><span class="c2">in the app.</span></p><p class="c0"><span class="c2">- AI-generated map data appears on an interactive map.</span></p><p class="c0"><span class="c2">- Print selected output control.</span></p><p class="c0"><span class="c2">- Functions for reformatting data output are provided.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">PROMPT REVISION&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FUNCTIONALITY</span></p><p class="c0"><span class="c2">- Qualities: add [more or less] of [quality].</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">CHAT OUTPUT TAIL MENU</span></p><p class="c0"><span class="c2">- A menu appears at the bottom of every chat response</span></p><p class="c0"><span class="c2">allowing the user to modify the original prompt </span></p><p class="c0"><span class="c2">or respond to the chat.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">---</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">In an app like this, menus divide interactivity with the LLM into</span></p><p class="c0"><span class="c2">categories that assist the user in generating prompts according</span></p><p class="c0"><span class="c2">to the needs when the LLM is used. &nbsp;Providing starting points for the LLM</span></p><p class="c0"><span class="c2">for the user will end up being far more productive than a bare text box, which</span></p><p class="c0"><span class="c2">is probably too simplistic and tiresome when there is</span></p><p class="c0"><span class="c2">such a wide range of situations for which a person might use an LLM</span></p><p class="c0"><span class="c2">and such a large number of instances when the prompts could be</span></p><p class="c0"><span class="c2">formulated with convenient, traditional app user interface.</span></p><p class="c0"><span class="c2">At the current time, this is not regarded as a concern as there is</span></p><p class="c0"><span class="c2">belief that AI technology is advancing so rapidly that the tool</span></p><p class="c0"><span class="c2">just described will be obsolete as soon as it is finished in a year or</span></p><p class="c0"><span class="c2">two. &nbsp;That may not be true.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">A weak point of the AI chatbot is that interacting with the LLM</span></p><p class="c0"><span class="c2">often involves a lot of repetition and revision of writing and typing</span></p><p class="c0"><span class="c2">but there are no functions provided for that or even something to</span></p><p class="c0"><span class="c2">formulate prompts generatively in the first place. &nbsp;</span></p><p class="c0"><span class="c2">The presets within each category will facilitate valuable</span></p><p class="c0"><span class="c2">usage of the LLM for that individual category.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">An LLM wrapper app like this demonstrates product development</span></p><p class="c0"><span class="c2">that extends beyond the basic AI chatbot because it works with</span></p><p class="c0"><span class="c2">the LLM with more developed interactive conveniences and it shows</span></p><p class="c0"><span class="c2">that product is not obsolesced by research and engineering but</span></p><p class="c0"><span class="c2">should continue to be discussed.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">Currently the textbox for an AI chatbot is freeform typing.</span></p><p class="c0"><span class="c2">Offering some organization and structure to the situation--</span></p><p class="c0"><span class="c2">laying down a kind of blueprint for the amusement park--</span></p><p class="c0"><span class="c2">will make the LLM a lot more useful for the consumer.</span></p><p class="c0"><span class="c2">It is only under these conditions when an LLM could</span></p><p class="c0"><span class="c2">become mainstream.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">---- GENERATE META INSTRUCTIONS FOR EXERCISE, QUIZ, ETC. ---</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">A paraprogram that structures responses from the LLM</span></p><p class="c0"><span class="c2">in a stateflow so that it is back and forth.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">The meta program routes the output in a flow chart </span></p><p class="c0"><span class="c2">for the correct answer until it is given.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c5"><span class="c2"></span></p></body></html>