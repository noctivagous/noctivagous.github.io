ChatGPT Isn't Finished (Made into a
Software Application Suite);
It's a Simple Textbox Interface to an API

noctivagous.github.io

Written and spoken language, also known as natural language, 
is for humans to communicate to other humans and not always
the best language for interacting with machines.  But there is
a persistent notion that it is supreme on occasion, such as with
Siri, Alexa, and other products.  In fact, there 
are times when humans are using codes instead of natural language between each
other, for a reason, such as referees on the field or airport ground controllers,
who using hand signals, times when supposedly the easiest form
of communcation for them would be to use a radio, a microphone attached
to their shorts.  What's more, when people do use radios professionally they 
often have official charts of codes that they follow to make communication 
concise.  Thus using natural language isn't even the best for everyday life 
so it certainly wouldn't always be the best way to interact with AI or a machine. 

The AI chatbots work around people typing out text.  But talking about typed chat text,
even the emoji character can be likened to a coded signal, and combinations of emoji and words
can communicate many modalities more concisely over communication media
or help approximate real world interaction. People don't use them
to talk to AI, though.   During a real world auction, a person isn't
shouting or lifting up his arm but lifting up a bid paddle.  So whereas it 
often feels like the best interface to a machine would be what comes out of a 
person's mouth conversationally or what would be written
down, and supposedly this is the most natural interface there could be for
anything (including writing code), in fact it is usually that natural language  
the merely easiest for workers in tech to implement in software and asks the least of
them to make a product for the consumer.

ChatGPT (GPT4) offers a lot of capabilities but the actual situation
is that it is just a superficial website gateway-- a plain text box-- 
for what OpenAI engineered that is sitting in the computer data centers.   
Originally  OpenAI was just focused on selling access to that through
a very technical API (the API that communicates to the LLM in the data 
centers).  Then it put together this chat-style format on a web page 
as a shallow demonstration of how it is possible to interact with the API.  
The API's responses are stacked up vertically after the user sends out 
text to the API.  On the front end, it's not that sophisticated.

According to official accounts,  ChatGPT is an accidental success; 
OpenAI originally released it as a "research preview". They had no 
intention of marketing it commercially.  But then the public's interest 
in the user-friendly interface to GPT3 exceeded expectations. 
This is according to their own version of events.

The ChatGPT style of web interaction with AI was possible earlier, of course, and 
there were consumers in previous years requesting an opportunity to chat 
for free with an AI bot in this way, because all of the available options 
cost money and might not be very good.  Fortunately, OpenAI provided 
an opportunity for people interested in AI to try out interacting with 
their API for free, without needing to write a program that interacted with 
the GPT3 API.  OpenAI also succeeded with ChatGPT because it provided a high-quality 
LLM, this GPT3.

But what OpenAI may not realize is that, as an organization, it only
has hired personnel to work on one side of the situation, the engineering 
of the AI in the data centers, and they do not have a team intent 
on completing the ChatGPT app into something finished, resembling a 
completed suite of features (like an iLife app, such as GarageBand).  
The natural evolution of ChatGPT would lead to this, for interacting 
with an LLM can go beyond writing text from scratch every time in a 
one-line box, something that gets tiresome after a while (always writing 
from scratch the commands).  This is to say that ChatGPT isn't a suite of tools and 
OpenAI stopped at providing text box that sends API calls, with the web page 
stacking the responses in the appearance of a "chat".

ChatGPT just provides a simple interface to the GPT's raw API that, 
previously, few people except experienced programmers could use.  
The "research preview" transformed the situation by satisfying lay 
demand for free access to AI, but it wasn't built out beyond that, it isn't a 
complete software package with a fully developed app experience, 
with ways to access all of the use cases and scenarios of an LLM. 
Too much is left to the user to figure out.

It's very basic, as it's not even possible to collapse, close, or hide 
any of the chat output from ChatGPT. There are no nodes (patches) 
a person can wire up to control its responses (such as what is found 
in Unreal Engine's Blueprints). Some people in the AI community 
have come up with their own independent apps with this feature for 
interfacing to LLMs, especially for the image generators.
 
Apart from a text box, there is nothing guiding the user for how to 
use ChatGPT, which means that too much of a burden is placed
on the person who arrives at OpenAI's website.  
When we say that ChatGPT needs to be built into an app 
this means that ChatGPT doesn't have any menus, toolbars, panels, 
presets, templates, or generic prompts.  It isn't a finished app 
because it is a blank box with little guidance of how to use it. 
It isn't any kind of lifestyle or productivity app. So, there 
is no way the public can find this tool useful for very long unless 
OpenAI begins to work on it as real software.

At the most basic level, what ChatGPT needs is not just a few specific 
examples to click on such as "Come up with a trip itinerary for me to 
visit____" but instead a set of grouped, generic prompts: "Come up with a ___" or "Make 
an outline for ___".  These would be grouped into categories of 
use as well, such as for daily life, research, quizzing, etc.

An LLM could be discussed as the basis for a different category of app,
such as one that assists users in reading older or ancient 
texts and it would be dedicated to this task, offering the option to
generate live marginalia or explanations of the text on the page as each page is turned. 
It would fetch related images and information live and place them
in various tabs in the margins.  Any word clicked on would show
a definition (in one mode). A paragraph might be clicked on to the side
to be examined in different ways.  A page might be turned into modern
wording.  In this example, the LLM is being used as the software engineering 
resource in combination with regular software application features.
The user is not forced to paste text into ChatGPT's small text box
and then tell it to do each thing because the software application
has provided many relevant features for the job in software.
It would have the ability to take in raw images, convert them
to the text, and translate them, but this is better as one feature
of a whole rather than providing it individually and disconnected
from anything because in that case the user has to come up with a 
reason for the feature.

Another app meant for assisting the cooking that made use of an LLM 
would look different because it would have features tailored for different 
aspects of that task, such as generating recipes out of available ingredients, 
replacing ingredients in provided recipes with substitutions, etc.  It would 
also carry conventional app features, like storing recipes.  
An LLM offers the  AI resource for these use cases and many 
more but it makes more sense to use it as the backend for a new category of app. 
Just by focusing on these two use case, and how they are crammed into the tiny 
text box that is ChatGPT's means input, it demonstrates how uncomfortable 
ChatGPT really is to use for a wide variety of tasks.  A bare text box 
would have to be repurposed for these two very different needs.

A common problem in the AI community and the tech community
is the belief that the following is what consumers will really want
for the long term.  The consumer will utter, "I want this complex thing 
that would normally take me a lot of time," and then the AI goes off and 
does it, returns to the person with an impressive result and the consumer
and his friends are all very delighted.  This is the parlor trick mentality 
of technology that is to be avoided because it doesn't carry long-term value for
people and these products eventually lose users over time because
the users are impressed too at first but they don't work in technology
and then eventually they lose interest, as would have to be the case.

A prominent opportunity is a switch control to turn on and off the setting 
where ChatGPT provides a summary of any topic before providing an
answer, which can be tiring because often what is wanted is just
a direct answer to the question.  Sometimes the user wants a summary
and overview of the subject mentioned and other times it is superfluous.
These are the sorts of features that should be present in a comprehensive 
app wrapper for what is ChatGPT.

In a finished ChatGPT style of app, there would be a keyboard shortcut to
interrupt the AI to stop it, another one to delete the response just given
if it wasn't wanted, and so on.

Finally, typing text is not always the strongest means of controlling 
an LLM at all times, because it depends on the use case.  If it is 
DALL-E, then there should be pre-configured controls (such as the 
node-based programming nodes) with adjustable parameters.
Some startups and websites have demonstrated this already.

These issues all existed between GPT3.5 and GPT4 and it is expected
that they will be relevant in the near future for newer AI models.





