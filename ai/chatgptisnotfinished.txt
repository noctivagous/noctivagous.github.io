ChatGPT Isn't Finished (Made into a
Software Application Suite);
It's a Simple Textbox Interface to an API

noctivagous.github.io

Written and spoken language, often discussed as "natural language" in
technology circles, is for humans to communicate to other humans, but 
is this the best for communicating with machines? 
There are many times when dialogue isn't the best format for commands,
signals, and so forth.  Even so, there is a persistent notion that natural language
dialogue is the supreme way for a person to talk to a machine, that there could be 
nothing better than a personal assistant who is human,
implied by products like Siri and Alexa.  In fact, there are times when humans 
are using coded terms instead of natural language when communicating
commands and responses among each other, for a reason, 
such as when referees communicate on the field or airport ground controllers direct 
airplanes-- both cases involve using hand signals.  For an airport ground controller, 
supposedly the easiest means of communication would be radio directly to the
pilot, with a microphone attached to the controller's shirt.  
But actually, when people do use radios professionally (e.g. air traffic towers) they
often have official charts of codes that they follow to make communication
concise, to dispatch instructional information more concisely than regular conversation
and dialogue.  Thus using conversational and natural language isn't even treated as
the best format for everyday life, so it certainly wouldn't always be ideal for interacting 
with AI or a machine.  There would be a lot of resistance to formulating a product
based on a chart of codes at any computer company, something the user has
to learn or memorize.  Dialogue may be the easiest for a consumer to understand 
with the least amount of personal memorization and effort needed but that is a 
totally different subject than what is actually optimal or what will work in the
long-term.

The AI chatbots work around people typing out text.  But on this topic, typed chat text,
even the emoji character can be likened to a coded signal, and combinations of emoji and words
can communicate many modalities more concisely over digital communication media than
spoken dialogue or it can help approximate subtleties of real world interaction. 
People don't use them to talk to AI and that is a different avenue to go down.   
During a real world auction, a person isn't shouting or lifting up his arm but instead
lifting up a bid paddle.  So whereas it often feels like the best interface to a machine
would be what comes out of a person's mouth conversationally, like talking to a receptionist,
or what would be written down in an essay, and supposedly this is the most 
natural interface there could be for anything (including writing code), in fact 
it is usually that natural language the merely easiest for workers in tech to implement 
in software that asks the least of the consumer.

ChatGPT (GPT4) offers a lot of capabilities but the actual situation
is that it is just a superficial website gateway-- a plain text box-- 
for what OpenAI engineered that is sitting in the computer data centers.   
Recently, in May of 2024, it was mentioned by a founder of OpenAI John Schulman 
on a podcast by Dwarkesh Patel that it wasn't that simple of a situation to make 
OpenAI's ChatGPT out of its original API, that the situation required modifications.  

But in terms of a product offering, an aspiration to make an interactive chatbot AI, 
the goal was always present in the AI community and it might be regarded as an 
inevitability given that text would be the most technologically straightfoward medium
before jumping to audio, etc.  What is most important in the situation is to 
remark that this back-and-forth text chat format carries major product 
restrictions because it isn't treating AI as a tool but rather shaping it as 
a personal assistant.

Microsoft experimented with public interactions with its early and limited Tay AI in 2016
on Twitter, allowing anyone to send messages to the Twitter account and get
single, short responses.

Originally, OpenAI was just focused on selling access to their AI model through
a technical API (the API that communicates to the LLM in the data 
centers).  Then it put together this chat-style format on a web page and applied
tweaks that only OpenAI could apply to their own technologies to get it to work
smoothly, as can be surmised from what Schulman explained.  Now these chatbots
can be run locally on home computers.  The API responses are stacked up 
vertically after the user sends out text to the AI model.  
On the front end, it's not that sophisticated when looked at from an app
developer's persective, someone who believes that AI should be regarded
as a tool first and a personal assistant second, especially 
until the technology advances further.

The public's interest in the user-friendly interface to GPT3 exceeded expectations. 
This is according to their own version of events.  There is a post at this
address where Schulman is recruiting for what became ChatGPT:
https://community.openai.com/t/hiring-software-engineer-to-help-turn-webgpt-into-a-product/14638

The ChatGPT style of web interaction with AI was possible earlier, of course, and 
there were consumers in previous years requesting an opportunity to chat 
for free with an AI bot in this way, because all of the available options 
cost money and might not be very good and no one wanted to sign up for
something that cost money back then when it was all unproven.  Fortunately, OpenAI provided 
an opportunity for the public interested in AI to try out interacting with 
their AI, without needing to write a program that interacted with 
the GPT3 API.  OpenAI succeeded with ChatGPT because it provided a high-quality 
LLM, this GPT3.

But what OpenAI may not realize is that, as an organization, it only
has hired personnel to work on one side of the situation, the research and
engineering of the AI in the data centers, and they do not have a team intent 
on completing the ChatGPT app into something truly finished, resembling a 
completed suite of features (like an iLife app, such as GarageBand).  
Still today, in May of 2024, OpenAI appears to believe in the personal assistant
format of text AI with its GPT-4o.

The natural evolution of ChatGPT, if it were viewed as a tool, would lead to an
app suite, for interacting with an LLM can go beyond writing text from scratch every time in a 
one-line box, something that gets tiresome after a while (always writing 
from scratch the commands).   ChatGPT isn't a suite of tools and 
OpenAI stopped at providing text box that sends API calls, with the web page 
stacking the responses in the appearance of a "chat".

The OpenAI "research preview" transformed the situation by satisfying lay 
demand for free access to AI, but it wasn't built out from a product standpoint, it isn't a 
complete software package with a fully developed app experience, 
with ways to access all of the use cases and scenarios of an LLM. 
Too much is left to the user to figure out.

It's very basic, as it's not even possible to collapse, close, or hide 
any of the chat output from ChatGPT.  With the power that AI
provides sometimes the basics of software get overlooked, is the issue.
There are no nodes (patches) a person can wire up to control its responses 
(such as what is found in Unreal Engine's Blueprints). Some people in the AI community 
have come up with their own independent apps with this feature for 
interfacing to LLMs, especially for the image generators.
 
Apart from a text box, there is nothing guiding the user for how to 
use ChatGPT, which means that too much of a burden is placed
on the person who arrives at OpenAI's website or installs their app.  
When we say that ChatGPT needs to be built into an app 
this means that ChatGPT doesn't have any menus, toolbars, panels, 
presets, templates, or generic prompts.  Perhaps there is an unrealistic
desire that this isn't necessary.  It isn't a finished app 
because it is a blank box with little guidance of how to use it. 
It isn't any kind of lifestyle or productivity app. So, there 
is no way the public can find this tool useful for very long unless 
OpenAI begins to work on it as real software in a traditional kind of way
as we have come to know it.  What has been shown is that what people
thought in the past would give them everything (Siri like interactions)
they find to be less useful than they thought in the early 1990s and
on television shows when the computer would be a genie in a bottle.
At least today, the genie in the bottle format (in other words, the personal
assistant format) for using AI doesn't work that well except for power users.

At the most basic level, what ChatGPT needs is not just a few specific 
examples to click on such as "Come up with a trip itinerary for me to 
visit____" but instead a set of grouped, generic prompts. 
 These would be grouped into categories of use as well, such as for 
daily life, research, quizzing, etc.  This is a tool and when that is the
case there have to be categories of usage, not a catchall text box.

An LLM could be discussed as the basis for a different category of app,
such as one that assists users in reading older or ancient 
texts and it would be dedicated to this task, offering the option to
generate live marginalia or explanations of the text on the page as each page is turned. 
It would fetch related images and information live and place them
in various tabs in the margins.  Any word clicked on would show
a definition (in one mode). A paragraph might be clicked on to the side
to be examined in different ways.  A page might be turned into modern
wording.  In this example, the LLM is being used as the software engineering 
resource in combination with regular software application features.
The user is not forced to paste text into ChatGPT's small text box
and then tell it to do each thing because the software application
has provided many relevant features for the job in software.
It would have the ability to take in raw images, convert them
to the text, and translate them, but this is better as one feature
of a whole rather than providing it individually and disconnected
from anything because in that case the user has to come up with a 
reason for the feature.

Another app meant for assisting the cooking that made use of an LLM 
would look different because it would have features tailored for different 
aspects of that task, such as generating recipes out of available ingredients, 
replacing ingredients in provided recipes with substitutions, etc.  It would 
also carry conventional app features, like storing recipes.  
An LLM offers the  AI resource for these use cases and many 
more but it makes more sense to use it as the backend for a new category of app. 
Just by focusing on these two use case, and how they are crammed into the tiny 
text box that is ChatGPT's means input, it demonstrates how uncomfortable 
ChatGPT really is to use for a wide variety of tasks.  A bare text box 
would have to be repurposed for these two very different needs.

A common problem in the AI community and the tech community
is the belief that the following is what consumers will really want
for the long term.  The consumer will utter, "I want this complex thing 
that would normally take me a lot of time," and then the AI goes off and 
does it, returns to the person with an impressive result and the consumer
and his friends are all very delighted.  This is the parlor trick mentality 
of technology that is to be avoided because it doesn't carry long-term value for
people and these products eventually lose users over time because
the users are impressed too at first but they don't work in technology
and then eventually they lose interest, as would have to be the case.

A prominent opportunity is a switch control to turn on and off the setting 
where ChatGPT provides a summary of any topic before providing an
answer, which can be tiring because often what is wanted is just
a direct answer to the question.  Sometimes the user wants a summary
and overview of the subject mentioned and other times it is superfluous.
These are the sorts of features that should be present in a comprehensive 
app wrapper for what is ChatGPT.

In a finished ChatGPT style of app, there would be a keyboard shortcut to
interrupt the AI to stop it, another one to delete the response just given
if it wasn't wanted, and so on.

Finally, typing text is not always the strongest means of controlling 
an LLM at all times, because it depends on the use case.  If it is 
DALL-E, then there should be pre-configured controls (such as the 
node-based programming nodes) with adjustable parameters.
Some startups and websites have demonstrated this already.

These issues all existed between GPT3.5 and GPT4 and it is expected
that they will be relevant in the near future for newer AI models.


FETCH AND FORMULATE REPORT OF IMAGES, GALLERIES

It might be easy to overlook that at the current stage the
LLMs have not been set up to fetch images from the web
in response to a query on a certain topic and place them
in context of the query.  Let's say that a person wants to 
research edible mushroom plants. There will be many websites 
that provide information about them but this will take a lot
of time to go through them to get a complete overview, perhaps.  
There would be value in having the AI compile 
a report about the topic that is complete with images,
captions, and so on, from multiple websites, not for the
purpose of re-publication but for providing the user
an overview on a less known topic that might be somewhat unpleasant
to research on the Internet.  "What are all of the different
types of edible mushrooms grown for cooking meals?" would
return a list of images and captions.  Optional would be
a summary next to each mushroom type.  This is beyond what
Google provides at the moment.

AN IMAGE REMINDING THE USER OF THE VAST AMOUNT OF INFORMATION
CONTAINED IN AN LLM AND THE MANY CAPABILITIES.

One of the issues of leaving interaction with an LLM at
a simplistic chat text box is that the user is not in
touch with what the LLM provides.  Within the AI community
there are many criticisms of the LLM but no matter what
these could be truly useful bases of knowledge and profound
tools if they are provided the right interface and the
right indications that they are massive, they are thorough,
and they are capable.  One does not get this impression
when clicking inside the text box and then getting a response.
In this way too much is left on the user to figure out.




  







