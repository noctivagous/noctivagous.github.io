In the normal order of things, a person has cognition and then, secondarily, senses 

and modes of expression link into that.  I have noticed that in the current field 

of AI, the direction could be described as reversed. 



We would usually think of AI as a thinking apparatus that 

supplementarily and complementarily possesses various 

means of expressing itself and taking in information , 

after the central thought machine has been 

programmed.  But to make any AI today the current method is to take whatever 

existing human expression has been recorded, especially text (written word) data, 

and manage to make an AI machine out of that secondary, expression product of cognition,

which generally resu;ts from real-world human discourse and or activities.



Researchers are formulating AI technologies by focusing on the expressions, 

the by-products, the senses, and representations of cognition first— 

digital products of sight, sound, written word stored in computer data. Then, by drawing deep 

connections from those repositories of training data, they are making AI products 

that are intelligent by way of various computational mechanisms that make

processing the data an intelligent activity.   The deep and extensive associations established 

with this data, using enormous computational resources, are enough to

make what feels like a complete AI machine at first. It is enough to generate new information and

data and process data in a realistically human-looking way and indeed there is striking 

intelligence in the situation that cannot be dismissed as merely statistical.

The whole seems to be larger than the sum of its parts despite relying on

empirical thinking that does not subscribe to that viewpoint.



Current AI does not focus on cognition as the foundation and

then afterwards (secondarily) link it into modes of sense and expression (text, image, video), as we

normally conceive of a machine experiencing life.  It instead inverts the process, making use of vast 

repositories  of very specific and isolated sense and expression products (image, text, video training data) in 

order to manufacture what it ultimately provides a basis of cognition.  Because of this inverted relationship

there are those who doubt whether the AI is aware or truly intelligent beyond computational processing. 

They feel this because cognition arises as a result of linking together deeply what people 

have said and done over the centuries as it has been stored in computer data, not a machine

that was made directly to cogitate, as something that has its own objectives and understandings.  

Current AI weaves human multimedia into deep neural networks and 

then from this effort, to everyone’s delight, emerges capable and multi-layered 

AI products capabilities.  Perhaps the ceiling of this technology

is a consequence the relationship just described.



Today, what determines any AI cognition is the mass of training data, not a central

machine that has a crafted constitution that then determines its own sense and expressions,

which would still take in training data.


What is also interesting is that when AI is trained it will not quite understand what

2D video or 2D image data actually is relative to physical experience, 

despite all of the intelligent things it can do with it that have impact for humans

when they use the AI.  It can track objects inside a video of two people playing tennis 

but it hasn't been directly taught, first, what people are, what a tennis court is, and

then finally how a 2D video is merely a technological convention for representing 

and transmitting the 3D world among people.  Instead, the idiomatic digital format of transmission 

itself is made the primary focus to make something intelligent.  

The specific is made the subject of research rather than the general.












 