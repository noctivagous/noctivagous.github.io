Moving Past Apple's iOS

For tablet computers, iOS (iPadOS) has a major drawback: the simplest tasks are easy to achieve, but anything slightly complicated is has to be specifically learned because it is invisible or offscreen.  The "user friendly" description only applies to the fundamentals of launching an app, zooming inside a document, and scrolling. After that, the system software features that control the device are tacked on, one after another.  The consequence is that a user can easily activate one of iOS's many side features on accident (often without ever having been introduced to them), and this is a poor state of UI design.  But actually, iOS is an undeveloped and prototype-level collection of user interface conventions, incomplete except for consumption of media.  Because it strives towards minimalism and commercial accessibility, it is nubby, dumbed down, and evokes feelings of interacting with playground equipment.  For controlling software, Apple insists on depriving the user of complementary physical controls like knobs, sliders, and buttons, believing that those were the problem in the first place.

Steve Jobs just knew what mattered at the time-- to put together a tablet UI that worked for the hands and didn't require a stylus, and to accomplish that he brought in the multitouch technologies that had just been introduced by researchers.  The minimalist ideology he imposed was secondary and isn't the foundation of the iPad's success.  The chronology is that Apple developed first with large, tablet-sized multitouch screens and then shrank that to make the iPhone. Then, a few years later Apple released a multitouch interface in its original size as the iPad.  Embedding a foolproof, kiosk type of user interface inside a mobile tablet can sell a lot of devices because anyone from the public can use what iOS provides.  But it won't ever achieve what a PC (desktop computer) can, which is the current problem, that no one has manufactured a finished touchscreen product.  Software will never be programmed on an iPad without desktop computer accessories that make it behave like a PC and currently Apple's software development toolkit does not run on iPads.

Making a device blunt in its simplicity comes at a steep cost, because eventually the apps that people want to make and use are more complex, and software developers find that there is no systematic UI scheme available for their needs to match PC functionality.  In other words, iOS is ideologically narrow, deeply determined to package bare essentials as the digital environment for interactive mobile life.  It doesn’t possess any conceptual frameworks to accommodate complex usage of a tablet computer.  Necessarily there are PC trackpads and keyboard sold for these tablets, to turn them into PCs with screen cursors when the software is for serious usage.  No cursor would be necessary if iOS carried a complete set of UI principles, but achieving that will involve breaking out of a minimalist ideology that eschews accessory physical controls.

The theory of the PC was developed over a period of years by Douglas Engelbart and later Xerox PARC, so a tablet's return to the PC's conventions isn't a surprise when nothing equivalent has been developed for a multitouch device.  The theory behind iOS isn't much beyond a set of raw conveniences to accommodate the multitouch “gestures” unveiled by researchers in the 2000s, serving to launch apps and press buttons inside iOS apps.  Apple's packaging of that carried a minimalist ideology, which effectively halted the development of touchscreen UI.  For example, iOS is supposedly intuitive but it's unknown to the user how to open a file inside a specific application or how to manage the filesystem in a sophisticated way because the files are no longer the focus, just launching apps, for commercialized simplicity's sake.  The objective of making everything user friendly the point of being stupid and foolproof has resulted in an uncomfortable set of devices for several years now that can scroll, zoom, activate buttons but which severely limit engagement with the mobile computer's broad capabilities.

What iOS is really about is a false belief in a zero user-orientation period.  That is, the user should require so little time to be acquainted with iOS.  But "easy to use" (user friendly) shouldn't be equated with "no effort needed to understand it at all," which would be the domain of preschool children's toys.  For computing, that's not a good goal in the end because of the problems it creates that no one can do anything with it who makes software.  There has to be a more complex scheme set up for the future.  It shouldn't aim for being "dead simple" just because profitable sales are valued.


Touch Modifier Buttons

There are a lot of avenues to go down, and here is one.  An object sits there on the tablet touchscreen, but what does touching it mean?  In real life it moves according to physics.  On a touchscreen computer, the initial answer is vague, but generally "open" or "activate".  Beyond that things get complicated to make the touch do anything else.  On iOS, a single touch is restricted to one operation: "activate".

However, if several physical buttons were placed to the left the screen in a column, they would be able to specify what a touch means when it occurs.  Closing a window would not involve touching a close button but instead momentarily holding down the "close" touch button on the left edge of the screen and then touching any window(s), panel(s), or object(s) that need to be closed.  When a certain touch button is held down, e.g. an "inspect" button, whatever object the finger touches will be affected accordingly (it will be inspected).  

A touch operation button momentarily specifies what a touch/gesture means just before the touch occurs, then the physical button is released by the user.  The speed and straightforwardness of the interface improves: five objects can be removed from a page quickly by holding down a "remove" operation button, then tapping each of the five objects, then releasing the "remove" touch button.   This kind of setup will allow the user to control software with a wide range of touch operations instead of searching for operations inside the interface.  

Thus, what is convoluted to achieve today on a tablet will not be and what is out of reach will become possible when physical buttons are placed onto the device.  When there are several touch modifier keys to the left of the screen, they can accommodate a wide range of purposes and this is a core feature of a new tablet device.  A “generate” modifier will generate an object at the position of a touch in an empty space, or it will generate a child object for the object that was touched.  For example: five objects can be generated by holding down the "generate" touch button and then tapping the desired locations of the five objects.  For power users, a some of these modifier buttons can be made programmable.  In this scheme, the user will always know how to accomplish tasks because the modifier keys will cover a broad range of activities, because "close" can apply to exiting, or closing something.  



It is also possible that something is deleted not through the use of a "delete" modifier next to a "close" modifier but instead tapping an object twice with "close," with it darkening as a warning that it will be deleted will be the way to delete something.  Other modifier keys include "route" such as for opening a file in a specific application, because "route" is a very generic keyword that can apply to many situations.

We could mention many buttons, such as "group" touch modifier button.  But often operations are in opposition to each other. Opposing touch modifiers (group --- ungroup,  add --- subtract,  generate --- remove) on opposite sides.


NOCTIVAGOUS.GITHUB.IO