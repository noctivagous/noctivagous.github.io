<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=0U9YPQOyyETk9e3hl0rBKJWvJV5Bbvwb-E44677KeT8);.lst-kix_43s5gz7t7f5m-5>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-5}.lst-kix_i691tfqtkrqh-5>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-5}.lst-kix_dtsavrrdqo0t-0>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-0}.lst-kix_i691tfqtkrqh-6>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-6}.lst-kix_43s5gz7t7f5m-6>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-6}ol.lst-kix_i691tfqtkrqh-6.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-6 0}.lst-kix_dtsavrrdqo0t-2>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-2,lower-roman) ") "}ul.lst-kix_yii9rdili81k-0{list-style-type:none}.lst-kix_dtsavrrdqo0t-3>li:before{content:"(" counter(lst-ctn-kix_dtsavrrdqo0t-3,decimal) ") "}ul.lst-kix_yii9rdili81k-1{list-style-type:none}ul.lst-kix_yii9rdili81k-2{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-7{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-8{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-3.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-3 0}.lst-kix_dtsavrrdqo0t-1>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-1,lower-latin) ") "}ol.lst-kix_43s5gz7t7f5m-1{list-style-type:none}.lst-kix_dtsavrrdqo0t-0>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-0,decimal) ") "}ol.lst-kix_43s5gz7t7f5m-2{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-0{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-5{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-6{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-3{list-style-type:none}.lst-kix_i691tfqtkrqh-3>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-3}ol.lst-kix_43s5gz7t7f5m-4{list-style-type:none}.lst-kix_i691tfqtkrqh-0>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-0,decimal) ") "}.lst-kix_i691tfqtkrqh-1>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-1,lower-latin) ") "}.lst-kix_dtsavrrdqo0t-1>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-1}ol.lst-kix_43s5gz7t7f5m-0.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-0 0}ul.lst-kix_2brnjfyn8uhd-0{list-style-type:none}.lst-kix_i691tfqtkrqh-8>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-8}ul.lst-kix_2brnjfyn8uhd-1{list-style-type:none}.lst-kix_i691tfqtkrqh-6>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-6,decimal) ". "}ul.lst-kix_2brnjfyn8uhd-2{list-style-type:none}.lst-kix_i691tfqtkrqh-8>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-8,lower-roman) ". "}.lst-kix_i691tfqtkrqh-2>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-2}.lst-kix_i691tfqtkrqh-5>li:before{content:"(" counter(lst-ctn-kix_i691tfqtkrqh-5,lower-roman) ") "}ul.lst-kix_2brnjfyn8uhd-7{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-7.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-7 0}.lst-kix_i691tfqtkrqh-3>li:before{content:"(" counter(lst-ctn-kix_i691tfqtkrqh-3,decimal) ") "}ul.lst-kix_2brnjfyn8uhd-8{list-style-type:none}.lst-kix_dtsavrrdqo0t-4>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-4}.lst-kix_i691tfqtkrqh-2>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-2,lower-roman) ") "}.lst-kix_i691tfqtkrqh-4>li:before{content:"(" counter(lst-ctn-kix_i691tfqtkrqh-4,lower-latin) ") "}ul.lst-kix_2brnjfyn8uhd-3{list-style-type:none}ul.lst-kix_2brnjfyn8uhd-4{list-style-type:none}ul.lst-kix_2brnjfyn8uhd-5{list-style-type:none}ul.lst-kix_2brnjfyn8uhd-6{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-3.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-3 0}ol.lst-kix_i691tfqtkrqh-7.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-7 0}ol.lst-kix_i691tfqtkrqh-1{list-style-type:none}.lst-kix_dtsavrrdqo0t-3>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-3}ol.lst-kix_i691tfqtkrqh-2{list-style-type:none}ol.lst-kix_i691tfqtkrqh-0{list-style-type:none}ol.lst-kix_43s5gz7t7f5m-6.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-6 0}ol.lst-kix_i691tfqtkrqh-5{list-style-type:none}ol.lst-kix_i691tfqtkrqh-6{list-style-type:none}ol.lst-kix_i691tfqtkrqh-3{list-style-type:none}ol.lst-kix_i691tfqtkrqh-4{list-style-type:none}ol.lst-kix_i691tfqtkrqh-1.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-1 0}ol.lst-kix_i691tfqtkrqh-7{list-style-type:none}ol.lst-kix_i691tfqtkrqh-8{list-style-type:none}.lst-kix_i691tfqtkrqh-7>li:before{content:"" counter(lst-ctn-kix_i691tfqtkrqh-7,lower-latin) ". "}.lst-kix_dtsavrrdqo0t-4>li:before{content:"(" counter(lst-ctn-kix_dtsavrrdqo0t-4,lower-latin) ") "}ul.lst-kix_yii9rdili81k-3{list-style-type:none}.lst-kix_yii9rdili81k-6>li:before{content:"\0025cf   "}ul.lst-kix_yii9rdili81k-4{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-0{list-style-type:none}.lst-kix_yii9rdili81k-5>li:before{content:"\0025a0   "}ul.lst-kix_yii9rdili81k-5{list-style-type:none}.lst-kix_yii9rdili81k-7>li:before{content:"\0025cb   "}ul.lst-kix_yii9rdili81k-6{list-style-type:none}.lst-kix_43s5gz7t7f5m-1>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-1}ul.lst-kix_yii9rdili81k-7{list-style-type:none}ul.lst-kix_yii9rdili81k-8{list-style-type:none}.lst-kix_dtsavrrdqo0t-5>li:before{content:"(" counter(lst-ctn-kix_dtsavrrdqo0t-5,lower-roman) ") "}ol.lst-kix_dtsavrrdqo0t-6{list-style-type:none}.lst-kix_dtsavrrdqo0t-8>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-8,lower-roman) ". "}ol.lst-kix_dtsavrrdqo0t-5{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-8{list-style-type:none}.lst-kix_yii9rdili81k-1>li:before{content:"\0025cb   "}ol.lst-kix_dtsavrrdqo0t-7{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-2{list-style-type:none}.lst-kix_dtsavrrdqo0t-6>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-6,decimal) ". "}.lst-kix_yii9rdili81k-0>li:before{content:"\0025cf   "}.lst-kix_yii9rdili81k-8>li:before{content:"\0025a0   "}ol.lst-kix_dtsavrrdqo0t-1{list-style-type:none}ol.lst-kix_dtsavrrdqo0t-4{list-style-type:none}.lst-kix_dtsavrrdqo0t-7>li:before{content:"" counter(lst-ctn-kix_dtsavrrdqo0t-7,lower-latin) ". "}ol.lst-kix_dtsavrrdqo0t-3{list-style-type:none}ol.lst-kix_i691tfqtkrqh-0.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-0 0}ol.lst-kix_43s5gz7t7f5m-5.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-5 0}ol.lst-kix_dtsavrrdqo0t-8.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-8 0}ol.lst-kix_dtsavrrdqo0t-2.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-2 0}.lst-kix_yii9rdili81k-2>li:before{content:"\0025a0   "}.lst-kix_yii9rdili81k-3>li:before{content:"\0025cf   "}.lst-kix_43s5gz7t7f5m-7>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-7}.lst-kix_yii9rdili81k-4>li:before{content:"\0025cb   "}.lst-kix_43s5gz7t7f5m-4>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-4}.lst-kix_43s5gz7t7f5m-0>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-0,decimal) ". "}ol.lst-kix_i691tfqtkrqh-2.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-2 0}.lst-kix_43s5gz7t7f5m-1>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-1,lower-latin) ". "}ol.lst-kix_43s5gz7t7f5m-7.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-7 0}.lst-kix_dtsavrrdqo0t-7>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-7}.lst-kix_43s5gz7t7f5m-0>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-0}.lst-kix_43s5gz7t7f5m-6>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-6,decimal) ". "}.lst-kix_43s5gz7t7f5m-5>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-5,lower-roman) ". "}ol.lst-kix_dtsavrrdqo0t-1.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-1 0}ol.lst-kix_43s5gz7t7f5m-4.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-4 0}.lst-kix_43s5gz7t7f5m-2>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-2,lower-roman) ". "}.lst-kix_43s5gz7t7f5m-4>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-4,lower-latin) ". "}.lst-kix_dtsavrrdqo0t-6>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-6}.lst-kix_43s5gz7t7f5m-3>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-3,decimal) ". "}.lst-kix_2brnjfyn8uhd-7>li:before{content:"-  "}.lst-kix_2brnjfyn8uhd-8>li:before{content:"-  "}ol.lst-kix_i691tfqtkrqh-8.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-8 0}.lst-kix_2brnjfyn8uhd-6>li:before{content:"-  "}ol.lst-kix_dtsavrrdqo0t-6.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-6 0}ol.lst-kix_dtsavrrdqo0t-4.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-4 0}.lst-kix_2brnjfyn8uhd-3>li:before{content:"-  "}.lst-kix_2brnjfyn8uhd-4>li:before{content:"-  "}.lst-kix_2brnjfyn8uhd-5>li:before{content:"-  "}.lst-kix_43s5gz7t7f5m-7>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-7,lower-latin) ". "}.lst-kix_i691tfqtkrqh-0>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-0}.lst-kix_43s5gz7t7f5m-8>li:before{content:"" counter(lst-ctn-kix_43s5gz7t7f5m-8,lower-roman) ". "}ol.lst-kix_i691tfqtkrqh-5.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-5 0}ol.lst-kix_43s5gz7t7f5m-2.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-2 0}ol.lst-kix_dtsavrrdqo0t-0.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-0 0}.lst-kix_43s5gz7t7f5m-2>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-2}.lst-kix_43s5gz7t7f5m-8>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-8}.lst-kix_43s5gz7t7f5m-3>li{counter-increment:lst-ctn-kix_43s5gz7t7f5m-3}.lst-kix_2brnjfyn8uhd-0>li:before{content:"-  "}.lst-kix_2brnjfyn8uhd-2>li:before{content:"-  "}ol.lst-kix_i691tfqtkrqh-4.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-4 0}.lst-kix_2brnjfyn8uhd-1>li:before{content:"-  "}.lst-kix_dtsavrrdqo0t-8>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-8}ol.lst-kix_i691tfqtkrqh-3.start{counter-reset:lst-ctn-kix_i691tfqtkrqh-3 0}.lst-kix_dtsavrrdqo0t-5>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-5}ol.lst-kix_43s5gz7t7f5m-1.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-1 0}ol.lst-kix_43s5gz7t7f5m-8.start{counter-reset:lst-ctn-kix_43s5gz7t7f5m-8 0}.lst-kix_i691tfqtkrqh-1>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-1}.lst-kix_dtsavrrdqo0t-2>li{counter-increment:lst-ctn-kix_dtsavrrdqo0t-2}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_i691tfqtkrqh-4>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-4}.lst-kix_i691tfqtkrqh-7>li{counter-increment:lst-ctn-kix_i691tfqtkrqh-7}ol.lst-kix_dtsavrrdqo0t-5.start{counter-reset:lst-ctn-kix_dtsavrrdqo0t-5 0}ol{margin:0;padding:0}table td,table th{padding:0}.c1{background-color:#ffffff;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c23{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c19{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c13{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c12{color:#434343;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c18{background-color:#ffffff;color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c17{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Calibri";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c0{margin-left:36pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c4{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c24{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c9{background-color:#ffffff;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Courier New";font-style:normal}.c25{color:#000000;font-weight:500;text-decoration:none;vertical-align:baseline;font-size:25pt;font-family:"Montserrat";font-style:normal}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c20{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c11{font-family:"Courier New";font-weight:400}.c3{padding:0;margin:0}.c16{margin-left:108pt}.c22{height:16pt}.c15{text-indent:36pt}.c14{margin-left:72pt}.c8{height:11pt}.c21{background-color:#ffffff}.c10{padding-left:0pt}.c6{font-size:12pt}.title{padding-top:20pt;color:#000000;font-weight:500;font-size:25pt;padding-bottom:6pt;font-family:"Montserrat";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-weight:700;font-size:26pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c20 doc-content"><p class="c23 title" id="h.emk9phg3spnz"><span class="c25">Noctivagous LLM Wrapper App</span></p><p class="c5"><span class="c1">BEYOND THE CHATBOT APP FORMAT FOR AN LLM</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c18 c6">OVERVIEW</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c1">The AI industry took off when an LLM, GPT3, was interfaced to a GUI web chat interface. &nbsp;This straightforward and accessible means of interacting with an AI model was all it took to capture the public&rsquo;s interest in AI for the first several months of 2023. &nbsp;It served this purpose, to show what was lying behind that enormous model that previously only programmers could utilize. &nbsp;But somehow this basic &ldquo;chat&rdquo; (it isn&rsquo;t actually chatting, after all) GUI software convention became a fixed concept for trying out and making use of an LLM, despite providing little more than a minimalist set of features, a prototype step in app development. &nbsp; It would normally just be regarded as the first stage before the AI company built out a complete suite of front-facing software tools that wrapped around the LLM&rsquo;s generative capabilities, unveiling other facets of the LLMs by providing more GUI methods to form prompts. &nbsp;There are others besides typing words character by character. &nbsp;It is true that the LLM accepts complete sentences unlike previous computing technologies but the front-end app developer shouldn&#39;t necessarily ask the user to type out sentences to use the AI&ndash; nor does the LLM even require complete sentences to respond to prompts. &nbsp;It&rsquo;s actually the opposite, that it accepts all kinds of input combinations, and this shows that much variety among front-end apps could exist for interfacing to an LLM besides this simplistic &ldquo;chatbot&rdquo;. &nbsp;Other, more succinct forms of instructions exist in software already and they can be adapted to an LLM interactively so that the process is not so laborious.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">If the situation were more balanced in terms of pairing traditional app developers with AI researchers, there would be another step of evolution in app software for interacting with an LLM, something going beyond this quasi-chat. &nbsp;It would begin with a GUI software method to make prompts rapidly through keyboard shortcuts perhaps. &nbsp;The prompts would make sense when read on screen but they wouldn&rsquo;t necessarily exist in the form of complete sentences or paragraphs received by a human. &nbsp;There are plenty of techniques for making a GUI that generates prompts ready for an LLM without making the user type out everything from scratch as a complete sentence each time, something fatiguing for everyone and also rather odd for an entire industry to rely on exclusively when testing out and experiencing AI. &nbsp;This might involve, for example, providing pre-made building blocks that line up one after another inside the text box that are assembled in real time by the user with the keyboard shortcuts. &nbsp;These prompts wouldn&rsquo;t be tiresome to put together like writing out complete sentences for the AI and treating it as if it were human. &nbsp;The situation would be even better if these building blocks were served in an organized way, as predefined templates and categorized.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">What is currently interfaced to the LLM is like a garden hose feeding into a giant, olympic size swimming pool; it is going to take a lot of time for anyone to make use of what is there. &nbsp;A chatbot front-end is a disproportionately small interactive format compared to what the LLM offers. &nbsp;It is an incomplete and limited workflow for making use of the enormous model in the times when it is accessed through an interactive gateway. &nbsp; In any case, after all of the typing out has taken place for the machine&rsquo;s sake, a person does feel like his writing effort has been wasted formulating complete sentences for nobody&ndash; a machine that cannot appreciate that so much work was put into crafting a single AI instruction that is as complete as a short e-mail. &nbsp;Put simply, the situation is one of inefficiency and limitations on the front-end side given how much money is poured into training these models. &nbsp;So much front-end potential has been missed as a result of everyone fixating on the chatbot format. &nbsp;More accurately, so much potential has been wasted as a result of everyone remaining ignorant of how a chatbot should be seen as nothing but prototypal and bare for all of the training time put into an LLM. &nbsp;</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">The public&rsquo;s indifference to ChatGPT after the hype wore off should at least be noticed and the primary cause is that the chatbot format has no future. &nbsp;At the same time, it takes an app developer to point this out and may not be something the typical AI researcher would acknowledge.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">First, ask the question of how a person would use an LLM on a touchscreen tablet computer without typing on a keyboard (would it be navigating a cloud or tree of touchable labels?) and this is a way to break out of the notion that the chatbot app format is synonymous with interacting with an LLM in front-end software. &nbsp;Using chat to enhance business workflows is also a weak approach and has yielded little in terms of gains.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">The objective of this future (web-based) application is to build out a more complete app experience.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">This app will expand the number of GUI controls and conventions &nbsp;for</span></p><p class="c5 c15"><span class="c1">1) formulating prompts</span></p><p class="c5 c15"><span class="c1">2) interacting with the generated chat responses. &nbsp;</span></p><p class="c5 c15 c8"><span class="c1"></span></p><p class="c5"><span class="c1">Compared to the bare chatbot format, this app should provide the user a broader range of tools that interface to AI.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c6 c18">STOCK TEMPLATE COMMANDS</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">First, the chat prompt input area will no longer be limited to typing out prompts from scratch each time. &nbsp;To the left of the text input box will be placed a panel with a list of stock template commands for prompts. &nbsp;Once a command is clicked on, this will insert the phrase or &nbsp;keyword into the chat prompt input box. This gives the user some direction from the outset instead of just an empty text box. &nbsp;What will be inserted into the box by clicking on a command is a graphically encapsulated keyword (for a reference, it should remind a person of Apple&rsquo;s NSTokenField UI objects).</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c6 c21">Example template commands include the commonly used </span><span class="c11 c6">SUMMARIZE: [TEXT]</span><span class="c6">&nbsp; but also </span><span class="c11 c6">EXPLAIN: [TEXT], SUGGEST ADDITIONS FOR:[TEXT]</span><span class="c6">, &nbsp;</span><span class="c11 c6">SUGGEST MODIFICATIONS FOR:[TEXT DATA],</span><span class="c6">&nbsp;</span><span class="c11 c6">MAKE OUTLINE OF:[TEXT]</span><span class="c6">&nbsp;and </span><span class="c6 c11">COMPARE [TEXT] WITH [TEXT]</span><span class="c6">. &nbsp;All of these will be available for insertion as graphically encapsulated terms. &nbsp; There are many commands type out for AI chatbots that recur in their sentences and they are categorizable. But until now they have not been collected and then provided to the AI user in an app suite to serve as entry points for interacting with AI. &nbsp;These are what will be included in the stock template library. &nbsp;At a later point users will be able to add their own as well. &nbsp;The template command </span><span class="c11 c6">COMPARE [TEXT] WITH [TEXT]</span><span class="c6">&nbsp;a</span><span class="c7 c6">llows comparing details of two similar products found online, to give a specific usage example.</span></p><p class="c5 c8"><span class="c6 c7"></span></p><p class="c5"><span class="c6">Should the output of that comparison be in paragraph form or a table? &nbsp;The user can decide in advance by selecting the format of the output response: </span><span class="c11 c6">[TABLE, LIST, PROSE]</span><span class="c7 c6">. &nbsp;The (checkbox) controls for this are placed next to the text input area. &nbsp;Should the response data be TXT, HTML, RTF, or JSON? &nbsp;The controls for this setting can be accessed from the text input area as well.</span></p><p class="c5 c8"><span class="c7 c6"></span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">MODIFIABLE CHAT OUTPUT FOR REVISING AND FEEDING BACK INTO AI.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">A chat response will not just be static text for the Control+C operation but instead</span></p><ol class="c3 lst-kix_43s5gz7t7f5m-0 start" start="1"><li class="c5 c14 c10 li-bullet-0"><span class="c1">Will be editable by the user (where it sits) with an inline text editor activated by the user.</span></li><li class="c5 c14 c10 li-bullet-0"><span class="c1">Will be transformable by AI (where it sits in the chat). It will be replaced with another chat response when the user provides a modifying prompt.</span></li></ol><ol class="c3 lst-kix_43s5gz7t7f5m-1 start" start="1"><li class="c5 c16 c10 li-bullet-0"><span class="c1">These modifying prompts can be formulated with convenience functions that are accessible to the right side of the chat response area.</span></li></ol><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">In addition, a chat response</span></p><ol class="c3 lst-kix_43s5gz7t7f5m-0" start="3"><li class="c5 c14 c10 li-bullet-0"><span class="c1">Will be deletable from the chat sequence.</span></li><li class="c5 c14 c10 li-bullet-0"><span class="c1">Will be movable, out of the chat sequence into a different chat sequence or a separate project bin/folder.</span></li></ol><p class="c5 c8"><span class="c1"></span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">Instead of just watching every response pile up as part of a long, scrollable list of chat responses, the user has other options for working with the AI output. &nbsp;He can remain with and revise a single AI response repeatedly, as mentioned above. For this there will be interface options to edit the text that was generated and apply prompts to it. &nbsp;This adds a small requirement that there is an undo manager attached to each chat response after it is modified.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">THE PROMPT INPUT BOX AS A LIST</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">The prompt area in the app should resemble something like an Automator script (the 2005 Mac OS X program) in which configurable GUI components are stacked in a list. &nbsp;So instead of just text and an image attachment which is the current setup, a prompt may have more than one component included in it. &nbsp;So for the user there will be provided the ability to append multiple text area input boxes within the prompt input box. &nbsp;That is to say the prompt input box will be an empty holder for a dynamic list, with multiple data types available for the user. &nbsp;(This allows an extensible setup for the future for adding more data types.) &nbsp;To begin with, data types will include:</span></p><p class="c0"><span class="c1">Stock template command</span></p><p class="c0"><span class="c1">Text area</span></p><p class="c0"><span class="c1">Image</span></p><p class="c0 c8"><span class="c1"></span></p><p class="c5"><span class="c1">An example list:</span></p><p class="c5 c15"><span class="c6 c9">[COMMAND] + [TEXT AREA] + [COMMAND] + [TEXT AREA]</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">Through the use of keyboard shortcuts or clicking on [TEXT AREA] and the stock template commands, the components will be inserted right away into the prompt input box. &nbsp;This is the key difference from Automator which is that the components to be inserted into the prompt input box will be inserted with a click or a keystroke instead of being dragged. &nbsp;</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c21 c6">(As an aside, it is the goal of Noctivagous in the future to replace conventional dragging in which the mouse button is held down with key-click UI dragging, in which two keystrokes establish the source and destination.)</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">BETTER CONTROL OVER INTERACTION WITH THE LLM &nbsp;</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">With this app the user should be able to more effectively shape prompts, access stock prompts, reshape the output given by the AI, and immediately download the output in the desired file format, the one that is best for its destination. &nbsp;The entire chat sequence can be downloadable as a PDF, Word file, or HTML file, which will facilitate later utilization of the AI output </span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">By providing a collection of revision tools in-line for engaging with an LLM, the AI is utilized as a tool rather than an interlocutor.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">At the tail of each chat response will be a set of controls for making revisions or relevant follow-up responses, such as &ldquo;REVISE OUTPUT to Include [TEXT] AND/OR Exclude [TEXT]&rdquo;. &nbsp;The AI itself will be instructed to provide suggestions for follow-up responses that the user can click on.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">The general chat settings will also include omitting any introductions and conclusions. &nbsp;Modes include generating output that does not contain any lists and is only prose. &nbsp;By controlling the output of an LLM and using tools that can make use of it, this very broad technology can be experienced more powerfully than the current, plain interactive chatbot format.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">In the future it will be possible to provide use cases as a library of premade configurations of the app, much in the same way that users of a page layout software application are provided page templates so that they don&rsquo;t have to start from scratch each time.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">LAYOUT OF INCOMING AI RESPONSES</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">To begin with, the first requirement when building this app is that the tokens as they come in are placed inside a multiple column layout (like a newspaper or magazine) so that little or no scrolling is required to read the output.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">The quantity of text output in the response will be controlled with a slider control, sitting next to the text input box, that ranges from &ldquo;paragraph&rdquo; to &ldquo;multiple pages.&rdquo;</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5 c8"><span class="c1"></span></p><h2 class="c13" id="h.ny5731r4ujk6"><span>General </span><span class="c4">Goals of the App</span></h2><p class="c5 c8"><span class="c1"></span></p><ul class="c3 lst-kix_yii9rdili81k-0 start"><li class="c0 c10 li-bullet-0"><span class="c1">Make convenient the process of formulating prompts beyond typing.</span></li><li class="c0 c10 li-bullet-0"><span class="c1">Make easier and more accessible the process of making useful prompts by providing a variety of stock template prompts</span></li><li class="c0 c10 li-bullet-0"><span class="c1">Let the user control the quantity of text, style of the output, and data format of the output coming from the AI with GUI controls and settings sitting near the text input box that can be hidden or shown.</span></li><li class="c0 c10 li-bullet-0"><span class="c1">Place the AI&rsquo;s generated responses into a page design layout that demands little scrolling from the user as it fills up with the LLM&rsquo;s reply. &nbsp;The app should also permit activating an overview presentation of all chat responses, such as in the form of scaled down items on a grid.</span></li><li class="c0 c10 li-bullet-0"><span class="c1">Provide functionality for revision of output in the chat sequence itself.</span></li></ul><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">Eventually the GUI control containing data that provides the AI its prompts will not be limited to a text UI control but instead will include larger, premade units like building blocks as well as patches (as in node-based programming&rsquo;s patches). &nbsp;The user would be allowed to choose which way to communicate with the LLM: typing with text (with convenience functions and templates nearby), building blocks, or patches.</span></p><h2 class="c13" id="h.xdjlxz67d2s5"><span>App</span><span class="c4">&nbsp;Philosophy</span></h2><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">1) The AI (LLM) will be treated principally as a tool requiring lots of custom software interfaces to access its capabilities instead of (currently) an interlocutor that carries immense capabilities as a tool (e.g. ChatGPT) that are only acknowledged secondarily to the format of chat. The situation is rather bare and they are available only in minimal amounts in terms of software interactivity.</span></p><p class="c5"><span class="c1">2) Since the LLM is utilized as a tool first, whatever interacts with the AI will need to feature multiple facets for accessing its capabilities, providing many conveniences for the user rooted in traditional software workflows.</span></p><p class="c5 c8"><span class="c1"></span></p><p class="c5"><span class="c1">If possible it is also a goal to help the user feel the vast scope of the LLM&rsquo;s contents so that he or she recognizes that it contains an immense amount of accessible knowledge in all domains that the researchers found training data. &nbsp;This will involve a second set of objectives relating to incorporating features of taxonomy.</span></p><h1 class="c23" id="h.20ekzh4yyetp"><span class="c17">MORE SPECIFICATIONS</span></h1><h2 class="c13" id="h.ytdowhia1l0j"><span class="c4">OUTPUT LAYOUT AND CONTROLS</span></h2><p class="c0 c8"><span class="c2"></span></p><ol class="c3 lst-kix_dtsavrrdqo0t-0 start" start="1"><li class="c0 c10 li-bullet-0"><span class="c2">By default, so that all text can be evaluated by the user as it arrives, text received from the LLM is progressively appended inside of multiple text container columns, magazine/newspaper style, with 3 columns set by default. &nbsp;This is in place of the single column.</span></li><li class="c0 c10 li-bullet-0"><span class="c2">An option is provided to feed generated text into a clipped, portrait (8.5&rdquo; x 11&rdquo; or 1:1.294) text area that has been scaled down to 70%. &nbsp;The text area will have scrollbars appear on overflow.</span></li><li class="c0 c10 li-bullet-0"><span class="c2">Chat responses can be viewed as a set of grid items, each at 50% scale.</span></li><li class="c0 c10 li-bullet-0"><span class="c2">A slider is made prominent for the maximum chat output length, above or to the side of the chat input box, with markings going from &ldquo;paragraph&rdquo; to &ldquo;several pages&rdquo;.</span></li><li class="c0 c10 li-bullet-0"><span class="c2">Chat responses can be collapsed accordion-style inside the chat sequence. They can also be deleted from a chat sequence, to allow clearing out irrelevant or unwanted chat responses. &nbsp;All chat responses can be edited and reordered.</span></li></ol><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">The chat input box is placed at the top of the window instead of the bottom. &nbsp;It will eventually allow insertion of rich text, including tables and coloring of computer code. It can expand to the height of the viewport (the browser/window height).</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c0 c8"><span class="c2"></span></p><h2 class="c13" id="h.8sr8hrjbiw7u"><span class="c4">CHAT RESPONSES ARE TREATED AS DYNAMIC UI OBJECTS, EXIST AS NOTEBOOK CLIPPINGS</span></h2><p class="c0 c8"><span class="c2"></span></p><ol class="c3 lst-kix_dtsavrrdqo0t-0" start="6"><li class="c0 c10 li-bullet-0"><span class="c2">Chat responses will not be fixed like they are today, requiring copy and paste to change or make use of them. &nbsp;Their essential state at the code level is a notebook clipping that can be moved around and edited by the user in the chat window. &nbsp;</span></li></ol><p class="c5 c14"><span class="c2">. </span></p><ol class="c3 lst-kix_dtsavrrdqo0t-1 start" start="1"><li class="c5 c14 c10 li-bullet-0"><span class="c2">Chat responses can be transformed by the user in-line in multiple ways. First,hey can be modified by applying another chat operation to them, with the operations accessed by a menu at the bottom of the chat response. &nbsp;In other words, the LLM&rsquo;s API will operate on the chat response itself it just gave inside its container according to what the user has requested, whether it is a transformation of data state or copy revision. That is, it will transform the data inside the response text control and replace the previous text. &nbsp;</span></li></ol><ol class="c3 lst-kix_dtsavrrdqo0t-2 start" start="1"><li class="c5 c10 c16 li-bullet-0"><span class="c2">In terms of content, the user can instruct any number of changes to be applied by the AI. </span></li><li class="c5 c16 c10 li-bullet-0"><span class="c2">In terms of data format it might be transformed into or from a table, a list, paragraph form.</span></li></ol><p class="c5 c14"><span class="c2">The text area that contains a chat response can be changed back and forth from static text (as it is everywhere today) into a text editing control so that the user can make successive transformations inside the chat response and get the outcome he or she wants. &nbsp;The person may edit the response then apply another AI operation to the text and so on. &nbsp;Accordingly, there is an undo manager attached to each chat response box, a history of changes, so that the user can go back. &nbsp; When the user is finished, the chat response, existing fundamentally as a notebook clipping at all times, can be moved to a bin inside the app, it can be e-mailed, etc. or downloaded in any format for permanent storage. &nbsp;Each chat response notebook clipping has a download control with options for download format so that this does not have to be the same as the contents of the chat clipping itself.</span></p><ol class="c3 lst-kix_dtsavrrdqo0t-1" start="2"><li class="c5 c14 c10 li-bullet-0"><span class="c2">Notebook clippings are not tied to a single chat window but can be moved into bins. &nbsp;A chat session is a list of editable text controls that can be reordered, revised, and copy-edited so that it is exportable to file to serve as the basis of an eventual document for the user.</span></li></ol><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><h2 class="c13" id="h.prblm1q59vsq"><span class="c4">CHAT OUTPUT TAIL MENU: FOLLOW UP COMMANDS</span></h2><p class="c5"><span class="c2">For each response, the AI is asked to make a list (which is placed inside a dropdown menu) at the end of each chat response with five possible follow-up requests, and this allows context-specific operations to occur by the user. &nbsp;In the UI beneath each chat response is a standard set of operations for follow-up requests as well.</span></p><p class="c5"><span class="c2">- A menu appears at the bottom of every chat response</span></p><p class="c5"><span class="c2">allowing the user to modify the original prompt </span></p><p class="c5"><span class="c2">or respond to the chat. &nbsp;This includes the AI-generated modification prompts provided inside the response that are specific to it as well as the standard ones.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><h2 class="c13" id="h.at1wiqwv4eh8"><span class="c4">BUILDING LLM PROMPTS</span></h2><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">-- Rectangular building blocks components replace typewritten</span></p><p class="c5"><span class="c2">prompts. &nbsp;Each component contains GUI controls for its parameters</span></p><p class="c5"><span class="c2">and is around 200 pt x 200 pt. &nbsp;When there is more than one they </span></p><p class="c5"><span class="c2">flow like text. &nbsp;A prompt is made out</span></p><p class="c5"><span class="c2">of one or more of these building blocks.</span></p><p class="c5"><span class="c2">Each building block makes up the prompt, allowing rapid</span></p><p class="c5"><span class="c2">construction of parametric prompts rather than just verbal ones.</span></p><p class="c5"><span class="c2">The container for making a prompt out of these components </span></p><p class="c5"><span class="c2">can be made as large as a page.</span></p><p class="c5"><span class="c2">-- The AI itself can be requested to make relevant prompts</span></p><p class="c5"><span class="c2">and this will be incorporated into the app.</span></p><p class="c5 c8"><span class="c2"></span></p><h2 class="c13" id="h.umikz57lcqwy"><span class="c4">STANDARD APP SOFTWARE FUNCTIONALITY</span></h2><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">- Export contents of selected output control</span></p><p class="c5"><span class="c2">to document, .RTF, .PDF, .TXT, .CSV, .XLSX.</span></p><p class="c5"><span class="c2">- AI-generated tabular data appears as interactive table</span></p><p class="c5"><span class="c2">in the app.</span></p><p class="c5"><span class="c2">- AI-generated map data appears on an interactive map.</span></p><p class="c5"><span class="c2">- Print selected output control.</span></p><p class="c5"><span class="c2">- Functions for reformatting data output are provided.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><h2 class="c13" id="h.40s79vlypt91"><span class="c4">PROMPT KEYWORDS COMBINED WITH PASTE AREAS AND DROPDOWN MENUS</span></h2><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">The purpose is to provide keywords that are generic enough that they apply to a multitude of circumstances.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c0"><span class="c2">CONTINUE: [PASTE AREA]</span></p><p class="c0"><span class="c2">EXPLAIN: [PASTE AREA]</span></p><p class="c0"><span class="c2">REACT TO: [PASTE AREA]</span></p><p class="c0"><span class="c2">COMPARE: [PASTE AREA 1] &nbsp;TO [PASTE AREA2]</span></p><p class="c0"><span class="c2">COMPARE: [TABLE CONTROL WITH PASTE CAPABILITIES]</span></p><p class="c0"><span class="c2">EXPAND ON CONTENTS OF TEXT:</span></p><p class="c0"><span class="c2">SUMMARIZE:</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">SUGGEST MODIFICATIONS:</span></p><p class="c0"><span class="c2">SUGGEST ADDITIONS:</span></p><p class="c0"><span class="c2">MAKE VARIATIONS OF: (such as for paraphrasing but not limited to this specific case)</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">VERIFY FACTUALITY:</span></p><p class="c0"><span class="c2">CHANGE [TONE/VOICE/PERSPECTIVE]:</span></p><p class="c0"><span class="c2">LIST INSTANCES OF [PASTE AREA] FROM:</span></p><p class="c0"><span class="c2">MAKE OUTLINE OF:</span></p><p class="c0"><span class="c2">MAKE SUGGESTIONS FOR HOW TO CARRY OUT:</span></p><p class="c0 c15"><span class="c1">suggest the beginning steps of the first part to carry this out</span></p><p class="c0 c15"><span class="c1">Make up specifics</span></p><p class="c0"><span class="c2">OUTLINE THE STEPS [TO CARRY OUT]...</span></p><p class="c0"><span class="c2">MERGE WITH [PASTE AREA]</span></p><p class="c0"><span class="c2">PROVIDE PLANNING [HOW TO CARRY OUT A CHORE OR TASK]:</span></p><p class="c0"><span class="c2">DIAGNOSE PROBLEM:</span></p><p class="c0"><span class="c2">SUGGEST SOLUTIONS FOR PROBLEM:</span></p><p class="c0"><span class="c2">CONVERT:</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">MAKE ANALOGY FOR: [PASTE AREA]</span></p><p class="c0"><span class="c2">RELATE [PASTE AREA] TO [PASTE AREA]</span></p><p class="c0"><span class="c2">CONTRAST [PASTE AREA] WITH [PAST AREA]</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c19">GENERATION</span></p><p class="c0"><span class="c2">Make a template for</span></p><p class="c0"><span class="c2">FILL IN THE FOLLOWING [e.g. html] TEMPLATE [PASTE AREA FOR TEMPLATE] WITH THIS DATA [PASTE AREA FOR DATA]</span></p><p class="c0"><span class="c2">ANALYZE AND APPLY HEADING STYLES TO THE FOLLOWING TEXT [PASTE AREA] &nbsp; [ [X] WITH FONT: [Arial] ]</span></p><p class="c5 c8"><span class="c2"></span></p><h3 class="c24" id="h.jedx2w4xjrxx"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REFINEMENT</span></h3><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OMIT</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INCLUDE</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;EXCLUDE</span></p><p class="c5 c8"><span class="c2"></span></p><h3 class="c15 c24" id="h.dyamdzut9de5"><span class="c12">CHANGING SOURCE</span></h3><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RESPOND WITH SOLUTIONS [FROM ONLINE FORUMS]</span></p><p class="c5 c15"><span class="c2">RESPOND WITH SOLUTIONS [FROM ANCIENT TIMES]</span></p><p class="c5 c15 c8"><span class="c2"></span></p><p class="c5 c15 c8"><span class="c2"></span></p><p class="c0"><span class="c19">PROMPT REVISION&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FUNCTIONALITY</span></p><p class="c0"><span class="c2">- Qualities: add [more or less] of [quality].</span></p><h2 class="c13 c22" id="h.t9md0ey16s6"><span class="c4"></span></h2><h2 class="c13" id="h.yby2j290n6s4"><span class="c4">PROMPT STOCK TEMPLATE COMMANDS + CONTROLS IN JSON</span></h2><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">// Order of array contents matters for each stock prompt command because</span></p><p class="c5"><span class="c2">Compare PasteArea1 With PasteArea2 &nbsp;is four separate objects in sequence.</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c5"><span class="c2">promptKeywordCommands = [{</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compare = {[ {&ldquo;CommandText&rdquo; : &ldquo;COMPARE&rdquo;}, {&ldquo;UIControl&rdquo; : &ldquo;TextAreaRichText&rdquo;}, &nbsp;{&ldquo;CommandText&rdquo; = &ldquo;WITH&rdquo;} {&ldquo;UIControl&rdquo; : &ldquo;TextAreaRichText&rdquo; }]}, </span></p><p class="c5"><span class="c2">etc.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">]</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><h2 class="c13" id="h.jhld2bibjp8c"><span class="c4">CONTROLS USED IN THE APP:</span></h2><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">RICH TEXT CONTROL</span></p><p class="c5"><span class="c2">TABLE CONTROL</span></p><p class="c5"><span class="c2">PLAIN TEXT CONTROL</span></p><p class="c5"><span class="c2">CODE EDITOR CONTROL WITH HIGHLIGHTING</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><h2 class="c13" id="h.584jlljjfssv"><span class="c4">FIRST VERSION</span></h2><p class="c5 c8"><span class="c2"></span></p><ol class="c3 lst-kix_i691tfqtkrqh-0 start" start="1"><li class="c0 c10 li-bullet-0"><span class="c2">TEXT BOX AT TOP OR LEFT COLUMN AS 20% OF VIEWPORT WIDTH and 100% OF VIEWPORT HEIGHT.</span></li></ol><ol class="c3 lst-kix_i691tfqtkrqh-1 start" start="1"><li class="c5 c14 c10 li-bullet-0"><span class="c2">Typing into left column spanning height of viewport</span></li></ol><ol class="c3 lst-kix_i691tfqtkrqh-0" start="2"><li class="c0 c10 li-bullet-0"><span class="c2">IN OUTPUT AREA FEED GENERATED AI TEXT INTO THREE NEWSPAPER COLUMNS WITH 10PT GUTTERS (GAPS).</span></li></ol><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><h2 class="c13" id="h.v76k6n1preie"><span class="c4">BOOLEAN OPTIONS</span></h2><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">[ &nbsp;] RESPONSE IS HTML WITH RELEVANT HYPERLINKS EMBEDDED THROUGHOUT</span></p><p class="c5"><span class="c2">[ &nbsp;] MAKE LIST OF REFERENCES WITH HYPERLINKS AT BOTTOM</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><h2 class="c13" id="h.43tcb7rtlsjv"><span class="c4">AICHATPROMPT:// URL HYPERLINKS IN CHAT RESPONSES</span></h2><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">EMBEDS OF AICHATPROMPT:// HYPERLINKS THROUGHOUT TEXT ALLOW THE USER TO CLICK ON WORDS, PHRASES, AND PARAGRAPHS CHOSEN BY THE AI THAT WILL EXPAND ON THOSE TOPICS IN A SEPARATE CHAT RESPONSE.</span></p><p class="c5 c8"><span class="c2"></span></p><ul class="c3 lst-kix_2brnjfyn8uhd-0 start"><li class="c0 c10 li-bullet-0"><span class="c2">THIS THEN LEADS INTO THE FACT THAT SOME CALLS TO THE LLM CAN BE SHORT REQUESTS AND FOR BEING DISPLAYED IN A SMALL CONTEXT, LIKE A POPOVER THAT PROVIDES AN EXPLANATION OF A TERM. &nbsp;CALLS TO THE LLM CAN BE APPLIED TO GUI CONTEXTS LARGE (FULL TEXT CHAT RESPONSE) DOWN TO SMALL (E.G. POPOVER)</span></li></ul><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><h1 class="c23" id="h.p4c59t1oxr6s"><span class="c17">PREVIOUS ARTICLE</span></h1><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">MAKING THE LLM GO MAINSTREAM</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">A Versatile, Fully-Developed, General Use</span></p><p class="c5"><span class="c2">Software Application Suite </span></p><p class="c5"><span class="c2">Acting As An LLM Wrapper Is How</span></p><p class="c5"><span class="c2">Current AI Technology Can Finally </span></p><p class="c5"><span class="c2">Be Adopted By The Public</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">noctivagous.github.io</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">The potential and utility of an LLM is still hidden.</span></p><p class="c5"><span class="c2">A much more developed category of wrapper app for an LLM</span></p><p class="c5"><span class="c2">should be the priority of the AI community, one that goes</span></p><p class="c5"><span class="c2">beyond the basic AI chat format in which the user is</span></p><p class="c5"><span class="c2">given a free-form textbox and responses are stacked vertically. &nbsp;</span></p><p class="c5"><span class="c2">Interacting with the LLM is confined to typing out prompts from scratch</span></p><p class="c5"><span class="c2">each time; there is no developed workflow for modifying</span></p><p class="c5"><span class="c2">prompts, crafting them parametrically, or viewing the </span></p><p class="c5"><span class="c2">output in different views or presentations. &nbsp;There are </span></p><p class="c5"><span class="c2">many uses for an LLM but the user is supposed to reduce </span></p><p class="c5"><span class="c2">them into a text box. Whatever comes out is supposed to </span></p><p class="c5"><span class="c2">suffice if it is just a stream of text, a chat response.</span></p><p class="c5"><span class="c2">Few genuinely sophisticated features have </span></p><p class="c5"><span class="c2">been provided on the front-end to serve the end user, </span></p><p class="c5"><span class="c2">at least by the major AI vendors.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">The new user is placed in front of the text box and then</span></p><p class="c5"><span class="c2">told, &quot;Now go! Ask for whatever you want!&quot; which sounds great at first, like an opportunity to interact with a genie in a bottle. &nbsp;In reality, instructions for work jobs are more complex</span></p><p class="c5"><span class="c2">than discrete and simple requests made out of sentences. They have</span></p><p class="c5"><span class="c2">parameters, settings, modes that surround the request the person</span></p><p class="c5"><span class="c2">is making. &nbsp;In addition to this, the person should be surrounded</span></p><p class="c5"><span class="c2">by available resources such as the images, documents, and snippets</span></p><p class="c5"><span class="c2">of text he wants to make use of with this machine.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">Current AI technology cannot succeed by way of simplistic chat-formatted responses</span></p><p class="c5"><span class="c2">generated from an LLM. &nbsp;After all, in the workplace a person is provided</span></p><p class="c5"><span class="c2">a complete document of specifications to carry out a job, not just a few sentences. </span></p><p class="c5"><span class="c2">The analogue to this for an LLM would be a set of parametric components, </span></p><p class="c5"><span class="c2">settings, controls, and areas for stored resources that can be included in</span></p><p class="c5"><span class="c2">the queries. &nbsp;The queries themselves need to be made in different ways,</span></p><p class="c5"><span class="c2">whether it is typing them out or wiring them up.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">The &quot;genie in a bottle&quot; format in which the person gets a wish</span></p><p class="c5"><span class="c2">granted with a sentence, its response format in which the person</span></p><p class="c5"><span class="c2">clarifies or corrects the response provided is limited and</span></p><p class="c5"><span class="c2">contrasts with the natural condition of everyday life in which a </span></p><p class="c5"><span class="c2">set of commands comes in structured, in bulk, and may (as in the</span></p><p class="c5"><span class="c2">case of specifications) have charts and other non-verbal descriptions</span></p><p class="c5"><span class="c2">of the demands.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">When you want something complex done do you tell a person who doesn&#39;t know you </span></p><p class="c5"><span class="c2">just one line or a few sentences? &nbsp;Will it all be verbal information?</span></p><p class="c5"><span class="c2">No, you send them a document with detailed specifications and it may have</span></p><p class="c5"><span class="c2">a table included. &nbsp;So the LLM has to be able to receive</span></p><p class="c5"><span class="c2">commands in all kinds of ways and the only way to do that is to provide</span></p><p class="c5"><span class="c2">a complete suite for input settings, input methods and output setting</span></p><p class="c5"><span class="c2">and output methods. &nbsp;What should be part of any query would be</span></p><p class="c5"><span class="c2">a bundle of things and the app makes this possible.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">The small LLM text box amounts to a prototypal, unfinished situation</span></p><p class="c5"><span class="c2">in which the user laboriously starts from scratch each time to compose</span></p><p class="c5"><span class="c2">short prompts, writing instructions out all over again for every minor tweak</span></p><p class="c5"><span class="c2">when something wasn&#39;t quite right, writing paragraphs of prose and </span></p><p class="c5"><span class="c2">complete sentences for every revised interaction. &nbsp;Because the LLM </span></p><p class="c5"><span class="c2">might not provide what was wanted the first time, revisions and tweaks </span></p><p class="c5"><span class="c2">are inevitable for everyone. It&#39;s all too exhausting and incompatible </span></p><p class="c5"><span class="c2">with mainstream adoption of AI.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">To surpass the limitations of the AI chat format,</span></p><p class="c5"><span class="c2">this future app should seek to provide an application suite</span></p><p class="c5"><span class="c2">of prompt-making functionality, crafted by the product makers</span></p><p class="c5"><span class="c2">in accordance with how people generally end up using (or could use)</span></p><p class="c5"><span class="c2">an LLM, divided into modules or categories inside the app. &nbsp;</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">Categories and app sections can include the following.</span></p><p class="c5"><span class="c2">The first is the most freeform. &nbsp;Each category, when activated</span></p><p class="c5"><span class="c2">displays a collection of specialized controls and functionality</span></p><p class="c5"><span class="c2">specific to that category. &nbsp;For dealing with text,</span></p><p class="c5"><span class="c2">common text software tools are built into that mode or section</span></p><p class="c5"><span class="c2">of the app, something of value to many scholars.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">1) (Default Mode) - Continue / Comment On / Make Response to (provided text).</span></p><p class="c5"><span class="c2">2) Inquiry/Explain a Subject - Generate a profile or background on a topic. &nbsp;</span></p><p class="c5"><span class="c2">Provide reading list for subject.</span></p><p class="c5"><span class="c2">3) Manufacture / Generate - literature, poem, essay, possible business names, recipes, etc.</span></p><p class="c5"><span class="c2">4) Programming / Code - &nbsp;Templates, Generate Code, Evaluate Code, Rewrite Code.</span></p><p class="c5"><span class="c2">5) How-to (How to Do a Thing) - &nbsp;Solutions for a Problem. &nbsp;Practical Skills. &nbsp;Everyday </span></p><p class="c5"><span class="c2">Reference. Domestic chores.</span></p><p class="c5"><span class="c2">6) Veracity Check - (find out if something is true generally).</span></p><p class="c5"><span class="c2">7) Work with Texts - &nbsp;Explain provided (especially older) text. &nbsp;Translate. Dictionary word lookup. </span></p><p class="c5"><span class="c2">Text passage origin / its meaning / summary. &nbsp;Extract summary of only</span></p><p class="c5"><span class="c2">certain type of information from the document.</span></p><p class="c5"><span class="c2">8) Data: Generate or Retrieve (e.g. avg. weather for a region). &nbsp;Reformat operations for </span></p><p class="c5"><span class="c2">provided data. Check for a condition inside provided data/text. &nbsp;Analyze.</span></p><p class="c5"><span class="c2">9) Converse or Simulate Interaction: role-playing, simulated interviews,</span></p><p class="c5"><span class="c2">language learning, and other interactive sessions designed to mimic real-life interactions.</span></p><p class="c5"><span class="c2">10) Education/Reading: Provide typical course curriculum for a subject. &nbsp;</span></p><p class="c5"><span class="c2">Provide reading list. Describe prerequisites for taking up a subject.</span></p><p class="c5"><span class="c2">Make quizzes, tests.</span></p><p class="c5"><span class="c2">11) Proofread / Copyedit / Rephrase</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">For any activity that makes use of an LLM there </span></p><p class="c5"><span class="c2">will have to be uses crafted for them. &nbsp;The &quot;Work with Texts&quot; will</span></p><p class="c5"><span class="c2">reflect what people do when they work with texts. &nbsp;This is not</span></p><p class="c5"><span class="c2">an automatic thing.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">----</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">OPERATIONS FOR AN LLM WRAPPER</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">Common operations would be EXTEND, which is to take</span></p><p class="c5"><span class="c2">existing input and go further with it. &nbsp;REVISE.</span></p><p class="c5"><span class="c2">EVALUATE ACCURACY. &nbsp;</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">----------------------------</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">Provide the LLM wrapper a YouTube URL</span></p><p class="c5"><span class="c2">and it will summarize the transcript.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">----------------------------</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">--- SETTINGS IN THE UI ---</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">PARAMETERS, BUTTONS, AND CONTROLS.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">CURRENT OUTPUT MODE: [RTF] (HTML/PDF/TXT)</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">OUTPUT RESULTS OF QUERY: </span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- to a table</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- to a code text box</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- to a web page</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c5"><span class="c2">STYLE THE RESULTS</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- with headings</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- body text font: [Times New Roman] (14pt)</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- heading font: [Arial] (Bold) (18pt)</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">EXPORT RESULTS AS</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- spreadsheet</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- csv</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- html</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- json</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">CONVERT</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- [json] to [xml]</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- [html] to [rtf]</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">------------------------</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">--- BINS, HOLDING AREAS ---</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">--- Separate, stationary holding area for documents to be used in queries</span></p><p class="c5"><span class="c2">--- Separate, stationary holding area for pasted text snippets to be used in queries</span></p><p class="c5"><span class="c2">--- Separate bin for images made part of queries</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">----</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">FETCH AND FORMULATE REPORT OF IMAGES, GALLERIES</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">It might be easy to overlook that at the current stage the</span></p><p class="c5"><span class="c2">LLMs have not been set up to fetch images from the web</span></p><p class="c5"><span class="c2">in response to a query on a certain topic and place them</span></p><p class="c5"><span class="c2">in context of the query. &nbsp;Let&#39;s say that a person wants to </span></p><p class="c5"><span class="c2">research edible mushroom plants. There will be many websites </span></p><p class="c5"><span class="c2">that provide information about them but this will take a lot</span></p><p class="c5"><span class="c2">of time to go through them to get a complete overview, perhaps. &nbsp;</span></p><p class="c5"><span class="c2">There would be value in having the AI compile </span></p><p class="c5"><span class="c2">a report about the topic that is complete with images,</span></p><p class="c5"><span class="c2">captions, and so on, from multiple websites, not for the</span></p><p class="c5"><span class="c2">purpose of re-publication but for providing the user</span></p><p class="c5"><span class="c2">an overview on a less known topic that might be somewhat unpleasant</span></p><p class="c5"><span class="c2">to research on the Internet. &nbsp;&quot;What are all of the different</span></p><p class="c5"><span class="c2">types of edible mushrooms grown for cooking meals?&quot; would</span></p><p class="c5"><span class="c2">return a list of images and captions. &nbsp;Optional would be</span></p><p class="c5"><span class="c2">a summary next to each mushroom type. &nbsp;This is beyond what</span></p><p class="c5"><span class="c2">Google provides at the moment.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">AN IMAGE REMINDING THE USER OF THE VAST AMOUNT OF INFORMATION</span></p><p class="c5"><span class="c2">CONTAINED IN AN LLM AND THE MANY CAPABILITIES.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">One of the issues of leaving interaction with an LLM at</span></p><p class="c5"><span class="c2">a simplistic chat text box is that the user is not in</span></p><p class="c5"><span class="c2">touch with what the LLM provides. &nbsp;Within the AI community</span></p><p class="c5"><span class="c2">there are many criticisms of the LLM but no matter what</span></p><p class="c5"><span class="c2">these could be truly useful bases of knowledge and profound</span></p><p class="c5"><span class="c2">tools if they are provided the right interface and the</span></p><p class="c5"><span class="c2">right indications that they are massive, they are thorough,</span></p><p class="c5"><span class="c2">and they are capable. &nbsp;One does not get this impression</span></p><p class="c5"><span class="c2">when clicking inside the text box and then getting a response.</span></p><p class="c5"><span class="c2">In this way too much is left on the user to figure out.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">&nbsp; </span></p><p class="c5"><span class="c2">&nbsp; </span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">An LLM is so versatile but the barrier to its mainstream</span></p><p class="c5"><span class="c2">adoption is the fatigue produced by typing out prompts each time,</span></p><p class="c5"><span class="c2">the lack of organization, structure and guidance provided by such a simplistic user interface,</span></p><p class="c5"><span class="c2">and the lack of output formatting. So, the AI community should produce common tools </span></p><p class="c5"><span class="c2">that address this, providing a kind of notebook (sections of generic use </span></p><p class="c5"><span class="c2">categories), allowing the user the opportunity to select how it should be </span></p><p class="c5"><span class="c2">used when approaching it.The user approaches the LLM with a text box today </span></p><p class="c5"><span class="c2">but will instead walk up to adeveloped suite of options. The goal </span></p><p class="c5"><span class="c2">should be to allow the user to produce the prompts rapidly by providing him or her</span></p><p class="c5"><span class="c2">with parameter controls. &nbsp;Each category provides its own </span></p><p class="c5"><span class="c2">premade parameters and settings, setting up a kind of mode</span></p><p class="c5"><span class="c2">for interacting with an LLM. &nbsp;Mode #7, text mode supplies software </span></p><p class="c5"><span class="c2">features and workflows will be specific to that category.</span></p><p class="c5"><span class="c2">An application suite is what will allow AI in the form of an LLM to </span></p><p class="c5"><span class="c2">be of value.Put differently, we who use them are just those who are </span></p><p class="c5"><span class="c2">willing to put up with such a basic situation because we are accustomed </span></p><p class="c5"><span class="c2">to rough edges from technical problems.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">The interface for an LLM should be multifaceted, not limited to what the</span></p><p class="c5"><span class="c2">user can come up with inside a text box. A text box is a prompt for the user to</span></p><p class="c5"><span class="c2">come up with something impromptu. But our app is a </span></p><p class="c5"><span class="c2">presentation of pathways for any user who opens it up. &nbsp;</span></p><p class="c5"><span class="c2">Each pathway, each destination has its own utilities built in. &nbsp;</span></p><p class="c5"><span class="c2">For this reason, it is conceivable that a person would spend all</span></p><p class="c5"><span class="c2">day in our app interacting with an LLM.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">When the LLM is made use of for reading old texts, for example, it has traditional</span></p><p class="c5"><span class="c2">software functionality provided for that purpose, for paginating what is pasted, </span></p><p class="c5"><span class="c2">for treating a PDF as a book that has pages that can be flipped or</span></p><p class="c5"><span class="c2">laid out as an imposition (overview) sheet, for highlighting text, etc. This is </span></p><p class="c5"><span class="c2">in contrast to the AI chat that has little recognition when any common, </span></p><p class="c5"><span class="c2">specific usage occurs apart from writing code, which is when it will </span></p><p class="c5"><span class="c2">provide a code box.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">Allowing the output of an LLM to break out of a vertical chat format</span></p><p class="c5"><span class="c2">is important as at times there may be value in generating </span></p><p class="c5"><span class="c2">responses on a grid flowing from left to right, to see iterations. &nbsp;</span></p><p class="c5"><span class="c2">It just has to be emphasized that if an LLM can generate all kinds of</span></p><p class="c5"><span class="c2">data, then the means to present that data and generate it should be varied.</span></p><p class="c5"><span class="c2">If the LLM is used to generate specific kinds of data, the presentation of </span></p><p class="c5"><span class="c2">the generated output should adapt, just like described, </span></p><p class="c5"><span class="c2">so that it isn&#39;t always raw text stacked vertically. If it generates</span></p><p class="c5"><span class="c2">chart data, the data should show up in a chart. If it is a quiz being</span></p><p class="c5"><span class="c2">generated, then ideally an actual set of quiz controls should show up</span></p><p class="c5"><span class="c2">in the response. &nbsp;A recipe should be formatted as a recipe card if possible. &nbsp;</span></p><p class="c5"><span class="c2">Shaping the LLM&#39;s output presentation will make these very expensive</span></p><p class="c5"><span class="c2">AI models valuable. When AI is viewed as a more advanced tool rather than a </span></p><p class="c5"><span class="c2">simplistic genie in a bottle paradigm in which a question is asked an an action follows, </span></p><p class="c5"><span class="c2">these goals will be discussed more often. &nbsp;Tech often gets ahead</span></p><p class="c5"><span class="c2">of itself, wants to be more than it actually is and obsolesce the present</span></p><p class="c5"><span class="c2">to feel like it is moving into the future. &nbsp;But the basics of</span></p><p class="c5"><span class="c2">traditional software remain.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">NOISE IN DATA IS COMPRISED OF...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c5"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c5"><span class="c2">-----</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">1) Continue/Comment On/Make Response to: This would enable users to</span></p><p class="c5"><span class="c2">build upon or have the LLM respond to existing text, whether it&#39;s their own or</span></p><p class="c5"><span class="c2">provided by the LLM. &nbsp;There are &nbsp;dialectical benefits for</span></p><p class="c5"><span class="c2">the user of the LLM in this module. There is the ability to see</span></p><p class="c5"><span class="c2">a broader view of the topic by having the LLM response.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">2) Inquiry/Explain a Subject: Users could utilize the LLM</span></p><p class="c5"><span class="c2">to research and generate informative profiles or backgrounds</span></p><p class="c5"><span class="c2">on a wide range of topics, as well as receive curated reading</span></p><p class="c5"><span class="c2">lists to further explore those subjects.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">3) Manufacture/Generate Text: This would allow users</span></p><p class="c5"><span class="c2">to generate various types of written content,</span></p><p class="c5"><span class="c2">from literature and poetry to business name ideas and essays,</span></p><p class="c5"><span class="c2">based on specified parameters or prompts.</span></p><p class="c5"><span class="c2">The LLM could draw upon its broad knowledge to produce</span></p><p class="c5"><span class="c2">&nbsp;high-quality, original text tailored to the user&#39;s needs.</span></p><p class="c5"><span class="c2">&nbsp;</span></p><p class="c5"><span class="c2">4) Programming Code: This section would enable</span></p><p class="c5"><span class="c2">users to leverage the LLM&#39;s capabilities for</span></p><p class="c5"><span class="c2">software development, including generating code,</span></p><p class="c5"><span class="c2">answering programming-related questions, and</span></p><p class="c5"><span class="c2">even performing various code operations like</span></p><p class="c5"><span class="c2">refactoring, optimization, or debugging.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">5) How-to and Solutions for Problems: This feature would allow users to</span></p><p class="c5"><span class="c2">obtain step-by-step instructions or solutions for a variety of</span></p><p class="c5"><span class="c2">tasks and challenges, drawing on the LLM&#39;s extensive knowledge</span></p><p class="c5"><span class="c2">and problem-solving abilities. &nbsp;Especially relevant to household</span></p><p class="c5"><span class="c2">tasks, home improvement, automotive repair, questions about</span></p><p class="c5"><span class="c2">machines, appliances, etc.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">6) Veracity Check: Users could use this feature to assess the</span></p><p class="c5"><span class="c2">truthfulness or accuracy of claims, information, or statements,</span></p><p class="c5"><span class="c2">leveraging the LLM&#39;s understanding of factual knowledge and its</span></p><p class="c5"><span class="c2">ability to cross-reference sources. &nbsp;Primarily valued for</span></p><p class="c5"><span class="c2">circumstances relating to factuality outside of contemporary</span></p><p class="c5"><span class="c2">controversies.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">7) Explain Provided Text: Users could leverage this feature to gain</span></p><p class="c5"><span class="c2">insights into the origin, meaning, and context of a given text,</span></p><p class="c5"><span class="c2">helping to deepen their understanding. &nbsp;Especially useful for</span></p><p class="c5"><span class="c2">older texts. &nbsp;Translation, summarizing, etc. for provided texts</span></p><p class="c5"><span class="c2">falls under this category.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">8) Data Generation and Analysis: The LLM could be used to generate,</span></p><p class="c5"><span class="c2">format, and analyze various types of data, from weather forecasts</span></p><p class="c5"><span class="c2">to statistical insights, providing users with valuable information</span></p><p class="c5"><span class="c2">and insights from data.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">9) Converse, Simulate Interaction: This section would allow users</span></p><p class="c5"><span class="c2">to engage in more immersive and interactive experiences, such</span></p><p class="c5"><span class="c2">as role-playing, simulated interviews, and language learning</span></p><p class="c5"><span class="c2">exercises, helping to bridge the gap between the LLM and real-world interactions.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">10) Education: The LLM could be utilized to provide information on typical course</span></p><p class="c5"><span class="c2">curricula for different subjects, as well as describe the prerequisites and</span></p><p class="c5"><span class="c2">other relevant details to support educational and learning goals.</span></p><p class="c5"><span class="c2">Test questions and quizzes can be generated in this section.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">11) Proofread / Copy edit / Rephrase For Editing</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">Consider that conventional web search engines are </span></p><p class="c5"><span class="c2">limited in the same way, that often there is an inclination on the part of the</span></p><p class="c5"><span class="c2">user to make web searches carrying more specific conditions </span></p><p class="c5"><span class="c2">but there are no settings on the search page that </span></p><p class="c5"><span class="c2">are provided for this for fear that it would make using </span></p><p class="c5"><span class="c2">the web search engine too technical. &nbsp;But when a web search </span></p><p class="c5"><span class="c2">is made, sometimes there is a desire to </span></p><p class="c5"><span class="c2">limit the results to entities in the physical world, to</span></p><p class="c5"><span class="c2">make sure that results exclude Internet entities.</span></p><p class="c5"><span class="c2">Often there is a desire to limit a list of these results further </span></p><p class="c5"><span class="c2">to a geographic boundary, too. &nbsp;Web search could be said to be in </span></p><p class="c5"><span class="c2">the same state as the LLM chat format, something simplistic. </span></p><p class="c5"><span class="c2">Just like an LLM, there are possible categories of usage that </span></p><p class="c5"><span class="c2">won&#39;t make it difficult for a lay user </span></p><p class="c5"><span class="c2">to use the technology. But because of an online culture </span></p><p class="c5"><span class="c2">that seeks to make everything minimalist, the potential of many</span></p><p class="c5"><span class="c2">technologies is obscured. &nbsp;Minimalist is pursued as an ideal,</span></p><p class="c5"><span class="c2">to the detriment of usability and completion of the software needs.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">Even when you instruct humans you give them long spec sheets </span></p><p class="c5"><span class="c2">and documents with bullet lists. &quot;Genie in a bottle&quot; commands, </span></p><p class="c5"><span class="c2">making consecutive small requests to the AI, isn&#39;t broad enough for</span></p><p class="c5"><span class="c2">the AI to be of value for everyday tasks. &nbsp;The AI tool</span></p><p class="c5"><span class="c2">has to be able to take in a blueprint all at once and</span></p><p class="c5"><span class="c2">the parameters of this have to be easy to change.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">---</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">BUILDING LLM PROMPTS</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">-- Rectangular building blocks components replace typewritten</span></p><p class="c5"><span class="c2">prompts. &nbsp;Each component contains GUI controls for its parameters</span></p><p class="c5"><span class="c2">and is around 200pt x 200pt. &nbsp;When there is more than one they </span></p><p class="c5"><span class="c2">flow like text. &nbsp;A prompt is made out</span></p><p class="c5"><span class="c2">of one or more of these building blocks.</span></p><p class="c5"><span class="c2">Each building block makes up the prompt, allowing rapid</span></p><p class="c5"><span class="c2">construction of parametric prompts rather than just verbal ones.</span></p><p class="c5"><span class="c2">The container for making a prompt out of these components </span></p><p class="c5"><span class="c2">can be made as large as a page.</span></p><p class="c5"><span class="c2">-- The AI itself can be requested to make relevant prompts</span></p><p class="c5"><span class="c2">and this will be incorporated into the app.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">STANDARD APP SOFTWARE FUNCTIONALITY</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">- Export contents of selected output control</span></p><p class="c5"><span class="c2">to document, .RTF, .PDF, .TXT, .CSV, .XLSX.</span></p><p class="c5"><span class="c2">- AI-generated tabular data appears as interactive table</span></p><p class="c5"><span class="c2">in the app.</span></p><p class="c5"><span class="c2">- AI-generated map data appears on an interactive map.</span></p><p class="c5"><span class="c2">- Print selected output control.</span></p><p class="c5"><span class="c2">- Functions for reformatting data output are provided.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">PROMPT REVISION&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FUNCTIONALITY</span></p><p class="c5"><span class="c2">- Qualities: add [more or less] of [quality].</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">CHAT OUTPUT TAIL MENU</span></p><p class="c5"><span class="c2">- A menu appears at the bottom of every chat response</span></p><p class="c5"><span class="c2">allowing the user to modify the original prompt </span></p><p class="c5"><span class="c2">or respond to the chat.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">---</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">In an app like this, menus divide interactivity with the LLM into</span></p><p class="c5"><span class="c2">categories that assist the user in generating prompts according</span></p><p class="c5"><span class="c2">to the needs when the LLM is used. &nbsp;Providing starting points for the LLM</span></p><p class="c5"><span class="c2">for the user will end up being far more productive than a bare text box, which</span></p><p class="c5"><span class="c2">is probably too simplistic and tiresome when there is</span></p><p class="c5"><span class="c2">such a wide range of situations for which a person might use an LLM</span></p><p class="c5"><span class="c2">and such a large number of instances when the prompts could be</span></p><p class="c5"><span class="c2">formulated with convenient, traditional app user interface.</span></p><p class="c5"><span class="c2">At the current time, this is not regarded as a concern as there is</span></p><p class="c5"><span class="c2">belief that AI technology is advancing so rapidly that the tool</span></p><p class="c5"><span class="c2">just described will be obsolete as soon as it is finished in a year or</span></p><p class="c5"><span class="c2">two. &nbsp;That may not be true.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">A weak point of the AI chatbot is that interacting with the LLM</span></p><p class="c5"><span class="c2">often involves a lot of repetition and revision of writing and typing</span></p><p class="c5"><span class="c2">but there are no functions provided for that or even something to</span></p><p class="c5"><span class="c2">formulate prompts generatively in the first place. &nbsp;</span></p><p class="c5"><span class="c2">The presets within each category will facilitate valuable</span></p><p class="c5"><span class="c2">usage of the LLM for that individual category.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">An LLM wrapper app like this demonstrates product development</span></p><p class="c5"><span class="c2">that extends beyond the basic AI chatbot because it works with</span></p><p class="c5"><span class="c2">the LLM with more developed interactive conveniences and it shows</span></p><p class="c5"><span class="c2">that product is not obsolesced by research and engineering but</span></p><p class="c5"><span class="c2">should continue to be discussed.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">Currently the textbox for an AI chatbot is freeform typing.</span></p><p class="c5"><span class="c2">Offering some organization and structure to the situation--</span></p><p class="c5"><span class="c2">laying down a kind of blueprint for the amusement park--</span></p><p class="c5"><span class="c2">will make the LLM a lot more useful for the consumer.</span></p><p class="c5"><span class="c2">It is only under these conditions when an LLM could</span></p><p class="c5"><span class="c2">become mainstream.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">---- GENERATE META INSTRUCTIONS FOR EXERCISE, QUIZ, ETC. ---</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">A paraprogram that structures responses from the LLM</span></p><p class="c5"><span class="c2">in a stateflow so that it is back and forth.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5"><span class="c2">The meta program routes the output in a flow chart </span></p><p class="c5"><span class="c2">for the correct answer until it is given.</span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p><p class="c5 c8"><span class="c2"></span></p></body></html>