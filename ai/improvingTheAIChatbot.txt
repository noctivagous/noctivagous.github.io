
Improving the AI Chatbot

CLARIFICATION INTERMEDIATE QUESTIONS

Sometimes the AI chatbot user doesn't anticipate the different directions the
response could go, or the variations in contents it could have, especially when
asking about a topic that is unfamiliar. This is definitely true for programming
project,s where a seemingly simple query to the AI can entail many possible
approaches for the code. This points to the need for an intermediate stage of
response, which is a clarification menu that shows up before the output is
generated (a feature that is turned off if desired).  The AI would use it only
when necessary.  Initially I would try mapping the ASDF keys to a 4-option menu,
so that the user can proceed rapidly just by pressing a key and not get hung up
by intermediate clarification questions. "For this code, for the [topic] do you
want A) S) D) or F) ?" This menu would only appear when the AI determined it is
beneficial.  (The user could also insert shorthand into the prompt for
requesting varying degrees of clarification menus.)  Pressing RETURN will just
move past the menu. When relevant, for more involved matters, the clarification
menu would carry multiple layers of questions (a tree of questions) when the AI
knows that a satisfactory response likely requires that the user give multiple
specification answers in advance. The key issue is that the user does not always
know the issues implied by a query, and so many pages of text are generated in
the chat session as the user tries to refine the output, whereas often the AI
could have asked clarifying questions.

For the shorthand, the user can dictate inside the prompt which issues of
specifications it wants the AI to ask questions about.  For a code project, the
user might type [specq: programming library, variable naming. depth:4,
quantity:4] and then get questions from the AI in these areas in a quantity of
questioning level 4/10 and tree depth of 4. Thus the user can be proactive about
the output from the AI.


INTERACTIVE FORMS

The AI chatbot could also respond to the user's code (programming) query with an
interactive form where it has generated an outline of what it plans to do for
the project.  Underneath each outline point are text boxes where the user can
change or refine the AI's plans.  At the end of the form, the user can then
choose to either receive an updated interactive form or it can have the AI
proceed.  In another variation, the AI would include questions inside the
outline and the next step would be the interactive form that the user reviews.

This also shows that the interaction with the chatbot that the user has with the
AI doesn't have be at the end of response and separated from it but can be
interacting with controls and textfields that the AI embedded inside it.

The AI isn't always going to generate what you want. The AI chatbots could
certainly implement intermediate steps where the user can get an overview of its
plans, especially for programming projects, and then refine them iteratively
before anything is generated.


BRANCHING OFF AND SIDE QUERIES

One issue is that there are times when the user wants to know more about a
subject found within the generated text but not necessarily interrupting the
stream with a query about it (which will also affect later responses).  There
can be a mode provided in the AI chatbot where sentences and paragraphs can be
clicked on, which opens up accessory or marginal tabs for exploring topics in
the original generated response.  The output will be associated with the main
chat sequence but sit to the side or behind it.  In other words, the user should
be able to branch off from the initial chat session and return to it.  The AI
chatbot can certainly have other tools too, like built-in dictionaries and the
ability to add categorization tags to chat sessions.


HYPERTEXT FEATURES

When processing text, the AI might have another agent activated that adds
metadata features to the text.  These might include definitions for certain
terms, especially for translated materials, and contextual information.  The AI
can generate hypertext features, assisting in the use of text.


INTERACTIVE FORMS II

The AI is given a list of tags that it can send to the client to represent
controls (for example,  <aichat:textfield>) and the AI can send these inside a
type of chat response that it uses as an intermediate step, to gather
information before generating the final output.  These include 1D and 2D sliders
(<aichat:slider>), multiple choice lists, color pickers, checkboxes, etc. 
Replying to the AI after it embeds these in its response is then about
interacting with the chat response, not typing in the followup chat textbox as
is the case for everything now.  At the bottom of this interactive chat
response, the AI will have generated different submit buttons according to the
situation.  The AI can also, after receiving a submission, update the contents
of this interactive form in the place where it sits instead of generating a new
one underneath.  (It would send a command to the client like
<aichat:updateinplace>). What this implies for chatbots is that the the AI can
generate different types of chat responses (data types), some of which include
embedded interactive controls that allow it to tailor its output extensively in
tandem with the user. It can get a lot of information before carrying out the
request.  In a more advanced version, the interactive form that it generates
will be running code so that the AI can collect information from interactive
diagrams (https://github.com/mermaid-js/) that the user modified.

The interactive forms can provide just a general outline of the AI's proposed
plans or they can include sample details of how the AI intends to execute the
task, such as sample text or code.  In a translation effort, for example, the AI
can generate multiple options for the style of translation.

Other tags include <aichat-control:curveeditor>, <aichat-control:sequencer1d cols="8"> for a
drum sequencer, <aichat-control:sequencer2d rows="5" cols="8"> for a musical note
sequencer. In the software, the user would be able to add custom control tags
for custom use.


INTERACTIVE FORMS III

Every response from the AI chatbot could make use of an interactive form, which would
reduce the page length of any chat session by allowing modification and
feedback in place by the user, who decides whether to update the response in place by
using the corresponding submit button at the bottom.  The alternative is that
the user just uses the existing text box to respond as usual.  This means that every
response would make use of some of the control tags sent to the client (e.g.
<aichat-layout:flexboxcontainer>) so that the AI produces complex layouts with
interactive controls.  The issue is that the AI usually can only do one thing
well at a time, so it might require a second request to reformat the response
within the tags.


INTERACTIVE FORM TAGS REFERENCE

<!-- gui controls -->
<aichat-gui-control:button>
<aichat-gui-control:textfield dataformat="plaintext"> // richtext
<aichat-gui-control:numberfield" > // integer, float
<aichat-gui-control:checkbox>
<aichat-gui-control:radiogroup>
<aichat-gui-control:radiobutton>
<aichat-gui-control:slider-1d>
<aichat-gui-control:slider-2d>
<aichat-gui-control:slider-circular>
<aichat-gui-control:colorpicker>
<aichat-gui-control:sequencer-1d>
<aichat-gui-control:sequencer-2d>

<!-- layout -->
<aichat-layout:flexboxcontainer>

<!-- external data -->
<ai-chat-document-viewer type="pdf"> // for fetched documents
<ai-chat-iframe url="">

The client will construct the various interactive components on the fly based
on the provided tags, amounting to mini-applets in any given response.




