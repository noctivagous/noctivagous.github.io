Going Beyond The 2022 ChatGPT App Format

INTERACTIVE MODES

The next generation of AI chatbot web app should be a focus of the AI industry.  To begin with, we can recognize that the current AI chatbot is occasionally being put into modes by the user (following the guidance of the AI companies), such as prompting it to give a quiz or teach a subject.  But the user can't be expected to recall these prompt techniques all the time when the chat interface doesn't naturally follow that pattern.  After time, even regular users will forget to use these techniques.  Making the AI enter these modes with prompts is really just a forced hack when the user interface is a scrolling chat.  Most importantly, as the AI chatbot carries out these mode instructions, the app's GUI isn't able to change.  In fact, in these chatbot apps the AI cannot even insert form (GUI) controls inside a response to collect information and only collects information from the large text input field.  For example, if the AI is quizzing the user, it should be able to change the app's entire GUI into a proper interactive quiz format (still keyboard driven) so that the software matches the situation. The archetypal AI chatbot app of today should no longer just repurpose the bare scrolling chat.  Another of these modes, which would benefit from GUI, is step-by-step walkthrough in which the user has asked to be walked through a task or project.  For each step, the AI gives the user some instructions, waits for a response, and then comes up with the next step based on the results, repeating until the user accomplishes the job.  Whatever mode like this that the AI has been placed into was done with text prompts, not a formal app feature that the user activated. The mode is forced to occur inside the same vertical scrolling chat of plain text.  This isn't doing the AI model justice or the users.

So, for the next generation of AI chatbot app, this AI chat technique ("start quizzing me on..." or "collect information from me about...") should be officially incorporated into the app along with accompanying GUI changes.  For a quiz mode, the GUI can show one question at a time. Matching the GUI needs for a quiz, the app is presenting to the user form input controls like multiple choice buttons, sliders, and checkboxes to get an answer.  For the step-by-step walkthrough mode, one slide can be shown at a time, with a text input area.  The walkthrough mode is useful when asking the AI how to troubleshoot a computer problem, for example, or diagnose a car or appliance issue, or carry out some kind of technical task.  The author of this article has made use of AI chatbots in this mode while configuring a Linux system at the command line level, which is can suddenly turn into a convoluted chore that benefits greatly from AI assistance.

---

EXAMPLE MODES AND THEIR GUIs: 

1. Quiz Mode
GUI: Displays one question at a time with multiple-choice buttons, checkboxes, text inputs, or sliders. Progress bar, score tracker, and "Reveal Answer" button.
Workflow: AI generates questions from a topic; user submits answers; AI provides immediate feedback, explanations, and adapts difficulty.

2. Step-by-Step Walkthrough Mode
GUI: Carousel or slide-based layout showing one step at a time (instruction + expected result). Side panel for user input (e.g., paste terminal output). "Next" button enabled after submission.
Workflow: Step → User reports result → AI interprets/adjusts → Next step. Ideal for troubleshooting (e.g., Linux config, appliance repair).

3. Questionnaire/Information Gathering Mode
GUI: Form-based (single-page for all questions or one-at-a-time). Inputs include text fields, dropdowns, file uploads, date pickers. Progress indicators and validation.
Workflow: AI asks structured questions to collect data (e.g., for project setup); compiles responses; generates output (e.g., code scaffolds, plans).

4. Teaching/Course Instruction Mode
GUI: Lesson dashboard with modules, embedded videos/images, note-taking panel, and interactive exercises. Timeline navigation for revisiting sections.
Workflow: AI delivers content in sequenced lessons; interleaves quizzes, examples, and Q&A; tracks user progress and adapts pacing.

5. Document Study Mode
GUI: Integrated document viewer (PDF/text upload, page-by-page flip). Highlight/select tools for words/paragraphs; pop-up side panel for definitions, translations, or explanations.
Workflow: User uploads/navigates document; selects text; AI provides lookups, summaries, or context; supports foreign languages or arcane terms.

---

To simulate a walkthrough mode for in today's scrolling chatbot GUI, give it the following prompt: "I want to [e.g.: optimize the speed of my Linux system with the terminal].  Let's do this one step at a time and I give you results. A step–result–interpret loop."  This is usually better for the job than the default response and layout of the chatbot, which is a generated list of instructions for the user to follow.  Doing it the default way like that isn't making use of AI's latent interactive capacities.  The AI is useful for this because when working with the command line complexities and unexpected results can arise at each step. Yhe AI can respond according to the user's results.  Matching the app's GUI to a mode like walthrough is important this is better presented different than a vertical scrolling chat.  The chat right now is more about the user making queries.  In the walkthrough mode, each step is one in which the AI either gathers information or gives instructions and then asks for the results.

In a new type of chatbot, it will make a big difference that there are designated modes offered to the user in a formal way, each of which activate a collection of GUI, decision trees, and workflows.  The welcome screen for the chatbot app might provide a menu grid of these modes.  The improvement is that when the user approaches the software, there are entry points provided for how to use it and the burden isn't place on the user for how to make the AI valuable. The AI chatbot will improve if its GUI adapts to various mode scenarios.   The design of the software will be more than just a plain chat but it can still offer this. 

Another mode gathers information in the form of questionnaires, either all at once on a single form or spread out one question at a time, before taking action, such as to set up a software development project or project where there are placeholders it can generate.  A little more mode dynamic would be a teaching mode for course instruction, and the GUI would change to accommodate that, too.

When studying a book that has arcane vocabulary or is in a foreign language, the reader can activate the corresponding mode in the AI chatbot software, which allows opening up a document viewer inside the app, displaying its contents page by page, and tools will then be provided for looking up definitions and getting more information about a selected word or paragraph.

At the bottom of this document we provide multiple examples of different interactive modes for the AI chatbot software.  An important point is that people who work in different fields can make their own modes or use modes built for them, whether it is in the music industry, screenwriting, etc.  For that to happen, the web app (or desktop app) should have extensibility built in, which in this case would be the ability of users to make custom modes, explained in a section below.  The modes that ship with the app would be made out of the same declarative desriptor file format that users can utilize to make their interactive modes.


EXTENSIBILITY

The extensibility of the chatbot software is a central way that the app can allow the next generation AI chatbot software to adapt to the world instead of vice-versa.  Users may want to make their own functionality and modes for the AI chatbot app.  These modes can be programmed and supplied by users in the form of files that contain a sequence, decision tree, and workflow descriptor (declarative) data format.  It will describe which GUI to use for a specific step of a mode and it allows providing prompt text to go control every aspect of the sequence.  By implementing all of this, the AI chatbot of today, which has remained the same since 2022, can go beyond a one-size-fits-all vertical scrolling GUI and actually accommodate different situations.

If given a set of workflow components and GUI controls, the AI could put together its own GUI forms and sequences for a situation that is a mix of these situation. But a stock set of modes will provide familiar usage of the AI and structure for it.  It is better to guide the AI today than to let it do what it wants.
Extensibility allows the programming community to try out variations on and additions to the current chat.



IMPROVING THE CONVENTIONAL SCROLLING CHAT

An AI chatbot web app like ChatGPT could be given some commands that work with the actual app, such as, "Take the last response you generated and put it in the scrapbook."  This is part of the issue that the software should be built out more to be like traditional app software.  Interactions with the chatbot should be able to reference aspects of the software itself.

There is also the overlooked matter that the flow of the conversation with the AI in today's chatbot software is narrow and limited and it can never flow like a real chat, either in real life or onlione, where there commonly is an alternation between questions that ask for short answers and long ones.  In actuality, the chat software of today is following a very limiting query-and-response format and is not like chatting.  In real conversations, people ask for clarification when they need more information or something is vague, whereas the chatbot is programmed to just proceed with assumptions that fill in any unknown information.  In real convesations, people make brief suggestions, ask to make sure everything is ok, and there is a back and forth toward a goal.  After an expert or consultant asks for clarification, it gives him information about where to guide the project, what the other person's goals are and what the person needs to know.  So this is a key improvement that should be made in the next generation of AI chatbots so that they are more normal and natural for real life and the intake of information.
 
Take the case of a certain feature to implement, which is brief clarifying menus. The user looking to buy a product asks how to get started and the AI responds like a store employee or expert to begin the process.  The flow of the interaction is more natural and will be easier on the user for this situation.  The user can always ask a question.

USER: I am looking to buy a mini PC.  
AI: What is your budget? Press a key: 1) <$300 2) <$500 3) <$700 4) >$700 
USER: 3  
AI: 1) Linux or 2) Windows? 
USER: 1
AI: There are a lot of options and it depends on whether you want an Intel CPU
or a Ryzen.  The Ryzen chips focus more on multi-threaded processing. Which
do you prefer?  1) Intel 2) Ryzen.
USER: 2


Map kit - research things across a map that remains stationary during the chat.



DESKTOP APP

If this AI app is running on the desktop, the capabilities of the app widen. It can be given an AI agent that is allowed to execute apps and open up windows, which would allow it to generate an on-the-fly instructions for a user to use an unfamiliar app.  (In the future, it could be the case that the AI is given a set of complete application kit components and wires up its own apps on the fly.)  Such an app can, on its own, schedule processes for agents to track whatever the person wants to track.  It can monitor the system if it needs to and integrate into the usage of the computer.




SUMMARY OF EXAMPLE MODES: 

1. Quiz Mode
GUI: Displays one question at a time with multiple-choice buttons, checkboxes, text inputs, or sliders. Progress bar, score tracker, and "Reveal Answer" button.
Workflow: AI generates questions from a topic; user submits answers; AI provides immediate feedback, explanations, and adapts difficulty.

2. Step-by-Step Walkthrough Mode
GUI: Carousel or slide-based layout showing one step at a time (instruction + expected result). Side panel for user input (e.g., paste terminal output). "Next" button enabled after submission.
Workflow: Step → User reports result → AI interprets/adjusts → Next step. Ideal for troubleshooting (e.g., Linux config, appliance repair).

3. Questionnaire/Information Gathering Mode
GUI: Form-based (single-page for all questions or one-at-a-time). Inputs include text fields, dropdowns, file uploads, date pickers. Progress indicators and validation.
Workflow: AI asks structured questions to collect data (e.g., for project setup); compiles responses; generates output (e.g., code scaffolds, plans).

4. Teaching/Course Instruction Mode
GUI: Lesson dashboard with modules, embedded videos/images, note-taking panel, and interactive exercises. Timeline navigation for revisiting sections.
Workflow: AI delivers content in sequenced lessons; interleaves quizzes, examples, and Q&A; tracks user progress and adapts pacing.

5. Document Study Mode
GUI: Integrated document viewer (PDF/text upload, page-by-page flip). Highlight/select tools for words/paragraphs; pop-up side panel for definitions, translations, or explanations.
Workflow: User uploads/navigates document; selects text; AI provides lookups, summaries, or context; supports foreign languages or arcane terms.

6. Goal Tracking/Habit Building Mode
GUI: Dashboard with progress calendars, checklists, streak counters, and reminder notifications. Editable goals with sub-tasks.
Workflow: AI helps set SMART goals via questionnaire; provides daily check-ins; analyzes progress; adjusts plans (combines teaching and walkthrough).

7. Language Learning/Conversation Practice Mode
GUI: Chat with voice input/output, pronunciation feedback, vocabulary flashcards. Immersive scenarios (e.g., virtual cafe dialogue).
Workflow: AI converses in target language; corrects errors in real-time; drills grammar/vocab; tracks fluency progress (blends quiz and teaching).

8. Role-Playing/Simulation Mode
GUI: Character avatars, dialogue bubbles, and scenario timeline. Branching choice buttons for user decisions; environmental descriptions with images.
Workflow: AI sets up scenario (e.g., negotiation, historical event); responds in-character; adapts based on user choices; ends with debrief/analysis.
Data Analysis/Visualization Mode
GUI: Upload zone for datasets; interactive charts/graphs (draggable filters, zoom). Query bar for natural language asks; export buttons.
Workflow: User uploads data; AI suggests visualizations; iterates on queries (e.g., "Show trends in sales"); explains insights step-by-step.

9. Custom Workflow Builder Mode (For Extensibility)
GUI: Drag-and-drop builder for components (e.g., forms, slides, buttons). Preview pane and export/share for mode files.
Workflow: Users/AI define sequences via declarative files (JSON/YAML); describe GUI per step, prompts, and logic; app loads and runs custom modes.

These modes can be mixed (e.g., AI proposes a hybrid of walkthrough + data analysis for a task) or extended via user-uploaded workflow descriptors. A stock set ensures guided, familiar experiences, while allowing AI to assemble novel GUIs from components for unstructured queries.

field-specific modes that professionals (or enthusiasts) in various industries could create, share, or select from a mode marketplace. Each mode dynamically reshapes the GUI, input controls, and AI workflow to match the domain’s tools, terminology, and decision loops. Users upload or download declarative mode files (JSON/YAML) that define steps, prompts, widgets, and validation rules—making the AI a tailored assistant rather than a generic chat.


