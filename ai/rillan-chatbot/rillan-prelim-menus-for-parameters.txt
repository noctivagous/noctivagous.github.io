
Though it depends on the situation, quite often
too much labor is required of the user to put together a
complete and detailed text prompt to get a satisfactory
result.  This is a key reason that usage of AI falls
short of expectations.

Take for example the generation of an image.
I said to the AI, "Make a playing card with the
image of a joker on it."  I found out, after getting
the result, that what the AI had in its defaults 
was far from what I was expecting. It made an 
image of a joker from a recent movie in a photorealistic 
style inside a playing card frame.  It turns out I was really 
going to have to tell it a significant number of 
specifying details upfront:
	- what illustration style (photorealistic).
	- what the joker should look like. 
	- what the joker should be doing.
	- etc.

For routine usage of AI, all of these parameters take 
too much work to come up with.  It's way too much to expect 
from the user at the first step and its also work that
the AI should be providing in an intermediate step before
generation of the image occures.
 
So, the situation should really be the AI coming up
with these kinds of parameters first and asking them 
in a preliminary menu that features GUI controls.

Example:

---
AI: You said you want a joker on a playing card
	- What illustration style? [dropdown menu options]
	- What kind of joker? [dropdown menu] Other: [Textfield]
	- What position should the joker be in? [dropdown menu] Other: [Textfield].
	- More specifying information: [].
---


If this is image is being generated in a node flow diagram
environment then it would be the AI asking questions before
generating the nodes.  

It should be that the AI is taking care of the intermediate 
work of providing the menu of parameters, the parameters 
that currently aren't specified by the user until after
finding out how the AI made the image and departed from 
expectations.





