
Mobile App Stores on Tablet Computers and Touchscreen Smartphones

NOCTIVAGOUS.GITHUB.IO

The first tablet computers that appeared in the 2000s presented the consumer with an unmodified desktop computer screen, often tied to the use of a stylus.  Apart from omitting multi-touch functionality on the screen, the computer companies did not recognize that the input and interface to the operating system had changed, from mouse buttons and fixed screen cursor to intermittent touch points.  That is, no conversion of the overall system user interface or the apps on these devices was ever undertaken.  As would have to be the case, these products carried little appeal except for niche users. They ended up providing, for a mobile situation, a more complicated way to use a mouse curosr and PC operating system.

For the same reason that a car’s frame and chassis cannot be directly utilized for the fuselage for an airplane or the hull for a boat, the desktop PC operating system, its cursor, and the software it runs, cannot be left the same for a touchscreen tablet or smartphone device.  When the overall input configuration and form of the hardware changes, everything else has to respond too.  In some cases this is apparent to everyone and part of the technology shift, such as how VR games have to be developed differently than traditional 3D video games, and so everyone makes the change.  In other subjects, it is less obvious and continues to exist in an antiquated state, such as how video game controllers still do not detect how much force has been applied to their buttons. (Each button is like an on-off light switch, including the arrow buttons.)  If that one component of a controller changes, all of the video game companies have to change too.

On a touchscreen, the finger is swooping in and touching the buttons, not the cursor being pushed around, so all apps have to be written or converted for that.  For example, the computer user can't easily use touch for desktop apps because the desktop apps’ buttons are too small for the fingers.  Furthermore, when it is a touchscreen device with no keyboard, then all of the keyboard (hotkey) command shortcuts aren't available. Therefore, the desktop interface has to be restructured for apps that end up looking different; the apps as they are developed have to be made for touch, following a corresponding set of rules.  Under Steve Jobs, Apple went about making that kind of modification for Mac OS, turning it into a separate touch operating system, iOS, for its own type of apps.  It isn't a deep system-level change, however.  iOS is mostly a set of software conventions for touch-based apps, to make them easy to touch and use.

This change of user interface has nothing to do with what software is allowable for execution by the computer itself or the user.  In addition to that, not everyone would implement the surrounding touch operating system conventions in such a kiosk-like, minimalistic and restrictive way like Apple or Google choose.  With all of the differences occurring between mobile tablets and desktop computers, it appears that an opportunity appeared for Apple and Google to deceive the public, that this change in computing format necessitated a restrictive environment on how apps are loaded and executed on the hardware, that the two need to vet any app executed in an online store, prohibit custom app execution by the user, and take a large percentage of sales too.  This part is completely artificial, a point already made exceedingly obvious by Microsoft Surface tablets: these tablets run any Windows app the user wants and they are touchscreen devices.  Microsoft just never bothered to make a mobile version of Windows for Microsoft Surface that emphasized properties of mobile apps, so these tablets just run desktop apps and carry the problems mentioned, that there has to be a separate set of conventions for touch software (like iOS has).   Microsoft could have done better and provided its Surface tablets an entirely separate set of conventions and then left access to Windows apps on the side.  This situation shows how iPads could run Mac OS apps on the side. They could also run any touchscreen app just freely as them.

What Apple and Google did was make the kiosk-like grid launch screen and the app store the center of the user experience with these devices.

